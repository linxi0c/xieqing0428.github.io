<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[BigData复习笔记01：HDFS1.0与MapReduce]]></title>
    <url>%2Fposts%2F34c278f3%2F</url>
    <content type="text"><![CDATA[HDFS1.0与MapReduceblah blah blahtext##[title] [url] [link-text]12345[language] 是代码语言的名称，diff 用来设置代码块颜色高亮，非必须；-红+绿[title] 是顶部左边的说明，非必须；[url] 是顶部右边的超链接地址，非必须；[link text] 如它的字面意思，超链接的名称，非必须。代码#@ 前面的是label的名字，后面的是要显示的文字）：default1&#123;% label default@default %&#125;primary1&#123;% label primary@primary %&#125;success1&#123;% label success@success %&#125;info1&#123;% label info@info %&#125;warning1&#123;% label warning@warning %&#125;danger1&#123;% label danger@danger %&#125;1234567891011&#123;% tabs 选项卡, 1 %&#125;&lt;!-- tab --&gt;**这是选项卡 1** 呵呵哈哈哈哈哈哈哈哈呵呵哈哈哈哈哈哈哈哈呵呵哈哈哈哈哈哈哈哈呵呵哈哈哈哈哈哈哈哈呵呵哈哈哈哈哈哈哈哈呵呵哈哈哈哈哈哈哈哈……&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 2**&lt;!-- endtab --&gt;&lt;!-- tab --&gt;**这是选项卡 3** 哇，你找到我了！φ(≧ω≦*)♪～&lt;!-- endtab --&gt;&#123;% endtabs %&#125;1&#123;% pdf /path/to/your/file.pdf %&#125;推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn《数据库系统概论》学习笔记之关系数据库《数据库系统概论》学习笔记之绪论]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>复习笔记</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>复习笔记</tag>
        <tag>HDFS1.0</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink电商团购项目（一）]]></title>
    <url>%2Fposts%2F451f3483%2F</url>
    <content type="text"><![CDATA[Flink项目环境搭建第一章 大数据集群搭建Flink集群环境系统CentOS-7-x86_64-Minimal-1810.isoflink-master1 192.168.69.121 2core 2Gflink-master2 192.168.69.122 2core 2Gflink-slave1 192.168.69.123 1core 2Gflink-slave2 192.168.69.124 1core 2Gflink-slave3 192.168.69.125 1core 2GHadoop集群组件列表组件Master1Master2Slave1Slave2Slave3jdk1.8.0_212√√√√√scala-2.11.12√√√√√miniconda3√√√√√hadoop2.7.0√√√√√kafka0.11√√√√√mariadb/mariadb-server√√Hive2.2.0√√zookeeper 3.4.9√√√Flume1.9√√√√√Flink1.7√√√√√组件安装步骤参考往期系列文章Flink电商团购项目（零）Hadoop环境搭建推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn通行证项目前端开发小结拾贝电台开源了]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>项目实战</category>
        <category>Flink电商团购</category>
        <category>01-大数据集群搭建</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Flink</tag>
        <tag>项目</tag>
        <tag>电商</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flink电商团购项目（零）：环境搭建]]></title>
    <url>%2Fposts%2F8d61cd2a%2F</url>
    <content type="text"><![CDATA[Flink项目环境搭建第一章 大数据集群搭建Flink集群组件安装安装JDKcd /mnt/hgfs/aboutyuncp jdk-8u212-linux-x64.tar.gz /usr/aboutyuncd /usr/aboutyuntar zxvf jdk-8u212-linux-x64.tar.gzrm -rf jdk-8u212-linux-x64.tar.gzmv jdk1.8.0_212 jdk#配置JDK环境变量vim /etc/profile1234# SET JAVA PATH export JAVA_HOME=/usr/aboutyun/jdk export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib export PATH=$PATH:$JAVA_HOME/binsource /etc/profile安装Scalacd /mnt/hgfs/aboutyuncp scala-2.11.12.tgz /usr/aboutyuncd /usr/aboutyuntar zxvf scala-2.11.12.tgzrm -rf scala-2.11.12.tgzmv scala-2.11.12 scala#配置Scala环境变量vim /etc/profile123# SET SCALA PATH export SCALA_HOME=/usr/aboutyun/scala export PATH=$PATH:$SCALA_HOME/binsource /etc/profile安装miniconda3cd /mnt/hgfs/aboutyuncp Miniconda3-latest-Linux-x86_64.sh /usr/local/src/cd /usr/local/srcsudo yum -y install bzip2sh Miniconda3-latest-Linux-x86_64.shrm -rf Miniconda3-latest-Linux-x86_64.sh配置环境变量：source ~/.bashrc更新conda环境：conda update --all安装Zookeeper仅在Slave节点cd /mnt/hgfs/aboutyuncp zookeeper-3.4.9.tar.gz /usr/aboutyun/cd /usr/aboutyun/tar zxvf zookeeper-3.4.9.tar.gzrm -rf zookeeper-3.4.9.tar.gzmv zookeeper-3.4.9 zookeepercd zookeeper#配置Zookeeper环境变量vim /etc/profile123# SET ZOOKEEPER PATH export ZOOKEEPER_HOME=/usr/aboutyun/zookeeper export PATH=$PATH:$ZOOKEEPER_HOME/binsource /etc/profile#修改Zookeeper配置mkdir datamkdir logscd confcp zoo_sample.cfg zoo.cfgvim zoo.cfg12345dataDir=/usr/aboutyun/zookeeper/data dataLogDir=/usr/aboutyun/zookeeper/logs server.1=flink-slave1:2888:3888 server.2=flink-slave2:2888:3888 server.3=flink-slave3:2888:3888#分别添加ID123456#Slave1 echo "1" &gt; /usr/aboutyun/zookeeper/data/myid #Slave2 echo "2" &gt; /usr/aboutyun/zookeeper/data/myid #Slave3 echo "3" &gt; /usr/aboutyun/zookeeper/data/myid#启动Zookeeper服务zkServer.sh start#查看运行状态zkServer.sh statusjps#关闭Zookeeper服务zkServer.sh stop安装Hadoopcd /mnt/hgfs/aboutyuncp hadoop-2.7.0.tar.gz /usr/aboutyun/cd /usr/aboutyun/tar zxvf hadoop-2.7.0.tar.gzrm -rf hadoop-2.7.0.tar.gzmv hadoop-2.7.0 hadoopcd hadoop#配置Hadoop环境变量vim /etc/profile12345# SET HADOOP PATH export HADOOP_HOME=/usr/aboutyun/hadoopexport PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbinexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopsource /etc/profile#创建临时目录和文件目录mkdir -p /usr/aboutyun/hadoop/dfs/namemkdir -p /usr/aboutyun/hadoop/dfs/datamkdir -p /usr/aboutyun/hadoop/tmp/dfsmkdir -p /usr/aboutyun/hadoop/journalmkdir -p /usr/aboutyun/hadoop/yarn/logs#修改Hadoop配置文件cd etc/hadoopvim hadoop-env.sh1export JAVA_HOME=/usr/aboutyun/jdkvim yarn-env.sh1export JAVA_HOME=/usr/aboutyun/jdkvim slaves123flink-slave1 flink-slave2flink-slave3vim core-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://mycluster&lt;/value&gt; &lt;description&gt;默认文件系统的名称。一个URI，其方案和权限决定了FileSystem的实现。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt; &lt;value&gt;flink-slave1:2181,flink-slave2:2181,flink-slave3:2181&lt;/value&gt; &lt;description&gt;由逗号分隔的ZooKeeper服务器地址列表，由ZKFailoverController在自动故障转移中使用。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hadoop/tmp&lt;/value&gt; &lt;description&gt;数据目录目录&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt; &lt;value&gt;sshfenceshell(/bin/true)&lt;/value&gt; &lt;description&gt;用于服务防护的防护方法列表。可能包含内置方法（例如shell和sshfence）或用户定义的方法。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt; &lt;value&gt;/home/aboutyun/.ssh/id_rsa&lt;/value&gt; &lt;description&gt;用于内置sshfence fencer的SSH私钥文件。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;io.file.buffer.size&lt;/name&gt; &lt;value&gt;131072&lt;/value&gt; &lt;description&gt;SequenceFiles中使用的读/写缓冲区的大小。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ipc.client.connect.max.retries&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;description&gt;客户端为建立服务器连接而重试的次数。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;ipc.client.connect.retry.interval&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;客户端在重试建立服务器连接之前将等待的毫秒数。&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt;vim hdfs-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.nameservices&lt;/name&gt; &lt;value&gt;mycluster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.namenodes.mycluster&lt;/name&gt; &lt;value&gt;flink-master1,flink-master2&lt;/value&gt; &lt;description&gt;给定名称服务的前缀包含给定名称服务的逗号分隔的名称节点列表。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.flink-master1&lt;/name&gt; &lt;value&gt;flink-master1:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.rpc-address.mycluster.flink-master2&lt;/name&gt; &lt;value&gt;flink-master2:8020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.flink-master1&lt;/name&gt; &lt;value&gt;flink-master1:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.http-address.mycluster.flink-master2&lt;/name&gt; &lt;value&gt;flink-master2:50070&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt; &lt;value&gt;qjournal://flink-slave1:8485;flink-slave2:8485;flink-slave3:8485/mycluster&lt;/value&gt; &lt;description&gt;HA群集中多个名称节点之间的共享存储上的目录。此目录将由活动写入并由备用数据库读取，以保持命名空间同步。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.client.failover.proxy.provider.mycluster&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider&lt;/value&gt; &lt;description&gt;配置Java类的名称，DFS客户端将使用该名称来确定哪个NameNode是当前的Active，以及哪个NameNode当前正在为客户端请求提供服务。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;是否启用自动故障转移。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;3&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions.enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt;如果为“true”，则启用HDFS中的权限检查。如果为“false”，则关闭权限检查，但所有其他行为都保持不变。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hadoop/journal&lt;/value&gt; &lt;description&gt;指定JournalNode在本地磁盘存放数据的位置&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///usr/aboutyun/hadoop/dfs/name&lt;/value&gt; &lt;description&gt;设置namenode存放路径&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///usr/aboutyun/hadoop/dfs/data&lt;/value&gt; &lt;description&gt;设置datanode存放径路&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.blocksize&lt;/name&gt; &lt;value&gt;268435456&lt;/value&gt; &lt;description&gt;大型文件系统的HDFS块大小为256MB。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.handler.count&lt;/name&gt; &lt;value&gt;100&lt;/value&gt; &lt;description&gt;namenode的服务器线程数&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt;mv mapred-site.xml.template mapred-site.xmlvim mapred-site.xml1234567891011121314151617181920212223242526272829303132333435363738394041&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;description&gt;指定mr框架为yarn方式&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.map.memory.mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt; &lt;description&gt;每个Map任务的物理内存限制&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.reduce.memory.mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt; &lt;description&gt;每个Reduce任务的物理内存限制&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;0.0.0.0:10020&lt;/value&gt; &lt;description&gt;MapReduce JobHistory服务器IPC主机：端口&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;0.0.0.0:19888&lt;/value&gt; &lt;description&gt;MapReduce JobHistory服务器Web浏览时的主机：端口&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.application.classpath&lt;/name&gt; &lt;value&gt; /usr/aboutyun/hadoop/etc/hadoop, /usr/aboutyun/hadoop/share/hadoop/common/*, /usr/aboutyun/hadoop/share/hadoop/common/lib/*, /usr/aboutyun/hadoop/share/hadoop/hdfs/*, /usr/aboutyun/hadoop/share/hadoop/hdfs/lib/*, /usr/aboutyun/hadoop/share/hadoop/mapreduce/*, /usr/aboutyun/hadoop/share/hadoop/mapreduce/lib/*, /usr/aboutyun/hadoop/share/hadoop/yarn/*, /usr/aboutyun/hadoop/share/hadoop/yarn/lib/* &lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt;vim yarn-site.xml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133&lt;configuration&gt;&lt;!-- Site specific YARN configuration properties--&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.recovery.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;启动后启用RM以恢复状态。如果为true，则必须指定yarn.resourcemanager.store.class。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.automatic-failover.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.store.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore&lt;/value&gt; &lt;description&gt;用作持久存储的类。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt; &lt;value&gt;flink-slave1:2181,flink-slave2:2181,flink-slave3:2181&lt;/value&gt; &lt;description&gt;ZooKeeper服务的地址，多个地址使用逗号隔开&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;启用RM高可用性。启用时，（1）默认情况下，RM以待机模式启动，并在提示时转换为活动模式。（2）RM集合中的节点列在yarn.resourcemanager.ha.rm-ids中（3）如果明确指定了yarn.resourcemanager.ha.id，则每个RM的id来自yarn.resourcemanager.ha.id或者可以通过匹配yarn.resourcemanager.address。&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt; &lt;value&gt;rm1,rm2&lt;/value&gt; &lt;description&gt;启用HA时群集中的RM节点列表。最少2个&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm1&lt;/name&gt; &lt;value&gt;flink-master1:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address.rm2&lt;/name&gt; &lt;value&gt;flink-master2:8088&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt; &lt;value&gt;mycluster-yarn-ha&lt;/value&gt; &lt;description&gt;集群HA的id，用于在ZooKeeper上创建节点，区分使用同一个ZooKeeper集群的不同Hadoop集群&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt; &lt;value&gt;flink-master1&lt;/value&gt; &lt;description&gt;主机名&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt; &lt;value&gt;flink-master2&lt;/value&gt; &lt;description&gt;主机名&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;description&gt;reducer取数据的方式是mapreduce_shuffle&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;2048&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.cpu-vcores&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;discription&gt;每个节点可用cpu&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-mb&lt;/name&gt; &lt;value&gt;512&lt;/value&gt; &lt;discription&gt;单个任务可申请最少内存，默认1024MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;discription&gt;单个任务可申请最大内存，默认8192MB&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt; &lt;value&gt;1&lt;/value&gt; &lt;discription&gt;最小的cores 1 个，默认的就是一个&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.scheduler.minimum-allocation-vcores&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;discription&gt;最多可分配的cores 2 个&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;discription&gt;是否开启聚合日志&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds&lt;/name&gt; &lt;value&gt;-1&lt;/value&gt; &lt;discription&gt;定义NM唤醒上载日志文件的频率。默认值为-1。默认情况下，应用程序完成后将上载日志。通过设置此配置，可以在应用程序运行时定期上载日志。可设置的最小滚动间隔秒数为3600。&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log.server.url&lt;/name&gt; &lt;value&gt;http://flink-master1:19888/jobhistory/logs&lt;/value&gt; &lt;discription&gt; 配置日志服务器的地址&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt; &lt;value&gt;-1&lt;/value&gt; &lt;discription&gt; 在删除聚合日志之前保留多长时间。-1禁用。单位是秒&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.log-dirs&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hadoop/yarn/logs/&lt;/value&gt; &lt;discription&gt;nodemanager存放container日志的本地路径&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.remote-app-log-dir&lt;/name&gt; &lt;value&gt;/tmp/logs&lt;/value&gt; &lt;discription&gt;nodemanager存放container日志的本地路径&lt;/discription&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.am.max-attempts&lt;/name&gt; &lt;value&gt;4&lt;/value&gt; &lt;description&gt;The maximum number of application master execution attempts.&lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt;cd /usr/aboutyun/hadoop/sbin#编辑 start-dfs.sh，stop-dfs.sh 脚本1234567# 在开始处 #!/usr/bin/env bash 的下面，增加以下内容：HDFS_DATANODE_USER=rootHDFS_DATANODE_SECURE_USER=hdfsHDFS_ZKFC_USER=rootHDFS_JOURNALNODE_USER=rootHDFS_NAMENODE_USER=rootHDFS_SECONDARYNAMENODE_USER=root#编辑 start-yarn.sh，stop-yarn.sh 脚本1234# 在开始处 #!/usr/bin/env bash 的下面，增加以下内容：YARN_RESOURCEMANAGER_USER=rootHADOOP_SECURE_DN_USER=yarn YARN_NODEMANAGER_USER=root#启用JournalNode集群hadoop-daemon.sh start journalnode#初始化NameNode(仅master1)hadoop namenode -format#格式化Zookeeper(仅master1)hdfs zkfc -formatZK#启动NameNode(仅master1)hadoop-daemon.sh start namenode#将 NameNode 数据复制到备用 NameNode(仅master2)hdfs namenode -bootstrapStandbyhadoop-daemon.sh start namenode#启动Hadoop集群start-dfs.sh(仅master1)start-yarn.sh(仅master1)yarn-daemon.sh start resourcemanager(仅master2)#监控页面HDFS(master1)HDFS(master2)YARN(master1)YARN(master2)安装mysql仅在Master节点#安装mysqlyum -y install mariadb-server mariadbrpm -q mariadb mariadb-server#设置mysql开机启动systemctl enable mariadbsystemctl daemon-reload#开启mysqlsystemctl start mariadb#关闭mysqlsystemctl stop mariadb#重启mysqlsystemctl restart mariadb#查看mysql状态systemctl status mariadb#通过内置的安全脚本实现对数据库的安全保护mysql_secure_installation#登录root账户mysql -uroot -p#创建账户CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;GRANT ALL ON metastore.* TO &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;#刷新权限flush privileges;安装Hive仅在Master节点cd /mnt/hgfs/aboutyuncp apache-hive-2.2.0-bin.tar.gz /usr/aboutyun/cd /usr/aboutyun/tar zxvf apache-hive-2.2.0-bin.tar.gzrm -rf apache-hive-2.2.0-bin.tar.gzmv apache-hive-2.2.0-bin hive#配置Hive环境变量vim /etc/profile123# SET Hive PATH export HIVE_HOME=/usr/aboutyun/hive export PATH=$PATH:$HIVE_HOME/binsource /etc/profile#配置mysql驱动包cd /mnt/hgfs/aboutyuncp mysql-connector-java-5.1.47.tar.gz /usr/aboutyun/cd /usr/aboutyun/tar zxvf mysql-connector-java-5.1.47.tar.gzrm -rf mysql-connector-java-5.1.47.tar.gzcp mysql-connector-java-5.1.47-bin.jar /usr/aboutyun/hive/lib/#更换jline包（版本不一致）cp hive/lib/jline-2.12.jar /usr/aboutyun/hadoop/share/hadoop/yarn/lib/#配置hivecd hivemkdir -p data/hive/logmkdir -p data/hive/tmpmkdir -p data/hive/warehousecd confcp hive-env.sh.template hive-env.shvim hive-env.sh12345export JAVA_HOME=/usr/aboutyun/jdk export HADOOP_HOME=/usr/aboutyun/hadoop export HIVE_HOME=/usr/aboutyun/hive export HIVE_CONF_DIR=/usr/aboutyun/hive/conf export HIVE_AUX_JARS=/usr/aboutyun/hive/libcp hive-default.xml.template hive-site.xmlvim hive-site.xml123456789101112131415161718192021222324252627282930&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;hive&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;123&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hive/data/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.exec.scratchdir&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hive/data/hive/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/usr/aboutyun/hive/data/hive/log&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;把{system:java.io.tmpdir} 改成 /usr/aboutyun/hive/data/hive/tmp1:%s/$&#123;system:java.io.tmpdir&#125;/\/usr\/aboutyun\/hive\/data\/hive\/tmp/g把 {system:user.name} 改成 {user.name}1:%s/$&#123;system:user.name&#125;/aboutyun/g#初始化hive(MYSQL版)schematool -dbType mysql -initSchema安装Flumecd /mnt/hgfs/aboutyuncp apache-flume-1.9.0-bin.tar.gz /usr/aboutyun/cd /usr/aboutyun/tar zxvf apache-flume-1.9.0-bin.tar.gzrm -rf apache-flume-1.9.0-bin.tar.gzmv apache-flume-1.9.0-bin flumecd flume#Hbase环境变量vim /etc/profile123# SET FLUME PATH export FLUME_HOME=/usr/aboutyun/flume export PATH=$PATH:$FLUME_HOME/binsource /etc/profile#修改Flume配置cd confcp flume-env.sh.template flume-env.shvim flume-env.sh1export JAVA_HOME=/usr/aboutyun/jdk#验证Server12345678# NetCat flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=INFO,console# Exec flume-ng agent --conf conf --conf-file conf/flume-exec.conf --name=agent -Dflume.root.logger=INFO,console# Avro flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=DEBUG,consoleClient12345678# NetCat flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=INFO,console# Exec while true;do echo `date` &gt;&gt; /data/hadoop/flume/test.txt ; sleep 1; done# Avro telnet master 44444安装Kafkacd /mnt/hgfs/aboutyuncp kafka_2.11-0.11.0.3.tgz /usr/aboutyuncd /usr/aboutyuntar zxvf kafka_2.11-0.11.0.3.tgzrm -rf kafka_2.11-0.11.0.3.tgzmv kafka_2.11-0.11.0.3 kafkacd kafka#Kafka环境变量vim /etc/profile123# SET KAFKA PATH export KAFKA_HOME=/usr/aboutyun/kafka export PATH=$PATH:$KAFKA_HOME/binsource /etc/profile#修改Kafka配置mkdir logscd configvim server.properties12345678910111213log.dirs=/usr/aboutyun/kafka/logs zookeeper.connect=flink-slave1:2181,flink-slave2:2181,flink-slave3:2181 #Master1 broker.id=0#Master2 broker.id=1#Slave1 broker.id=2 #Slave2 broker.id=3#Slave3 broker.id=4普通启动：kafka-server-start.sh -daemon /usr/aboutyun/kafka/config/server.properties关闭集群：kafka-server-stop.sh安装Flinkcd /mnt/hgfs/aboutyuncp flink-1.7.2-bin-hadoop27-scala_2.11.tgz /usr/aboutyuncd /usr/aboutyuntar zxvf flink-1.7.2-bin-hadoop27-scala_2.11.tgzrm -rf flink-1.7.2-bin-hadoop27-scala_2.11.tgzmv flink-1.7.2 flinkcd flink#Flink环境变量vim /etc/profile123# SET FLINK PATH export FLINK_HOME=/usr/aboutyun/flink export PATH=$PATH:$FLINK_HOME/binsource /etc/profile#修改Flink配置cd confvim flink-conf.yaml12345678# 修改如下内容jobmanager.rpc.address: flink-master1high-availability: zookeeperhigh-availability.zookeeper.path.root: /flinkhigh-availability.cluster-id: flinkhigh-availability.storageDir: hdfs:///flink/ha/high-availability.zookeeper.quorum: flink-slave1:2181,flink-slave2:2181,flink-slave3:2181yarn.application-attempts: 10vim masters12flink-master1:8081flink-master2:8081vim slaves123flink-slave1 flink-slave2flink-slave3#启动Standalone集群HAstart-cluster.sh#关闭Standalone集群stop-cluster.sh#启动YARN集群HAyarn-session.sh#监控网页Flink(master1)推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn通行证项目前端开发小结拾贝电台开源了]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>项目实战</category>
        <category>Flink电商团购</category>
        <category>01-大数据集群搭建</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Flink</tag>
        <tag>项目</tag>
        <tag>电商</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[傻瓜式CDH集群部署指南]]></title>
    <url>%2Fposts%2F5578f504%2F</url>
    <content type="text"><![CDATA[CDH环境配置单机内存最低8GCloudera集群环境系统CentOS-7-x86_64-Minimal-1810.isocdh-master 192.168.69.111 4core 16Gcdh-slave1 192.168.69.112 4core 8Gcdh-slave2 192.168.69.113 4core 8G关闭防火墙及修改hosts永久关闭内核防火墙/etc/selinux/config]12# 修改如下信息SELINUX=disabled关闭系统防火墙停止firewallsystemctl stop firewalld.service禁止firewall开机启动systemctl disable firewalld.service修改hosts文件/etc/hosts]1234# 添加如下信息192.168.69.111 cdh-master 192.168.69.112 cdh-slave1 192.168.69.113 cdh-slave2SSH互信生成密钥对（公钥和私钥）ssh-keygen -t rsa -P &#39;&#39;追加authorized_keys1234567# 追加authorized_keyscat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keys# 修改权限chmod g-w ~chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys追加密钥到Masterssh cdh-slave1 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keysssh cdh-slave2 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys复制密钥到从节点scp ~/.ssh/authorized_keys cdh-slave1:~/.ssh/authorized_keysscp ~/.ssh/authorized_keys cdh-slave2:~/.ssh/authorized_keysntp时间同步所有节点安装相关ntp组件yum -y install ntp所有节点设置时区timedatectl set-timezone Asia/Shanghai启动ntp，以及设置开机启动12345# 启动ntpsystemctl start ntpd# 设置开机启动systemctl enable ntpd配置ntp服务器(master节点)/etc/ntp.conf]12345678910# 修改如下几行#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 添加如下几行restrict 192.168.69.2 mask 255.255.255.0 nomodify notrapserver 127.127.1.0fudge 127.127.1.0 stratum 10配置ntp服务器(slave节点)/etc/ntp.conf]123456789# 修改如下几行#server 0.centos.pool.ntp.org iburst#server 1.centos.pool.ntp.org iburst#server 2.centos.pool.ntp.org iburst#server 3.centos.pool.ntp.org iburst# 添加如下几行(master节点)restrict 192.168.69.2 mask 255.255.255.0 nomodify notrapserver 192.168.69.111重启ntp服务systemctl restart ntpd主节点定时服务-e]10-59/10 * * * * /usr/sbin/ntpdate -u asia.pool.ntp.org手动同步master的时间ntpdate -u 192.168.69.111查看同步状态ntpstat配置Cloudera rpm仓库下载repo文件sudo wget https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/cloudera-manager.repo -P /etc/yum.repos.d/使用GPG key导入仓库sudo rpm --import https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPM-GPG-KEY-cloudera下载parcel文件mkdir -p /opt/cloudera/parcel-repo/sudo wget https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel /opt/cloudera/parcel-repo/sudo wget https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha256 /opt/cloudera/parcel-repo/sudo wget https://archive.cloudera.com/cdh6/6.2.0/parcels/manifest.json /opt/cloudera/parcel-repo/安装 Java（64-bit）卸载掉自带的 OpenJdkrpm -qa | grep java使用Cloudera Manager 安装 Javasudo yum -y install oracle-j2sdk1.8设置环境变量/etc/profile]1234# SET JAVA PATH export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera/export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib export PATH=$PATH:$JAVA_HOME/binsource /etc/profileyum update报错Error: Delta RPMs disabled because /usr/bin/applydeltarpm not installed.123# 安装deltarpmyum provides '*/applydeltarpm'yum install deltarpm安装Cloudera Manager Server安装Cloudera Manager包sudo yum -y install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-serverPs：可以在https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPMS/x86_64/ 提前下好rpm包进行安装。启用Auto-TLS待续安装和配置数据库MariaDB for Cloudera Software(master节点)安装MariaDBsudo yum -y install mariadb-server配置MariaDB/etc/my.cnf]1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[mysqld]datadir=/var/lib/mysqlsocket=/var/lib/mysql/mysql.socktransaction-isolation = READ-COMMITTED# Disabling symbolic-links is recommended to prevent assorted security risks;# to do so, uncomment this line:symbolic-links = 0# Settings user and group are ignored when systemd is used.# If you need to run mysqld under a different user or group,# customize your systemd unit file for mariadb according to the# instructions in http://fedoraproject.org/wiki/Systemdkey_buffer = 16Mkey_buffer_size = 32Mmax_allowed_packet = 32Mthread_stack = 256Kthread_cache_size = 64query_cache_limit = 8Mquery_cache_size = 64Mquery_cache_type = 1max_connections = 550#expire_logs_days = 10#max_binlog_size = 100M#log_bin should be on a disk with enough free space.#Replace &apos;/var/lib/mysql/mysql_binary_log&apos; with an appropriate path for your#system and chown the specified folder to the mysql user.log_bin=/var/lib/mysql/mysql_binary_log#In later versions of MariaDB, if you enable the binary log and do not set#a server_id, MariaDB will not start. The server_id must be unique within#the replicating group.server_id=1binlog_format = mixedread_buffer_size = 2Mread_rnd_buffer_size = 16Msort_buffer_size = 8Mjoin_buffer_size = 8M# InnoDB settingsinnodb_file_per_table = 1innodb_flush_log_at_trx_commit = 2innodb_log_buffer_size = 64Minnodb_buffer_pool_size = 4Ginnodb_thread_concurrency = 8innodb_flush_method = O_DIRECTinnodb_log_file_size = 512M[mysqld_safe]log-error=/var/log/mariadb/mariadb.logpid-file=/var/run/mariadb/mariadb.pid## include all files from the config directory#!includedir /etc/my.cnf.d启动MariaDB开机启动MariaDBsudo systemctl enable mariadb启动MariaDB服务sudo systemctl start mariadb安全设置/usr/bin/mysql_secure_installation]1234567891011121314151617181920[...]Enter current password for root (enter for none):OK, successfully used password, moving on...[...]Set root password? [Y/n] YNew password: 123Re-enter new password: 123[...]Remove anonymous users? [Y/n] Y[...]Disallow root login remotely? [Y/n] Y[...]Remove test database and access to it [Y/n] Y[...]Reload privilege tables now? [Y/n] Y[...]All done! If you&apos;ve completed all of the above steps, your MariaDBinstallation should now be secure.Thanks for using MariaDB!安装MySQL JDBC Driver for MariaDB下载驱动包wget https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz解压驱动包tar zxvf mysql-connector-java-5.1.46.tar.gzrm -rf mysql-connector-java-5.1.46.tar.gz复制驱动包sudo mkdir -p /usr/share/java/cd mysql-connector-java-5.1.46sudo cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar创建数据库登录root账户mysql -uroot -p创建hive数据库CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;创建账户GRANT ALL ON metastore.* TO &#39;hive&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;GRANT ALL ON scm.* TO &#39;scm&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;GRANT ALL ON oozie.* TO &#39;oozie&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;GRANT ALL ON hue.* TO &#39;hue&#39;@&#39;%&#39; IDENTIFIED BY &#39;123&#39;;刷新权限flush privileges;查看数据库SHOW DATABASES;查看权限SHOW GRANTS FOR &#39;hive&#39;@&#39;%&#39;;设置Cloudera Manager数据库(master节点)设置语法sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm 123准备数据库sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm安装CDH及其他软件[强烈建议]所有节点拍摄快照启动Cloudera Manager Server(master节点)sudo systemctl start cloudera-scm-server查看日志(master节点)sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log直至出现INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.登录web页面http://cdh-master:7180账户：admin密码：admin安装组件接受最终用户许可条款和条件选择Cloudera Express免费版集群安装Cluster BasicsCDHSpecify Hosts输入cdh-master, cdh-slave1, cdh-slave2点击’搜索’选择存储库选择Public Cloudera Repository选择Parcels其他默认JDK 安装选项选中安装 Oracle Java SE 开发工具包 (JDK)设置登录凭据选择root输入密码安装agents安装ParcelsInspect Hosts虚拟内存设置12sysctl -w vm.swappiness=10echo vm.swappiness = 10 &gt;&gt; /etc/sysctl.conf大内存页设置1234567891011# 临时echo never&gt;/sys/kernel/mm/transparent_hugepage/defragecho never&gt;/sys/kernel/mm/transparent_hugepage/enabled# 永久vim /etc/rc.local# 加入如下信息echo never&gt;/sys/kernel/mm/transparent_hugepage/defragecho never&gt;/sys/kernel/mm/transparent_hugepage/enabled# 设置权限chmod +x /etc/rc.d/rc.local组件列表组件版本Supervisord3.0Cloudera Manager Agent6.2.0Cloudera Manager Management Daemon6.2.0Flume NG1.9.0+cdh6.2.0Hadoop3.0.0+cdh6.2.0HDFS3.0.0+cdh6.2.0HttpFS3.0.0+cdh6.2.0hadoop-kms3.0.0+cdh6.2.0MapReduce 23.0.0+cdh6.2.0YARN3.0.0+cdh6.2.0HBase2.1.0+cdh6.2.0Lily HBase Indexer1.5+cdh6.2.0Hive2.1.1+cdh6.2.0HCatalog2.1.1+cdh6.2.0Hue4.2.0+cdh6.2.0Impala3.2.0+cdh6.2.0Java 81.8.0_181Kafka2.1.0+cdh6.2.0Kite（仅限 CDH 5 ）1.0.0+cdh6.2.0kudu1.9.0+cdh6.2.0Oozie5.1.0+cdh6.2.0Parquet1.9.0+cdh6.2.0Pig0.17.0+cdh6.2.0sentry2.1.0+cdh6.2.0Solr7.4.0+cdh6.2.0spark2.4.0+cdh6.2.0Sqoop1.4.7+cdh6.2.0ZooKeeper3.4.5+cdh6.2.0使用向导设置群集选择服务选择所有服务选择HBase HDFS Hive Hue Kafka Oozie YARN(MR2 Included) ZooKeeper自定义角色分配默认数据库设置HiveMySQL &gt; 否 &gt; cdh-master &gt; metastore &gt; hive &gt; 123OozieMySQL &gt; cdh-master &gt; oozie &gt; oozie &gt; 123HueMySQL &gt; cdh-master &gt; hue &gt; hue &gt; 123审核更改默认命令详细信息Ps：若搭建过程中多次尝试安装，建议删除/dfs/nn下文件，避免HDFS服务报错汇总错误排查推荐链接 &gt;&gt; https://blog.csdn.net/zzq900503/article/details/53393721推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>CDH</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>CDH环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十五)：Flink]]></title>
    <url>%2Fposts%2F6cff886e%2F</url>
    <content type="text"><![CDATA[Flink：Storm你该回家了…Flink 安装配置Flink安装Flinkcd /mnt/hgfs/Hadoopcp flink-1.8.0-bin-scala_2.11.tgz /usr/local/src/cd /usr/local/src/tar zxvf flink-1.8.0-bin-scala_2.11.tgzrm -rf flink-1.8.0-bin-scala_2.11.tgzFlink环境变量：vim ~/.bashrc1234# 添加如下信息# SET FLINK PATH export FLINK_HOME=/usr/local/src/flink-1.8.0 export PATH=$PATH:$FLINK_HOME/binsource ~/.bashrc修改Flink配置cd flink-1.8.0/confvim flink-conf.yaml12# 修改如下信息jobmanager.rpc.address: mastervim masters12# 修改如下信息master:8081vim slaves12slave1 slave2启动集群启动服务：start-cluster.sh关闭集群：stop-cluster.sh监控网页：Web：http://master:8081推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Flink</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Flink</tag>
        <tag>Hadoop环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十四)：Storm on Yarn]]></title>
    <url>%2Fposts%2F6a54df13%2F</url>
    <content type="text"><![CDATA[Storm-on-Yarn：跟着老大哥有肉吃…Storm-on-Yarn 安装配置Storm on Yarn待续……推荐文章:Hadoop 集群搭建(八)：SparkFlink电商团购项目（零）：环境搭建]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Storm-on-Yarn</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Storm-on-Yarn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十三)：Storm]]></title>
    <url>%2Fposts%2F9017301c%2F</url>
    <content type="text"><![CDATA[Storm：我才是流处理！Storm 安装配置Storm安装Stormcd /mnt/hgfs/Hadoopcp apache-storm-1.2.2.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf apache-storm-1.2.2.tar.gzrm -rf apache-storm-1.2.2.tar.gzStorm环境变量：vim ~/.bashrc123# SET STORM PATH export STORM_HOME=/usr/local/src/apache-storm-1.2.2 export PATH=$PATH:$STORM_HOME/binsource ~/.bashrc修改Storm配置文件cd apache-storm-1.2.2创建日志文件/数据文件：mkdir datamkdir logs配置文件：cd confvim storm.yaml12345678910111213141516# 添加如下信息storm.zookeeper.servers: - "master" - "slave1" - "slave2" storm.zookeeper.port: 2181 storm.local.dir: "/usr/local/storm-1.2.2/data" ui.port: 8089 nimbus.seeds: ["master"] supervisor.slots.ports: - 6700 - 6701 - 6702 - 6703 - 6704 - 6705启动Storm集群主节点启动：storm nimbus &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/nimbus.out 2&gt;&amp;1 &amp;storm ui &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/ui.out 2&gt;&amp;1 &amp;从节点启动：storm supervisor &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/supervisor.out 2&gt;&amp;1 &amp;storm logviewer &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/logviewer.out 2&gt;&amp;1 &amp;主节点关闭：kill -9 `ps -ef | grep ui.core | awk ‘{print $2}’ | head -n 1kill -9 `ps -ef | grep daemon.nimbus | awk ‘{print $2}’ | head -n 1`kill -9 `ps -ef | grep daemon.supervisor | awk ‘{print $2}’ | head -n 1`kill -9 `ps -ef | grep daemon.logviewer | awk ‘{print $2}’ | head -n 1`WEB监控页面：Web： http://master:8089/index.html推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Storm</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十二)：Kafka]]></title>
    <url>%2Fposts%2Feee41037%2F</url>
    <content type="text"><![CDATA[Kafka：我不是写小说那个…Kafka 安装配置Kafka安装Kafkacd /mnt/hgfs/Hadoopcp kafka_2.11-2.2.0.tgz /usr/local/src/cd /usr/local/src/tar zxvf kafka_2.11-2.2.0.tgzrm -rf kafka_2.11-2.2.0.tgzKafka环境变量：vim ~/.bashrc1234# 添加如下信息# SET KAFKA PATH export KAFKA_HOME=/usr/local/src/kafka_2.11-2.2.0 export PATH=$PATH:$KAFKA_HOME/binsource ~/.bashrc修改Kafka配置cd kafka_2.11-2.2.0创建日志文件：mkdir logs配置文件：cd configvim server.properties123# 添加如下信息log.dirs=/usr/local/src/kafka_2.11-2.2.0/logs zookeeper.connect=master:2181,slave1:2181,slave2:2181仅在Masterbroker.id=0仅在Slave1broker.id=1仅在Slave2broker.id=2启动Kafka集群普通启动：kafka-server-start.sh -daemon /usr/local/src/kafka_2.11-2.2.0/config/server.properties关闭集群：kafka-server-stop.sh推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十一)：Flume]]></title>
    <url>%2Fposts%2F41d58b55%2F</url>
    <content type="text"><![CDATA[Flume：xx托我给您带个话…Flume 安装配置Flume安装Flumecd /mnt/hgfs/Hadoopcp apache-flume-1.9.0-bin.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf apache-flume-1.9.0-bin.tar.gzrm -rf apache-flume-1.9.0-bin.tar.gzHbase环境变量：vim ~/.bashrc1234# 添加如下信息# SET FLUME PATH export FLUME_HOME=/usr/local/src/apache-flume-1.9.0-bin export PATH=$PATH:$FLUME_HOME/binsource ~/.bashrc修改Flume配置cd apache-flume-1.9.0-bin/confcp flume-env.sh.template flume-env.shvim flume-env.sh12# 添加如下信息export JAVA_HOME=/usr/local/src/jdk1.8.0_212新增配置文件NetCat：vim flume-netcat.conf12345678910111213141516171819202122# 添加如下信息# Name the components on this agentagent.sources = r1agent.sinks = k1agent.channels = c1# Describe/configuration the sourceagent.sources.r1.type = netcatagent.sources.r1.bind = 127.0.0.1agent.sources.r1.port = 44444# Describe the sinkagent.sinks.k1.type = logger# Use a channel which buffers events in memoryagent.channels.c1.type = memoryagent.channels.c1.capacity = 1000agent.channels.c1.transactionCapacity = 100# Bind the source and sink to the channelagent.sources.r1.channels = c1agent.sinks.k1.channel = c1Exec：vim flume-exec.conf123456789101112131415161718192021# 添加如下信息# Name the components on this agentagent.sources = r1agent.sinks = k1agent.channels = c1# Describe/configuration the sourceagent.sources.r1.type = execagent.sources.r1.command = tail -f /data/hadoop/flume/test.txt# Describe the sinkagent.sinks.k1.type = logger# Use a channel which buffers events in memoryagent.channels.c1.type = memoryagent.channels.c1.capacity = 1000agent.channels.c1.transactionCapacity = 100# Bind the source and sink to the channelagent.sources.r1.channels = c1agent.sinks.k1.channel = c1Avro：vim flume-avro.conf123456789101112131415161718192021222324# 添加如下信息# Define a memory channel called c1 on agentagent.channels.c1.type = memory# Define an avro source alled r1 on agent and tell itagent.sources.r1.channels = c1agent.sources.r1.type = avroagent.sources.r1.bind = 127.0.0.1agent.sources.r1.port = 44444# Describe/configuration the sourceagent.sinks.k1.type = hdfsagent.sinks.k1.channel = c1agent.sinks.k1.hdfs.path = hdfs://master:9000/flume_data_poolagent.sinks.k1.hdfs.filePrefix = events-agent.sinks.k1.hdfs.fileType = DataStreamagent.sinks.k1.hdfs.writeFormat = Textagent.sinks.k1.hdfs.rollSize = 0agent.sinks.k1.hdfs.rollCount= 600000agent.sinks.k1.hdfs.rollInterval = 600agent.channels = c1agent.sources = r1agent.sinks = k1验证NetCat：# 服务端flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=INFO,console# 客户端flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=INFO,consoleExec：# 服务端flume-ng agent --conf conf --conf-file conf/flume-exec.conf --name=agent -Dflume.root.logger=INFO,console# 客户端Avro：# 服务端flume-ng agent --conf conf --conf-file conf/flume-netcat.conf --name=agent -Dflume.root.logger=DEBUG,console# 客户端telnet master 44444推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Flume</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Flume</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(十)：Thrift]]></title>
    <url>%2Fposts%2F34d202af%2F</url>
    <content type="text"><![CDATA[Thrift：行李少的可以从我这儿走…Thrift 安装配置Thrift安装Thrift仅在Master安装依赖环境：yum -y install automake libtool flex bison pkgconfig gcc-c++ boost-devel libevent-devel zlib-devel python-devel ruby-devel openssl-develyum -y install boost-develyum -y install libevent-devel安装：cd /mnt/hgfs/Hadoopcp thrift-0.12.0.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf thrift-0.12.0.tar.gzrm -rf thrift-0.12.0.tar.gzc++三部曲：cd thrift-0.12.0./configure --with-cpp=no --with-ruby=nomakemake installHbase源码包cd /mnt/hgfs/Hadoopcp hbase-1.3.3-src.tar.gz /usr/local/src/tmpcd /usr/local/src/tmptar zxvf hbase-1.3.3-src.tar.gzmv hbase-1.3.3 hbase-1.3.3-srcrm -rf hbase-1.3.3-src.tar.gzmv hbase-1.3.3-src/ ../待续……推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Thrift</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Thrift</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(九)：Hbase]]></title>
    <url>%2Fposts%2F497b75db%2F</url>
    <content type="text"><![CDATA[Hbase：我不认识Hive…Hbase 安装配置Hbase安装Hbasecd /mnt/hgfs/Hadoopcp hbase-1.3.3-bin.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf hbase-1.3.3-bin.tar.gzrm -rf hbase-1.3.3-bin.tar.gzHbase环境变量：vim ~/.bashrc123456# 添加如下信息# SET HBASE PATH export HBASE_HOME=/usr/local/src/hbase-1.3.3 export HBASE_CLASSPATH=$HBASE_HOME/conf export HBASE_LOG_DIR=$HBASE_HOME/logs export PATH=$PATH:$HBASE_HOME/binsource ~/.bashrc修改Hbase配置cd hbase-1.3.3创建临时目录和文件目录：mkdir logsmkdir tmp配置文件：cd confvim regionservers123# 添加如下信息slave1 slave2vim hbase-env.sh12345# 添加如下信息export JAVA_HOME=/usr/local/src/jdk1.8.0_212 export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib # 禁用Hbase自带独立Zookeeper集群export HBASE_MANAGES_ZK=falsevim hbase-site.xml12345678910111213141516171819202122232425262728# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/src/hbase-1.3.3/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://master:9000/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master,slave1,slave2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/local/src/zookeeper-3.4.14&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.master.info.port&lt;/name&gt; &lt;value&gt;60010&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;启动集群仅在Master启动Hbase服务：start-hbase.sh关闭Hbase服务：stop-hbase.sh推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>HBase</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>HBase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(八)：Spark]]></title>
    <url>%2Fposts%2F55aa9f3f%2F</url>
    <content type="text"><![CDATA[Spark：传说中的星二代Spark 安装配置Spark安装Sparkcd /mnt/hgfs/Hadoopcp spark-2.3.3-bin-hadoop2.7.tgz /usr/local/src/cd /usr/local/src/tar zxvf spark-2.3.3-bin-hadoop2.7.tgzrm -rf spark-2.3.3-bin-hadoop2.7.tgz配置Spark环境变量：vim ~/.bashrc1234# 添加如下信息# SET SPARK PATH export SPARK_HOME=/usr/local/src/spark-2.3.3-bin-hadoop2.7 export PATH=$PATH:$SPARK_HOME/binsource ~/.bashrc修改spark配置文件cd spark-2.3.3-bin-hadoop2.7/confcp spark-env.sh.template spark-env.shvim spark-env.sh123456789# 添加如下信息export SCALA_HOME=/usr/local/src/scala-2.11.12 export JAVA_HOME=/usr/local/src/jdk1.8.0_212 export HADOOP_HOME=/usr/local/src/hadoop-2.8.5 export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181" SPARK_MASTER_IP=master SPARK_LOCAL_DIRS=/usr/local/src/spark-2.3.3-bin-hadoop2.7 SPARK_DRIVER_MEMORY=1Gcp slaves.template slavesvim slaves123# 添加如下信息slave1slave2启动Standalone仅在Master启动集群：cd spark-2.3.3-bin-hadoop2.7/sbin./start-all.shWEB监控页面：Spark：http://master:8080验证cd spark-2.3.3-bin-hadoop2.7本地模式：./bin/run-example SparkPi 10 --master local[2]集群Standlone：./bin/spark-submit --class org.apache.spark.examples.SparkPi --master spark://master:7077 examples/jars/spark-examples_2.11-2.3.3.jar 10Spark on yarn：./bin/spark-submit --class org.apache.spark.examples.SparkPi --master yarn-cluster examples/jars/spark-examples_2.11-2.3.3.jar 10推荐文章:Hadoop 集群搭建(十四)：Storm on YarnFlink电商团购项目（零）：环境搭建]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Spark</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(七)：Hive]]></title>
    <url>%2Fposts%2F9cf82033%2F</url>
    <content type="text"><![CDATA[Hive：不要把我认成HbaseHive 安装配置Hive安装Hive仅在Master 仅在Clientcd /mnt/hgfs/Hadoopcp apache-hive-2.3.4-bin.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf apache-hive-2.3.4-bin.tar.gzrm -rf apache-hive-2.3.4-bin.tar.gz配置Hive环境变量：vim ~/.bashrc1234# 添加如下信息# SET Hive PATH export HIVE_HOME=/usr/local/src/apache-hive-2.3.4-bin export PATH=$PATH:$HIVE_HOME/binsource ~/.bashrc配置mysql驱动包仅在Mastercd /mnt/hgfs/Hadoopcp mysql-connector-java-5.1.47.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf mysql-connector-java-5.1.47.tar.gzrm -rf mysql-connector-java-5.1.47.tar.gzcp mysql-connector-java-5.1.47-bin.jar /usr/local/src/apache-hive-2.3.4-bin/lib/更换jline包（版本不一致）：cp apache-hive-2.3.4-bin/lib/jline-2.12.jar /usr/local/src/hadoop-2.8.5/share/hadoop/yarn/lib/配置hive仅在Master 仅在Clientcd apache-hive-2.3.4-bin创建临时目录/日志目录/数仓目录：mkdir -p data/hive/logmkdir -p data/hive/tmpmkdir -p data/hive/warehouse配置文件：cd confcp hive-env.sh.template hive-env.shvim hive-env.sh123456# 添加如下信息export JAVA_HOME=/usr/local/src/jdk1.8.0_212 export HADOOP_HOME=/usr/local/src/hadoop-2.8.5 export HIVE_HOME=/usr/local/src/apache-hive-2.3.4-bin export HIVE_CONF_DIR=/usr/local/src/apache-hive-2.3.4-bin/conf export HIVE_AUX_JARS=/usr/local/src/apache-hive-2.3.4-bin/libcp hive-default.xml.template hive-site.xmlvim hive-site.xml1234567891011121314151617181920212223242526272829303132# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt; &lt;value&gt;jdbc:mysql://master:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt; &lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt; &lt;value&gt;alessa0&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt; &lt;value&gt;&#123;密码&#125;&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.warehouse.dir&lt;/name&gt; &lt;value&gt;/usr/local/src/apache-hive-2.3.4-bin/data/hive/warehouse&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.exec.scratchdir&lt;/name&gt; &lt;value&gt;/usr/local/src/apache-hive-2.3.4-bin/data/hive/tmp&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.querylog.location&lt;/name&gt; &lt;value&gt;/usr/local/src/apache-hive-2.3.4-bin/data/hive/log&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;把{system:java.io.tmpdir} 改成 /usr/local/src/apache-hive-2.3.4-bin/data/hive/tmp：1:%s/$&#123;system:java.io.tmpdir&#125;/\/usr\/local\/src\/apache-hive-2.3.4-bin\/data\/hive\/tmp/g把 {system:user.name} 改成 {user.name} ：1:%s/$&#123;system:user.name&#125;/alessa0/g初始化hive(MySQL版)schematool -dbType mysql -initSchema配置使用hiveserver2仅在Mastervim hive-site.xml12345678910111213141516171819202122232425262728293031323334# 添加如下信息 &lt;property&gt; &lt;name&gt;hive.server2.thrift.port&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.thrift.bind.host&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.enable.doAs&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.metastore.uris&lt;/name&gt; &lt;value&gt;thrift://master:9083&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.support.concurrency&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.zookeeper.quorum&lt;/name&gt; &lt;value&gt;master:2181,slave1:2181,slave2:2181&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.host&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hive.server2.webui.port&lt;/name&gt; &lt;value&gt;10002&lt;/value&gt; &lt;/property&gt;服务端启动仅在Master启动 metastore 服务 Shellnohup hive --service metastore &gt;&gt; /usr/local/src/apache-hive-2.3.4-bin/logs/hivelog.log 2&gt;&amp;1 &amp;启动 hiveserver2 服务 Shellnohup hiveserver2 1&gt;/usr/local/src/apache-hive-2.3.4-bin/logs/hiveserver.log 2&gt;/usr/local/src/apache-hive-2.3.4-bin/logs/hiveserver.err &amp;测试Web UI：http://master:10002/客户端连接仅在Client启动beeline ： Shellbeeline -u &quot;jdbc:hive2://master:10000&quot; alessa0 1008退出beeline ： Shell!q推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Hive</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Hive</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(六)：MySQL]]></title>
    <url>%2Fposts%2F3f038b9%2F</url>
    <content type="text"><![CDATA[MySQL：我就是个工具人…MySQL 安装配置MySQL安装mysql仅在Master安装mariadb： 开源版MySQLyum -y install mariadb-server mariadbrpm -q mariadb mariadb-server设置开机启动：systemctl enable mariadbsystemctl daemon-reload开启mysql：systemctl start mariadb关闭mysql：systemctl stop mariadb重启mysql：systemctl restart mariadb查看mysql状态：systemctl status mariadb通过内置的安全脚本实现对数据库的安全保护mysql_secure_installation创建Hive账户登录root账户：mysql -uroot -p创建账户：CREATE USER &#39;alessa0&#39;@&#39;%&#39; IDENTIFIED BY &#39;{密码}&#39;;设置mysql远程登录：GRANT ALL ON *.* TO &#39;alessa0&#39;@&#39;%&#39;;刷新权限：flush privileges;推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on YarnMySQL查询MySQL查询]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(五)：Redis]]></title>
    <url>%2Fposts%2F9aff70cb%2F</url>
    <content type="text"><![CDATA[Redis：就是这么快！Redis 安装配置Redis安装rediscd /mnt/hgfs/Hadoopcp redis-5.0.4.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf redis-5.0.4.tar.gzrm -rf redis-5.0.4.tar.gz待续……推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn针对Redis默认端口的挖矿脚本分析Docker 笔记 1：Docker 基础与搭建第一个 Docker 应用栈]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(四)：ZooKeeper]]></title>
    <url>%2Fposts%2F9c5427b6%2F</url>
    <content type="text"><![CDATA[ZooKeeper：你们都安分点…ZooKeeper 安装配置Zookeeper安装Zookeepercd /mnt/hgfs/Hadoopcp zookeeper-3.4.14.tar.gz /usr/local/src/cd /usr/local/srctar zxvf zookeeper-3.4.14.tar.gzrm -rf zookeeper-3.4.14.tar.gz配置Zookeeper环境变量：vim ~/.bashrc1234# 添加如下信息# SET ZOOKEEPER PATH export ZOOKEEPER_HOME=/usr/local/src/zookeeper-3.4.14 export PATH=$PATH:$ZOOKEEPER_HOME/bin`source ~/.bashrc修改Zookeeper配置cd zookeeper-3.4.14创建临时目录/日志目录：mkdir datamkdir logs配置文件：cd confcp zoo_sample.cfg zoo.cfgvim zoo.cfg123456# 添加如下信息dataDir=/usr/local/src/zookeeper-3.4.14/data dataLogDir=/usr/local/src/zookeeper-3.4.14/logs server.1=master:2888:3888 server.2=slave1:2888:3888 server.3=slave2:2888:3888分别添加唯一标识ID：仅在Masterecho &quot;1&quot; &gt; /usr/local/src/zookeeper-3.4.14/data/myid\仅在Slava1echo &quot;2&quot; &gt; /usr/local/src/zookeeper-3.4.14/data/myid\仅在Slava2echo &quot;3&quot; &gt; /usr/local/src/zookeeper-3.4.14/data/myid启动Zookeeper启动服务：zkServer.sh start查看运行状态：zkServer.sh statusjps关闭服务：zkServer.sh stop推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Zookeeper</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(三)：Hadoop]]></title>
    <url>%2Fposts%2F6617c8b9%2F</url>
    <content type="text"><![CDATA[Hadoop：我好了你们再上Hadoop 安装配置HadoopPs：除非特别指出仅在Master，则在所有节点配置# 安装Hadoopcd /mnt/hgfs/Hadoop cp hadoop-2.8.5.tar.gz /usr/local/src/cd /usr/local/src tar zxvf hadoop-2.8.5.tar.gzrm -rf hadoop-2.8.5.tar.gz配置Hadoop环境变量： vim ~/.bashrc12345# 添加如下信息# SET HADOOP PATH export HADOOP_HOME=/usr/local/src/hadoop-2.8.5 export PATH=$PATH:$HADOOP_HOME/bin export PATH=$PATH:$HADOOP_HOME/sbinsource ~/.bashrc# Hadoop配置文件 cd hadoop-2.8.5创建临时目录和文件目录：- mkdir -p /usr/local/src/hadoop-2.8.5/dfs/name- mkdir -p /usr/local/src/hadoop-2.8.5/dfs/data- mkdir -p /usr/local/src/hadoop-2.8.5/tmp/dfscd etc/hadoop仅在Client配置(若无可跳过此步骤)： vim core-site.xml123456789# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定Hadoop所使用的文件系统Schema --&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;mv mapred-site.xml.template mapred-site.xml vim mapred-site.xml123456789# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定MapReduce程序运行在Yarn上 --&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;vim yarn-site.xml123456789# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定ResourceManager地址 --&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;修改Hadoop配置文件： vim hadoop-env.sh12# 添加如下信息export JAVA_HOME=/usr/local/src/jdk1.8.0_212vim yarn-env.sh12# 添加如下信息export JAVA_HOME=/usr/local/src/jdk1.8.0_212vim slaves123# 添加如下信息slave1slave2vim core-site.xml1234567891011121314# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定Hadoop所使用的文件系统Schema --&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定HDFS本地临时存放目录 --&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/local/src/hadoop-2.8.5/tmp&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;vim hdfs-site.xml123456789101112131415161718192021222324# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定SecondaryNamenode端口地址 --&gt; &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; &lt;value&gt;master:9001&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定HDFS本地Namenode存放目录 --&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/src/hadoop-2.8.5/dfs.name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定HDFS本地Datanode存放目录 --&gt; &lt;name&gt;dfs.datanode.name.dir&lt;/name&gt; &lt;value&gt;file:/usr/local/src/hadoop-2.8.5/dfs.data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- HDFS副本数量(小于等于从节点的数量) --&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;*选项卡 1选项卡 2选项卡 3JavaAnaconda3Scalavim mapred-site.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定MapReduce程序运行在Yarn上 --&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;!-- 配置JHS --&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; &lt;value&gt;master:10020&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; &lt;value&gt;master:19888&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.app.mapreduce.am.staging-dir&lt;/name&gt; &lt;value&gt;/usr/local/src/hadoop-2.8.5/tmp/hadoop-yarn/staging&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.intermediate-done-dir&lt;/name&gt; &lt;value&gt;$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done_intermediate&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.done-dir&lt;/name&gt; &lt;value&gt;$&#123;yarn.app.mapreduce.am.staging-dir&#125;/history/done&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.cleaner.enable&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.cleaner.interval-ms&lt;/name&gt; &lt;value&gt;86400000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.max-age-ms&lt;/name&gt; &lt;value&gt;604800000&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;mapreduce.jobhistory.move.interval-ms&lt;/name&gt; &lt;value&gt;180000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;vim yarn-site.xml1234567891011121314151617181920212223242526272829303132333435# 添加如下信息&lt;configuration&gt; &lt;property&gt; &lt;!-- 指定reducer获取数据的方式--&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定reducer获取数据所需的类--&gt; &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;!-- 指定ResourceManager地址 --&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;master:8032&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;master:8030&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;master:8035&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;master:8033&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;master:8088&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt;启动集群仅在Master初始化NameNode：hadoop namenode -format启动Hadoop集群：start-dfs.shstart-yarn.shWEB监控页面：HDFS：http://ip:50070YARN：http://ip:8088推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(二)：语言环境]]></title>
    <url>%2Fposts%2F18e4e892%2F</url>
    <content type="text"><![CDATA[Java, Python, Scala人生苦短Ps：安装包均存放于vmware共享文件夹Hadoop中JavaAnaconda3Scala安装JDKcd /mnt/hgfs/Hadoopcp jdk-8u212-linux-x64.tar.gz /usr/local/src/cd /usr/local/src/tar zxvf jdk-8u212-linux-x64.tar.gzrm -rf jdk-8u212-linux-x64.tar.gz配置JDK环境变量：vim ~/.bashrc12345# 添加如下信息# SET JAVA PATH export JAVA_HOME=/usr/local/src/jdk1.8.0_212 export CLASSPATH=.:$CLASSPATH:$JAVA_HOME/lib export PATH=$PATH:$JAVA_HOME/binsource ~/.bashrc安装anaconda3cd /mnt/hgfs/Hadoopcp Miniconda3-latest-Linux-x86_64.sh /usr/local/src/cd /usr/local/srcsudo yum -y install bzip2sh Miniconda3-latest-Linux-x86_64.shrm -rf Miniconda3-latest-Linux-x86_64.sh配置环境变量：source ~/.bashrc更新conda环境：conda update —all安装Scalacd /mnt/hgfs/Hadoopcp scala-2.11.12.tgz /usr/local/src/cd /usr/local/src/tar zxvf scala-2.11.12.tgzrm -rf scala-2.11.12.tgz配置Scala环境变量：vim ~/.bashrc1234# 添加如下信息# SET SCALA PATH export SCALA_HOME=/usr/local/src/scala-2.11.12 export PATH=$PATH:$SCALA_HOME/binsource ~/.bashrc推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on YarnPython-OpenCV学习笔记——像素读取和写入Python-OpenCV学习笔记——图片写入及图片质量]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>语言</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Java</tag>
        <tag>Python</tag>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop 集群搭建(一)：节点配置]]></title>
    <url>%2Fposts%2Fb7d573f0%2F</url>
    <content type="text"><![CDATA[虚拟机节点配置Hello, BigData集群环境系统：CentOS-7-x86_64-Minimal-1810.isoMaster 192.168.69.101Slave1 192.168.69.102Slave2 192.168.69.103修改IP地址：vim /etc/sysconfig/network-scripts/ifcfg-ens33Master12345# 修改如下信息IPADDR=192.168.69.101 NETMASK=255.255.255.0 GATEWAY=192.168.69.2 DNS1=119.29.29.29仅在Slave112345# 修改如下信息IPADDR=192.168.69.102 NETMASK=255.255.255.0 GATEWAY=192.168.69.2 DNS1=119.29.29.29仅在Slave212345# 修改如下信息IPADDR=192.168.69.103 NETMASK=255.255.255.0 GATEWAY=192.168.69.2 DNS1=119.29.29.29关闭系统防火墙及内核防火墙永久关闭内核防火墙：yum -y install vimvim /etc/selinux/config12# 修改如下信息SELINUX=disabled停止firewall：systemctl stop firewalld.service禁止firewall开机启动：systemctl disable firewalld.service修改主机文件修改主机名：仅在Masterhostnamectl set-hostname master仅在Slave1hostnamectl set-hostname slave1仅在Slave2hostnamectl set-hostname slave2修改hosts文件：vim /etc/hosts123456# 添加如下信息192.168.69.101 master 192.168.69.102 slave1 192.168.69.103 slave2 # 本地(可不加)192.168.69.1 clientSSH互信配置生成密钥对（公钥和私钥）–三次回车生成密钥：ssh-keygen -t rsa -P &#39;&#39;追加：cat ~/.ssh/id_rsa.pub &gt; ~/.ssh/authorized_keyschmod g-w ~chmod 700 ~/.sshchmod 600 ~/.ssh/authorized_keys追加密钥到Master：ssh [ 主机名 ] cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys复制密钥到从节点：scp ~/.ssh/authorized_keys [ 主机名 ]:~/.ssh/authorized_keys设置vmware共享文件夹cd /mnt/hgfs/ 发现没有文件，解决如下安装工具：yum -y install open-vm-tools gcc gcc-c++ automake make kernel-devel git终端中输入如下命令：git clone https://github.com/rasa/vmware-tools-patches.gitcd vmware-tools-patches./patched-open-vm-tools.sh`查看分享目录：vmware-hgfsclientsu临时挂载分享目录：mount.vmhgfs .host:/ /mnt/hgfs/永久挂载分享目录：vmware-config-tools.pl -d --clobber-kernel-modules=vmhgfs#使用如下方法挂载有的会出错：vim /etc/fstab12# 末尾添加如下信息.host:/ /mnt/hgfs fuse.vmhgfs-fuse allow_other 0 0删除工具包cd ~rm -rf ~/vmware-tools-patchesreboot修改src权限cd /usr/localsudo chown -R alessa0:alessa0 srcsudo chown -R alessa0:alessa0 bin更改源为阿里云：cd /etc/yum.repos.d/mv CentOS-Base.repo CentOS-Base.repo.bakwget http://mirrors.aliyun.com/repo/Centos-7.repowget http://mirrors.163.com/.help/CentOS7-Base-163.repoyum clean allyum makecache安装网络工具包和基础工具包：sudo yum -y install net-tools checkpolicy gcc dkms foomatic openssh-server bash-completion psmiscHadoop集群组件列表组件masterslave1slave2jdk1.8.0_212√√√miniconda3√√√scala-2.11.12√√√hadoop-2.8.5√√√redis-5.0.4√zookeeper-3.4.14√√√spark-2.3.3-bin-hadoop2.7√√√mariadb/mariadb-server√apache-hive-2.3.4-bin√hbase-1.3.3√√√thrift-0.12.0√apache-flume-1.9.0-bin√√√kafka_2.11-2.2.0√√√apache-storm-1.2.2√√√Storm-on-Yarn√flink-1.8.0√√√推荐文章:Hadoop 集群搭建(八)：SparkHadoop 集群搭建(十四)：Storm on Yarn]]></content>
      <categories>
        <category>技术</category>
        <category>大数据</category>
        <category>环境搭建</category>
        <category>CentOS 7</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Hadoop环境搭建</tag>
        <tag>Vmware</tag>
      </tags>
  </entry>
</search>
