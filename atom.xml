<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>听泉.ღ</title>
  
  <subtitle>— 听泉小窝 —</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://alessa0.cn/"/>
  <updated>2019-08-05T07:19:19.282Z</updated>
  <id>https://alessa0.cn/</id>
  
  <author>
    <name>Alessa0</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>BigData复习笔记03：推荐算法</title>
    <link href="https://alessa0.cn/posts/c6d1abe8/"/>
    <id>https://alessa0.cn/posts/c6d1abe8/</id>
    <published>2019-07-30T11:51:35.000Z</published>
    <updated>2019-08-05T07:19:19.282Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --><p></p><p class="description">推荐系统</p><br><img src="https://image.alessa0.cn/120137.jpg" alt="kari-shea-Pe97ltx47Lw-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Chapter03. 推荐算法</p></blockquote><h1 id="推荐系统"><a href="#推荐系统" class="headerlink" title="推荐系统"></a>推荐系统</h1><blockquote><p>个性化推荐系统，基于海量数据向用户建议商品</p></blockquote><p>基于数据，利用算法，对用户和商品深度挖掘</p><h2 id="常用推荐算法"><a href="#常用推荐算法" class="headerlink" title="常用推荐算法"></a>常用推荐算法</h2><h3 id="基于人口的推荐"><a href="#基于人口的推荐" class="headerlink" title="基于人口的推荐"></a>基于人口的推荐</h3><blockquote><p>最容易实现</p></blockquote><p>根据用户基本信息发现用户之间的相关程度，将相似用户喜欢的商品推荐给当前用户。</p><p>基本信息包括：<strong>（不包含用户行为信息）</strong></p><ul><li>性别</li><li>年龄</li><li>地域</li><li>……</li></ul><h3 id="基于内容的推荐"><a href="#基于内容的推荐" class="headerlink" title="基于内容的推荐"></a>基于内容的推荐</h3><blockquote><p>Content Based，初期最为广泛使用</p></blockquote><p>根据商品的元信息，利用内容相关性，基于用户以往的喜好，给用户推荐相似的商品</p><h4 id="引入Item属性的CB推荐"><a href="#引入Item属性的CB推荐" class="headerlink" title="引入Item属性的CB推荐"></a>引入Item属性的CB推荐</h4><p>对当前Item进行内容分析，利用属性索引，在数据库中进行相关性计算，取出相关Item推荐给User</p><ul><li>优点<ul><li>提升推荐结果相关性</li><li>结果可解释</li><li>推荐结果易被用户感知</li></ul></li><li>缺点<ul><li>无个性化</li><li>依赖对Item的深度分析</li></ul></li></ul><h4 id="引入User属性的CB推荐"><a href="#引入User属性的CB推荐" class="headerlink" title="引入User属性的CB推荐"></a>引入User属性的CB推荐</h4><p>对当前Item进行内容分析，利用属性索引，结合User行为数据，在数据库中进行相关性计算，取出相关Item推荐给User</p><ul><li>优点<ul><li>用户模型刻画了用户兴趣需求</li><li>推荐形式多样，具有个性化</li><li>结果可解释</li></ul></li><li>缺点<ul><li>推荐精度低</li><li>马太效应<ul><li>解决：试探，加入随机推荐位</li></ul></li><li>用户行为稀疏导致覆盖率低</li></ul></li></ul><p>不同场景选取不同推荐方式</p><h4 id="【Demo】倒排表"><a href="#【Demo】倒排表" class="headerlink" title="【Demo】倒排表"></a>【Demo】倒排表</h4><blockquote><p>对Item进行挖掘，得出Token -&gt; ItemA:ScoreA, ItemB:ScoreB, …倒排表</p></blockquote><ol><li><p>对Item中文分词，得出正排表</p><figure class="highlight python"><figcaption><span>fenci.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">os.system(<span class="string">'tar xvzf jieba.tar.gz &gt; /dev/null'</span>)</span><br><span class="line">sys.path.append(<span class="string">"./"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> jieba</span><br><span class="line"><span class="keyword">import</span> jieba.posseg</span><br><span class="line"><span class="keyword">import</span> jieba.analyse</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    music_id, music_name = ss</span><br><span class="line">    tmp_list = []</span><br><span class="line">    <span class="keyword">for</span> x, w <span class="keyword">in</span> jieba.analyse.extract_tags(music_name, withWeight=<span class="literal">True</span>):</span><br><span class="line">        tmp_list.append((x, float(w)))</span><br><span class="line">    final_list = sorted(tmp_list, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">'\t'</span>.join([music_id, music_name, <span class="string">','</span>.join([<span class="string">':'</span>.join([t_w[<span class="number">0</span>], str(t_w[<span class="number">1</span>])]) <span class="keyword">for</span> t_w <span class="keyword">in</span> final_list])]))</span><br></pre></td></tr></table></figure></li><li><p>转置</p><figure class="highlight python"><figcaption><span>map_inverted.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    music_id = ss[<span class="number">0</span>].strip()</span><br><span class="line">    music_name = ss[<span class="number">1</span>].strip()</span><br><span class="line">    music_token_list = ss[<span class="number">2</span>].strip()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> feature <span class="keyword">in</span> music_token_list.split(<span class="string">','</span>):</span><br><span class="line">        ss = feature.strip().split(<span class="string">':'</span>)</span><br><span class="line">        token = ss[<span class="number">0</span>].strip()</span><br><span class="line">        weight = ss[<span class="number">1</span>].strip()</span><br><span class="line">        print(<span class="string">'\t'</span>.join([token, music_name, weight]))</span><br></pre></td></tr></table></figure></li><li><p>得到倒排表</p><figure class="highlight python"><figcaption><span>red_inverted.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">cur_token = <span class="literal">None</span></span><br><span class="line">m_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    token = ss[<span class="number">0</span>].strip()</span><br><span class="line">    name = ss[<span class="number">1</span>].strip()</span><br><span class="line">    weight = float(ss[<span class="number">2</span>].strip())</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> cur_token <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        cur_token = token</span><br><span class="line">    <span class="keyword">if</span> cur_token != token:</span><br><span class="line">        final_list = sorted(m_list, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">        print(<span class="string">'\t'</span>.join([cur_token, <span class="string">','</span>.join([<span class="string">':'</span>.join([name_weight[<span class="number">0</span>], str(name_weight[<span class="number">1</span>])]) <span class="keyword">for</span> name_weight <span class="keyword">in</span> final_list])]))</span><br><span class="line">        cur_token = token</span><br><span class="line">        m_list = []</span><br><span class="line"></span><br><span class="line">    m_list.append((name, weight))</span><br><span class="line"></span><br><span class="line">final_list = sorted(m_list, key=<span class="keyword">lambda</span> x: x[<span class="number">1</span>], reverse=<span class="literal">True</span>)</span><br><span class="line">print(<span class="string">'\t'</span>.join([cur_token.strip(), <span class="string">','</span>.join([<span class="string">':'</span>.join([name_weight[<span class="number">0</span>], str(name_weight[<span class="number">1</span>])]) <span class="keyword">for</span> name_weight <span class="keyword">in</span> final_list])]))</span><br></pre></td></tr></table></figure></li><li><p>【Hadoop Streaming脚本】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/chapter03/01_inverted/music_meta.txt.small"</span></span><br><span class="line">OUTPUT_PATH_FENCI=<span class="string">"/chapter03/01_inverted/output/python3/fenci"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/chapter03/01_inverted/output/python3/result"</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/chapter03/01_inverted/music_meta.txt.small"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/chapter03/01_inverted"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_FENCI&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=0 \</span><br><span class="line">    -D mapreduce.map.memory.mb=4096 \</span><br><span class="line">    -D mapreduce.job.name=jieba_fenci_demo \</span><br><span class="line">    -files map.py,jieba.tar.gz \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_FENCI&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py"</span> \</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=demo_inverted \</span><br><span class="line">    -files map_inverted.py,red_inverted.py \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_FENCI&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_inverted.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_inverted.py"</span> \</span><br></pre></td></tr></table></figure></li></ol><h3 id="基于协同的推荐"><a href="#基于协同的推荐" class="headerlink" title="基于协同的推荐"></a>基于协同的推荐</h3><p>从User行为日志中挖掘，User与Item关联构成UI矩阵 or IU矩阵</p><p>可使用UI <em>IU得到UU矩阵，使用IU </em>UI得到II矩阵</p><ul><li>优点<ul><li>充分利用群体智慧</li><li>推荐精度高于CB</li><li>利于挖掘隐含的相关性</li></ul></li><li>缺点<ul><li>推荐结果解释性较差</li><li>对时效性强的Item不适用</li><li>冷启动问题</li></ul></li></ul><h4 id="User-Based-CF"><a href="#User-Based-CF" class="headerlink" title="User-Based CF"></a>User-Based CF</h4><blockquote><p>假设：</p><p>用户喜欢那些跟他有相似爱好的用户喜欢的东西</p><p>具有相似兴趣的用户在未来也具有相似兴趣</p></blockquote><h4 id="Item-Based-CF"><a href="#Item-Based-CF" class="headerlink" title="Item-Based CF"></a>Item-Based CF</h4><blockquote><p>假设：</p><p>用户喜欢跟他过去喜欢的物品相似的物品</p><p>历史上相似的物品未来也相似</p></blockquote><div class="table-container"><table><thead><tr><th></th><th>User-Based</th><th>Item-Based</th></tr></thead><tbody><tr><td>性能</td><td>适用于用户较少场合，如果用户多，计算UU矩阵代价太大</td><td>适用于物品数明显小于用户数的场合，物品多。计算II矩阵代价太大</td></tr><tr><td>领域</td><td>时效性强，用户个性化兴趣不太明显的领域</td><td>长尾物品丰富，用户个性化需求强烈的领域</td></tr><tr><td>实时性</td><td>用户有新行为，不一定造成推荐结果立即变化</td><td>用户有新行为，一定导致推荐结果实时变化</td></tr><tr><td>冷启动</td><td>在新用户对很少物品产生行为后，不能立即进行个性化推荐，UU矩阵需要更新。新物品上线后，一旦有用户对物品产生行为，就可以将新物品推荐给兴趣相似的其他用户</td><td>新用户只要对一个物品产生行为，就可以给他推荐和该物品相关的其他物品。在没有更新II矩阵的情况下无法将新物品推荐给用户</td></tr><tr><td>推荐理由</td><td>很难提供令用户信服的推荐解释</td><td>利用用户历史行为给用户做推荐解释，可以令用户比较信服</td></tr></tbody></table></div><h4 id="协同推荐实现方案（以Item-Based为例）"><a href="#协同推荐实现方案（以Item-Based为例）" class="headerlink" title="协同推荐实现方案（以Item-Based为例）"></a>协同推荐实现方案（以Item-Based为例）</h4><h5 id="倒排式"><a href="#倒排式" class="headerlink" title="倒排式"></a>倒排式</h5><ol><li><p>相似度计算公式</p><script type="math/tex;mode=display">\cos (\theta)=\frac{\sum_{k=1}^{n} x_{1 k} x_{2 k}}{\sqrt{\sum_{k=1}^{n} x_{1 k}^{2}} \sqrt{\sum_{k=1}^{n} x_{2 k}^{2}}}</script></li><li><p>处理数据</p><p>格式{user, item, score}</p></li><li><p>构建II矩阵</p><ol><li><p>归一化矩阵</p><ol><li><p>转置UI矩阵 -&gt; IU矩阵</p><figure class="highlight python"><figcaption><span>1_gen_ui_map.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    user, item, score = ss</span><br><span class="line">    print(<span class="string">'%s\t%s\t%s'</span> % (item, user, score))</span><br></pre></td></tr></table></figure></li><li><p>归一化</p><figure class="highlight python"><figcaption><span>1_gen_ui_red.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">cur_item = <span class="literal">None</span></span><br><span class="line">user_score_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    item, user, score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> cur_item <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        cur_item = item</span><br><span class="line">    <span class="keyword">if</span> cur_item != item:</span><br><span class="line">        sum = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> kv <span class="keyword">in</span> user_score_list:</span><br><span class="line">            (u, s) = kv</span><br><span class="line">            sum += pow(s, <span class="number">2</span>)</span><br><span class="line">        sum = math.sqrt(sum)</span><br><span class="line">        <span class="keyword">for</span> kv <span class="keyword">in</span> user_score_list:</span><br><span class="line">            (u, s) = kv</span><br><span class="line">            print(<span class="string">'%s\t%s\t%s'</span> % (u, cur_item, float(s / sum)))</span><br><span class="line">        user_score_list = []</span><br><span class="line">        cur_item = item</span><br><span class="line"></span><br><span class="line">    user_score_list.append((user, float(score)))</span><br><span class="line">sum = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> kv <span class="keyword">in</span> user_score_list:</span><br><span class="line">    (u, s) = kv</span><br><span class="line">    sum += pow(s, <span class="number">2</span>)</span><br><span class="line">sum = math.sqrt(sum)</span><br><span class="line"><span class="keyword">for</span> kv <span class="keyword">in</span> user_score_list:</span><br><span class="line">    (u, s) = kv</span><br><span class="line">    print(<span class="string">'%s\t%s\t%s'</span> % (u, cur_item, float(s / sum)))</span><br></pre></td></tr></table></figure></li></ol></li><li><p>生成II-pair对</p><ol><li><p>标准输入输出</p><figure class="highlight python"><figcaption><span>2_gen_ii_pair_map.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    u, i, s = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">"%s\t%s\t%s"</span> % (u, i, s))</span><br></pre></td></tr></table></figure></li><li><p>生成{item, item, score}</p><figure class="highlight python"><figcaption><span>2_gen_ii_pair_red.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">cur_user = <span class="literal">None</span></span><br><span class="line">item_score_list = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    user, item, score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> cur_user <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        cur_user = user</span><br><span class="line">    <span class="keyword">if</span> cur_user != user:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(item_score_list) - <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(item_score_list)):</span><br><span class="line">                item_a, score_a = item_score_list[i]</span><br><span class="line">                item_b, score_b = item_score_list[j]</span><br><span class="line">                print(<span class="string">'%s\t%s\t%s'</span> % (item_a, item_b, score_a * score_b))</span><br><span class="line">                print(<span class="string">'%s\t%s\t%s'</span> % (item_b, item_a, score_a * score_b))</span><br><span class="line">        item_score_list = []</span><br><span class="line">        cur_user = user</span><br><span class="line">    item_score_list.append((item, float(score)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len(item_score_list) - <span class="number">1</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, len(item_score_list)):</span><br><span class="line">        item_a, score_a = item_score_list[i]</span><br><span class="line">        item_b, score_b = item_score_list[j]</span><br><span class="line">        print(<span class="string">'%s\t%s\t%s'</span> % (item_a, item_b, score_a * score_b))</span><br><span class="line">        print(<span class="string">'%s\t%s\t%s'</span> % (item_b, item_a, score_a * score_b))</span><br></pre></td></tr></table></figure></li></ol></li><li><p>求和</p><ol><li><p>以ii为key做partition</p><figure class="highlight python"><figcaption><span>3_sum_map.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    item_a, item_b, score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    print(<span class="string">"%s\t%s"</span> % (item_a + <span class="string">","</span> + item_b, score))</span><br></pre></td></tr></table></figure></li><li><p>求和</p><figure class="highlight python"><figcaption><span>3_sum_red.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">cur_ii_pair = <span class="literal">None</span></span><br><span class="line">sum = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ii_pair, score = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> cur_ii_pair <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        cur_ii_pair = ii_pair</span><br><span class="line">    <span class="keyword">if</span> cur_ii_pair != ii_pair:</span><br><span class="line">        ii = ii_pair.strip().split(<span class="string">','</span>)</span><br><span class="line">        <span class="keyword">if</span> len(ii) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        item_a, item_b = ii</span><br><span class="line">        print(<span class="string">'%s\t%s\t%s'</span> % (item_a, item_b, sum))</span><br><span class="line">        cur_ii_pair = ii_pair</span><br><span class="line">        sum = <span class="number">0.0</span></span><br><span class="line">    sum += float(score)</span><br><span class="line">ii = cur_ii_pair.strip().split(<span class="string">','</span>)</span><br><span class="line"><span class="keyword">if</span> len(ii) != <span class="number">2</span>:</span><br><span class="line">    sys.exit()</span><br><span class="line">item_a, item_b = ii</span><br><span class="line">print(<span class="string">'%s\t%s\t%s'</span> % (item_a, item_b, sum))</span><br></pre></td></tr></table></figure></li></ol></li><li><p>【Hadoop Streaming脚本】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/chapter03/02_cf/music_uis.data"</span></span><br><span class="line">OUTPUT_PATH_1=<span class="string">"/chapter03/02_cf/item_based/output/python3/step1"</span></span><br><span class="line">OUTPUT_PATH_2=<span class="string">"/chapter03/02_cf/item_based/output/python3/step2"</span></span><br><span class="line">OUTPUT_PATH_3=<span class="string">"/chapter03/02_cf/item_based/output/python3/step3"</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/chapter03/02_cf/music_uis.data"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/chapter03/02_cf"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH_1&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_2&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_3&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.name=step1 \</span><br><span class="line">    -files 1_gen_ui_map.py,1_gen_ui_red.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_1&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python 1_gen_ui_map.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python 1_gen_ui_red.py"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.name=step2 \</span><br><span class="line">    -files 2_gen_ii_pair_map.py,2_gen_ii_pair_red.py \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_1&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_2&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python 2_gen_ii_pair_map.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python 2_gen_ii_pair_red.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.name=step3 \</span><br><span class="line">    -files 3_sum_map.py,3_sum_red.py \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_2&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_3&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python 3_sum_map.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python 3_sum_red.py"</span> \</span><br></pre></td></tr></table></figure></li></ol></li></ol><h3 id="冷启动问题"><a href="#冷启动问题" class="headerlink" title="冷启动问题"></a>冷启动问题</h3><h4 id="用户冷启动"><a href="#用户冷启动" class="headerlink" title="用户冷启动"></a>用户冷启动</h4><ol><li>提供热门排行榜，等用户数据收集到一定程度再切换到个性化推荐</li><li>利用用户注册时提供的年龄、性别等数据做粗粒度的个性化</li><li>利用用户社交网络账号，导入用户在社交网站上的好友信息，然后给用户推荐其好友喜欢的物品</li><li>在用户新登录时要求其对一些物品进行反馈，收集这些兴趣信息，然后给用户推荐相似的物品</li></ol><h4 id="物品冷启动"><a href="#物品冷启动" class="headerlink" title="物品冷启动"></a>物品冷启动</h4><ol><li>把新物品推荐给可能对他感兴趣的用户，利用内容信息，将物品推荐给喜欢过和与其相似的物品的用户</li><li>物品必须能够在第一时间展现给用户，否则一段时间过后，物品的价值就大大降低了</li><li>User-based和Item-based都行不通时，只能利用Content-Based解决该问题，频繁更新相关性数据</li></ol><h4 id="系统冷启动"><a href="#系统冷启动" class="headerlink" title="系统冷启动"></a>系统冷启动</h4><ul><li>引入专家知识，通过一定的高效方式迅速建立起物品的相关性矩阵</li></ul><p><br></p><meting-js id="1346104347" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="http://www.hui-wang.info/2018/01/04/用人工智能为友情链接升级换代/">用人工智能为友情链接升级换代</a></li><li><a href="http://www.hui-wang.info/2017/12/22/安可推荐系统开发笔记（1）/">安可推荐系统开发笔记（1）</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;推荐系统&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/120137.jpg&quot; alt=&quot;kari-shea-Pe97ltx47Lw-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="复习笔记" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="推荐" scheme="https://alessa0.cn/tags/%E6%8E%A8%E8%8D%90/"/>
    
      <category term="Content-Based" scheme="https://alessa0.cn/tags/Content-Based/"/>
    
      <category term="协同" scheme="https://alessa0.cn/tags/%E5%8D%8F%E5%90%8C/"/>
    
  </entry>
  
  <entry>
    <title>BigData复习笔记02：TFIDF, LCS与中文分词</title>
    <link href="https://alessa0.cn/posts/944875b5/"/>
    <id>https://alessa0.cn/posts/944875b5/</id>
    <published>2019-07-24T11:56:32.000Z</published>
    <updated>2019-08-05T07:19:19.304Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --><p></p><p class="description">TF-IDF, LCS, HMM</p><br><img src="https://image.alessa0.cn/122942.jpg" alt="ole-witt-vp7gEXuon08-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Chapter02. 中文分词</p></blockquote><h1 id="NLP文本相似度"><a href="#NLP文本相似度" class="headerlink" title="NLP文本相似度"></a>NLP文本相似度</h1><blockquote><p>文本相似度</p><blockquote><p>语义相似（从人的角度理解语句含义）</p><p>字面相似（中文分词）</p></blockquote></blockquote><h2 id="余弦相似度-向量空间模型"><a href="#余弦相似度-向量空间模型" class="headerlink" title="余弦相似度/向量空间模型"></a>余弦相似度/向量空间模型</h2><h3 id="相似度度量"><a href="#相似度度量" class="headerlink" title="相似度度量"></a>相似度度量</h3><ul><li>计算个体间相似程度</li></ul><h3 id="余弦相似度"><a href="#余弦相似度" class="headerlink" title="余弦相似度"></a>余弦相似度</h3><ul><li>一个向量空间中两个向量夹角的余弦值作为衡量两个个体之间差异的大小</li><li>余弦值接近1，夹角趋于0，表明两个向量越相似</li></ul><script type="math/tex;mode=display">\begin{aligned} \cos (\theta) &=\frac{\sum_{i=1}^{n}\left(x_{i} \times y_{i}\right)}{\sqrt{\sum_{i=1}^{n}\left(x_{i}\right)^{2}} \times \sqrt{\sum_{i=1}^{n}\left(y_{i}\right)^{2}}} \\ &=\frac{a \cdot b}{ \| a| | x| | b| |} \end{aligned}</script><ul><li>案例：<ul><li>步骤0<ul><li>句子A: 这只皮鞋号码大了，那只号码合适</li><li>句子B: 这只皮鞋号码不小，那只更合适</li></ul></li><li>步骤1: 分词<ul><li>句子A: 这只/皮鞋/号码/大了，那只/号码/合适</li><li>句子B: 这只/皮鞋/号码/不/小，那只/更/合适</li></ul></li><li>步骤2: 列出所有词<ul><li>这只, 皮鞋, 号码, 大了, 那只, 合适, 不, 小, 更</li></ul></li><li>步骤3: 计算词频<ul><li>句子A: 这只1, 皮鞋1, 号码2, 大了1, 那只1, 合适1, 不0, 小0, 更0</li><li>句子B: 这只1, 皮鞋1, 号码1, 大了0, 那只1, 合适1, 不1, 小1, 更1</li></ul></li><li>步骤4: 词频向量化<ul><li>句子A: (1, 1, 2, 1, 1, 1, 0, 0, 0)</li><li>句子B: (1, 1, 1, 0, 1, 1, 1, 1, 1)</li></ul></li><li>步骤5: 套公式计算</li></ul></li></ul><script type="math/tex;mode=display">\begin{array}{l}{\cos (\theta)=\frac{1 \times 1+1 \times 1+2 \times 1+1 \times 0+1 \times 1+1 \times 1+0 \times 1+0 \times 1+0 \times 1}{\sqrt{1^{2}+1^{2}+2^{2}+1^{2}+1^{2}+1^{2}+0^{2}+0^{2}+0^{2}+1^{2}+1^{2}+1^{2}+0^{2}+1^{2}+1^{2}+1^{2}+1^{2}+1^{2}}}} \\ {=\frac{6}{\sqrt{7} \times \sqrt{8}}} \\ {=0.81}\end{array}</script><h3 id="文本相似度计算的处理流程"><a href="#文本相似度计算的处理流程" class="headerlink" title="文本相似度计算的处理流程"></a>文本相似度计算的处理流程</h3><ol><li>【依据】<strong>词袋模型</strong>B.O.W</li><li>找出两篇文章的关键词</li><li>每篇文章各取出若干个关键词，合并成一个集合，计算每篇文章对于这个集合中的词的词频</li><li>生成两篇文章各自的词频向量</li><li>计算两个向量的余弦相似度，值越大越相似</li></ol><h2 id="TD-IDF"><a href="#TD-IDF" class="headerlink" title="TD-IDF"></a>TD-IDF</h2><h3 id="词频TF"><a href="#词频TF" class="headerlink" title="词频TF"></a>词频TF</h3><blockquote><p>假设：如果一个词很重要，应该会在文章中多次出现</p></blockquote><ul><li>词频：一个词在文章中出现的次数<ul><li><strong>停用词</strong>：类似“的”, “地”, “得” 对结果毫无帮助，必须过滤掉</li></ul></li></ul><h3 id="反文档频率IDF"><a href="#反文档频率IDF" class="headerlink" title="反文档频率IDF"></a>反文档频率IDF</h3><blockquote><p>假设：如果某个词比较少见，但是它在这篇文章中多次出现，那么它很可能反应了这篇文章的特性，正是我们所需要的关键词</p></blockquote><ul><li>在词频的基础上，赋予每一个词的权重，进一步体现该词的重要性<ul><li>最少见的词（“的”、“是”、“在”）给予最小的权重</li><li>较常见的词（“国内”、“中国”、“报道”）给予较小的权重</li><li>较少见的词（“养殖”、“维基”、”涨停“）</li></ul></li><li>将<strong>TF</strong>和<strong>IDF</strong>进行<strong>相乘</strong>，就得到了一个词的<strong>TF-IDF值</strong>，某个词对文章重要性越高，该值越大，于是排在前面的几个词，就是这篇文章的关键词。</li></ul><h3 id="计算步骤"><a href="#计算步骤" class="headerlink" title="计算步骤"></a>计算步骤</h3><ol><li>【前提】准备<strong>语料库</strong></li><li>计算<strong>TF</strong>：某个词在文章中出现的次数<ul><li>词频标准化（任选一种）<ul><li>TF = 某个词在文章中出现的次数 / <strong>文章的总次数</strong></li><li>TF = 某个词在文章中出现的次数 / <strong>该文章出现次数最多的词的出现次数</strong></li></ul></li></ul></li><li>计算<strong>IDF</strong><ul><li>标准化<ul><li>IDF = <strong>log( 语料库的文档总数 / ( 包含该词的文档数 + 1 ) )</strong></li></ul></li></ul></li><li>计算<strong>TF-IDF</strong><ul><li>TF-IDF = 词频（TF）* 反文档频率（IDF）</li><li>TF-IDF与一个词在文档中的出现次数成<strong>正比</strong>，与包含该词的文档数成<strong>反比</strong></li></ul></li></ol><h3 id="【Demo】判断相似文章"><a href="#【Demo】判断相似文章" class="headerlink" title="【Demo】判断相似文章"></a>【Demo】判断相似文章</h3><ul><li>步骤1: 使用TF-IDF算法，找出两篇文章的关键词</li><li>步骤2: 每篇文章各取出若干个关键词，合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用<strong>相对词频</strong>）</li><li>步骤3: 生成两篇文章各自的词频向量</li><li>步骤4: 计算两个向量的余弦相似度，值越大越相似</li></ul><h3 id="【Demo】自动摘要"><a href="#【Demo】自动摘要" class="headerlink" title="【Demo】自动摘要"></a>【Demo】自动摘要</h3><blockquote><p>文章的信息都包含在句子中，有些句子包含的信息多，有些句子包含的信息少。“自动摘要”就是要找出那些包含信息最多的句子。</p><p>句子的信息量用“关键词”来衡量。如果包含的关键词越多，就说明这个句子越重要。</p><p>只要关键词之间的距离小于“门槛值”，它们就被认为处于同一个簇之中，如果两个关键词之间有超过“门槛值”个数以上的其他词，就可以把这两个关键词分在两个簇。</p><p>下一步，对于每个簇，都计算它的重要性分值。</p><blockquote><p>簇的重要性 = （包含的关键词数量）^2 / 簇的长度</p><blockquote><p>简化：不再区分“簇”，只考虑句子包含的关键词</p></blockquote></blockquote></blockquote><ol><li>确定关键词集合<ul><li>取有限的次数（如Top-10）</li><li>如：按TF-IDF分数 &gt; 0.7截断</li></ul></li><li>找出包含关键词的句子</li><li>把句子做排序，对每个句子划分等级<ul><li>包含关键词越多越重要</li><li>关键词分越高越重要</li></ul></li><li>把等级高的句子取出来，形成摘要</li></ol><ul><li>优点<ul><li>简单快速，结果比较符合实际情况</li></ul></li><li>缺点<ul><li>单纯以“词频”做衡量标准，不够全面，有时重要的词可能出现的次数并不多</li><li>该算法无法体现词的位置信息，出现位置靠前的词与出现位置靠后的词，都被视为重要性相同，这是不正确的<ul><li>解决方法：对全文的第一段和每一段的第一句话给予较大权重。</li></ul></li></ul></li></ul><h3 id="【案例代码】TF-IDF"><a href="#【案例代码】TF-IDF" class="headerlink" title="【案例代码】TF-IDF"></a>【案例代码】TF-IDF</h3><ol><li><p>TF</p><ol><li><p>Map</p><figure class="highlight python"><figcaption><span>map_tf.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">cnt = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    file_name, file_content = ss</span><br><span class="line">    word_list = file_content.strip().split(<span class="string">' '</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word_list:</span><br><span class="line">        cnt += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    file_count = file_name + <span class="string">':'</span> + str(cnt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word_list:</span><br><span class="line">        print(<span class="string">'%s\t%s\t%s'</span> % (file_count, word, <span class="number">1</span>))</span><br><span class="line">    cnt = <span class="number">0</span></span><br></pre></td></tr></table></figure></li><li><p>Reduce</p><figure class="highlight python"><figcaption><span>red_tf.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">current_file = <span class="literal">None</span></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">current_count = <span class="number">0</span></span><br><span class="line">sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    file_count, word, val = ss</span><br><span class="line">    file_name, count = file_count.strip().split(<span class="string">':'</span>)</span><br><span class="line">    <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line">    <span class="keyword">if</span> current_word != word:</span><br><span class="line">        tf = math.log(float(sum) / float(current_count))</span><br><span class="line">        print(<span class="string">'%s\t%s\t%s'</span> % (current_file, current_word, tf))</span><br><span class="line">        current_word = word</span><br><span class="line">        sum = <span class="number">0</span></span><br><span class="line">    sum += int(val)</span><br><span class="line">    current_file = file_name</span><br><span class="line">    current_count = count</span><br><span class="line"></span><br><span class="line">tf = math.log(float(sum) / float(current_count))</span><br><span class="line">print(<span class="string">'%s\t%s\t%s'</span> % (current_file, current_word, tf))</span><br></pre></td></tr></table></figure></li></ol></li><li><p>IDF</p><ol><li><p>Map</p><figure class="highlight python"><figcaption><span>map_idf.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    file_name, file_content = ss</span><br><span class="line">    word_list = file_content.strip().split(<span class="string">' '</span>)</span><br><span class="line"></span><br><span class="line">    word_set = set(word_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> word_set:</span><br><span class="line">        print(<span class="string">'\t'</span>.join([word, <span class="string">'1'</span>]))</span><br></pre></td></tr></table></figure></li><li><p>Reduce</p><figure class="highlight python"><figcaption><span>red_idf.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">docs_cnt = <span class="number">508</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    word, val = ss</span><br><span class="line">    <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line">    <span class="keyword">if</span> current_word != word:</span><br><span class="line">        idf = math.log(float(docs_cnt) / (float(sum) + <span class="number">1.0</span>))</span><br><span class="line">        print(<span class="string">'\t'</span>.join([current_word, str(idf)]))</span><br><span class="line">        current_word = word</span><br><span class="line">        sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    sum += int(val)</span><br><span class="line"></span><br><span class="line">idf = math.log(float(docs_cnt) / (float(sum) + <span class="number">1.0</span>))</span><br><span class="line">print(<span class="string">'\t'</span>.join([current_word, str(idf)]))</span><br></pre></td></tr></table></figure></li></ol></li><li><p>TF-IDF</p><ol><li><p>Map</p><figure class="highlight python"><figcaption><span>map.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#!/usr/bin/python</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span><span class="params">(file)</span>:</span></span><br><span class="line">    word_map = &#123;&#125;</span><br><span class="line">    file_in = open(file, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        word, idf = ss</span><br><span class="line">        word_map[word] = idf</span><br><span class="line">    <span class="keyword">return</span> word_map</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span><span class="params">(white_list_fd)</span>:</span></span><br><span class="line">    word_map = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        file, word, tf = ss</span><br><span class="line">        <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_map.keys()):</span><br><span class="line">            idf = word_map[word]</span><br><span class="line">            tfidf = float(float(tf) + float(idf))</span><br><span class="line">            print(<span class="string">"%s\t%s\t%s"</span> % (file, tfidf, word))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure></li><li><p>Reduce</p><figure class="highlight python"><figcaption><span>red.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">current_file = <span class="literal">None</span></span><br><span class="line">result = <span class="string">''</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">3</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    file, tfidf, word = ss</span><br><span class="line">    <span class="keyword">if</span> current_file <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_file = file</span><br><span class="line">        result = current_file + <span class="string">'\t'</span></span><br><span class="line">    <span class="keyword">if</span> current_file != file:</span><br><span class="line">        print(result[:<span class="number">-1</span>])</span><br><span class="line">        current_file = file</span><br><span class="line">        result = current_file + <span class="string">'\t'</span></span><br><span class="line"></span><br><span class="line">    result += word + <span class="string">':'</span> + tfidf + <span class="string">' '</span></span><br><span class="line">print(result[:<span class="number">-1</span>])</span><br></pre></td></tr></table></figure></li></ol></li><li><p>【Hadoop Streaming脚本】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/chapter02/01_tfidf/tfidf_input.data"</span></span><br><span class="line">OUTPUT_PATH_TF=<span class="string">"/chapter02/01_tfidf/output/python3/tf"</span></span><br><span class="line">OUTPUT_PATH_IDF=<span class="string">"/chapter02/01_tfidf/output/python3/idf"</span></span><br><span class="line">OUTPUT_PATH_TFIDF=<span class="string">"/chapter02/01_tfidf/output/python3/tfidf"</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/chapter02/01_tfidf/tfidf_input.data"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/chapter02/01_tfidf"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH_TF&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH_IDF&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH_TFIDF&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1. tf</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files map_tf.py,red_tf.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_TF&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_tf.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_tf.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2. idf</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map_idf.py,red_idf.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_IDF&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_idf.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_idf.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3. tf-idf</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files map.py,red.py,<span class="string">"hdfs://master:9000/chapter02/01_tfidf/output/python3/idf/part-00000#WH"</span>  \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_TF&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_TFIDF&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span><br></pre></td></tr></table></figure></li></ol><h2 id="LCS"><a href="#LCS" class="headerlink" title="LCS"></a>LCS</h2><blockquote><p>LCS：最长公共子序列(Longest Common Subsequence)</p></blockquote><ul><li>注意区别最长公共子串(Longest Common Substring)<ul><li>最长公共子串要求连续</li></ul></li><li>用于描述两段文字之间的“相似度”<ul><li>辨别抄袭，对一段文字进行修改后，计算改动前后文字的最长公共子序列。将除此子序列外的部分提取出来，用该方法判断修改的部分</li></ul></li><li>可用于推荐结果过滤（相似项目）</li></ul><h3 id="解法1：暴力穷举"><a href="#解法1：暴力穷举" class="headerlink" title="解法1：暴力穷举"></a>解法1：暴力穷举</h3><blockquote><p>假设字符串X, Y长度分别为m, n</p></blockquote><p>X的一个子序列，即下标序列{1, 2, …, m}严格递增子序列</p><ul><li>X共有2^m个不同子序列</li><li>Y共有2^n个不同子序列</li></ul><p><strong>时间复杂度: O(2^m * 2^n)</strong>, 基本不可用</p><h3 id="解法2：动态规划DP"><a href="#解法2：动态规划DP" class="headerlink" title="解法2：动态规划DP"></a>解法2：动态规划DP</h3><script type="math/tex;mode=display">L C S\left(X_{m}, Y_{n}\right)=\left\{\begin{array}{ll}{L C S\left(X_{m-1}, Y_{n-1}\right)+x_{m}} & {x_{m}=y_{n}} \\ {\max \left\{L C S\left(X_{m-1}, Y_{n}\right), L C S\left(X_{m}, Y_{n-1}\right)\right\}} & {x_{m} \neq y_{n}}\end{array}\right.</script><ul><li>使用二维数组C[m, n]</li><li>C[i, j]记录序列Xi和Yj的最长公共子序列的长度<ul><li>当i = 0 或j = 0时，空序列时Xi和Yj的最长公共子序列，故C[i, j] = 0</li></ul></li></ul><script type="math/tex;mode=display">c(i, j)=\left\{\begin{array}{c}{0} & {i = 0\ or \ j = 0} \\ {c(i-1, j-1)+1} & {i > 0,j > 0\ and\ x_{i}=y_{j}} \\ {\max \{c(i-1, j), c(i, j-1)\}} & {i > 0,j > 0\ and\ x_{i} \neq y_{j}} \end{array}\right.</script><h3 id="【案例代码】LCS"><a href="#【案例代码】LCS" class="headerlink" title="【案例代码】LCS"></a>【案例代码】LCS</h3><ol><li><p>Map</p><figure class="highlight python"><figcaption><span>map.py</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_lcs</span><span class="params">(str_1, str_2)</span>:</span></span><br><span class="line">    len_1 = len(str_1.strip())</span><br><span class="line">    len_2 = len(str_2.strip())</span><br><span class="line"></span><br><span class="line">    tmp = max(len_1, len_2) + <span class="number">10</span></span><br><span class="line"></span><br><span class="line">    len_vv = [[<span class="number">0</span>] * tmp] * tmp</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, len_1 + <span class="number">1</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, len_2 + <span class="number">1</span>):</span><br><span class="line">            <span class="keyword">if</span> str_1[i - <span class="number">1</span>] == str_2[j - <span class="number">1</span>]:</span><br><span class="line">                len_vv[i][j] = len_vv[i - <span class="number">1</span>][j - <span class="number">1</span>] + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                len_vv[i][j] = max(len_vv[i - <span class="number">1</span>][j], len_vv[i][j - <span class="number">1</span>])</span><br><span class="line">    <span class="keyword">return</span> float(float(len_vv[len_1][len_2] * <span class="number">2</span>) / float(len_1 + len_2))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    str_1, str_2 = ss</span><br><span class="line"></span><br><span class="line">    cos_score = cal_lcs(str_1, str_2)</span><br><span class="line">    print(<span class="string">'%s\t%s\t%s'</span> % (str_1, str_2, cos_score))</span><br></pre></td></tr></table></figure></li><li><p>【Hadoop Streaming脚本】</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/chapter02/02_lcs/lcs_input.data"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/chapter02/02_lcs/output/python3"</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/chapter02/02_lcs/lcs_input.data"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/chapter02/02_lcs"</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=0 \</span><br><span class="line">    -D mapreduce.job.name=lcs_demo \</span><br><span class="line">    -files map.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py"</span> \</span><br></pre></td></tr></table></figure></li></ol><h1 id="中文分词"><a href="#中文分词" class="headerlink" title="中文分词"></a>中文分词</h1><h2 id="中文分词基础"><a href="#中文分词基础" class="headerlink" title="中文分词基础"></a>中文分词基础</h2><h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><blockquote><p>一段文字不仅仅在于字面上是什么，还在于怎么切分和理解</p></blockquote><p>与英文不同，中文词之间没有空格，所以实现中文搜索引擎，比英文多了项分词的任务</p><ul><li>分词粒度<ul><li>粗粒度：推荐场景</li><li>细粒度：搜索场景（召回候选）</li></ul></li><li>切分方法<ul><li>01bit<ul><li>切开的开始位置对应位是1，否则对应位是0</li><li>“有/意见/分歧”的bit内容是11010</li></ul></li><li>节点序列<ul><li>用分词节点序列表示切分方案</li><li>“有/意见/分歧”的分词节点序列是{0, 1, 3, 5}</li></ul></li><li>基于词典匹配<ul><li>最大长度匹配<ul><li>前向查找</li><li>后向查找（一般效果较好）</li></ul></li></ul></li></ul></li><li>数据结构<ul><li>为了提高查找效率，不要逐个匹配词典中的词</li><li>查找词典所占的时间可能占总的分词时间的1/3左右，为了保证切分速度，需要选择一个好的查找词典方法</li><li>Trie树常用于加速分词查找词典问题</li></ul></li></ul><h3 id="【Demo】Trie树"><a href="#【Demo】Trie树" class="headerlink" title="【Demo】Trie树"></a>【Demo】Trie树</h3><ul><li>正向<ul><li>北京大学生活动中心<ul><li>Root<ul><li>北-京</li><li>北-京-大-学</li><li>大-学-生</li><li>学-生</li><li>生-活</li><li>活-动</li><li>中-心</li></ul></li></ul></li><li>结果：北京大学/生活/动/中心</li></ul></li><li>反向<ul><li>北京大学生活动中心<ul><li>Root<ul><li>心-中</li><li>动-活</li><li>活-生</li><li>生-学</li><li>生-学-大</li><li>学-大-京-北</li><li>京-北</li></ul></li></ul></li><li>结果：北京/大学生/活动/中心</li></ul></li></ul><h3 id="【Demo】DAG词图"><a href="#【Demo】DAG词图" class="headerlink" title="【Demo】DAG词图"></a>【Demo】DAG词图</h3><p>例：广州本田雅阁汽车</p><p>【DAG】：{0: [0, 1, 3], 1: [1], 2: [2, 3, 5], 3: [3], 4: [4, 5], 5: [5], 6: [6, 7], 7: [7]}</p><p><img src="https://image.alessa0.cn/123359.png" alt="DAG"></p><h2 id="概率语言模型"><a href="#概率语言模型" class="headerlink" title="概率语言模型"></a>概率语言模型</h2><blockquote><p>假设需要分出来的词在语料库和词表中都存在，最简单的方法是按词计算概率。</p><p>从统计思想的角度看，分词问题的输入是一个字串C = c1, c2, …, cN，输出是一个词串S = w1, w2, …, wM，其中M &lt;= N。对于一个特定的字符串C，会有多个切分方案S对应，分词的任务就是从不同S中找出一个切分方案，使得P(S|C)值最大。</p><p>P(S|C)就是由字符串C产生切分S的概率，也就是对输入字符串切分出最有可能的词序列。</p><script type="math/tex;mode=display">\operatorname{Seg}(C)=\arg \max _{S \in \mathrm{G}} P(S | C)=\arg \max _{S \in G} \frac{P(C | S) P(S)}{P(C)}</script></blockquote><h3 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h3><blockquote><p>朴素贝叶斯：独立性假设</p></blockquote><h3 id="引例"><a href="#引例" class="headerlink" title="引例"></a>引例</h3><blockquote><p>C：南京市长江大桥</p></blockquote><p>切分方案如下：</p><ul><li>S1：南京市/长江/大桥</li><li>S2：南京/市长/江大桥</li></ul><p>计算条件概率P(S1|C)和P(S2|C)，然后根据P(S1|C)和P(S2|C)的值来决定选择S1还是S2。</p><p>P(C)是字串在语料库中出现的概率。</p><ul><li>为容易实现，假设每个词之间的概率是上下文无关的</li></ul><p>根据<strong>朴素贝叶斯公式</strong></p><blockquote><script type="math/tex;mode=display">P(C \cap S)=P(S | C)^{\star} P(C)=P(C | S)^{\star} P(S)</script></blockquote><p>所以条件概率为</p><script type="math/tex;mode=display">\mathrm{P}(S | C)=\frac{P(C | S) \times P(S)}{P(C)}</script><ul><li>P(C)为常数，只是一个用来归一化的固定值</li><li>在中文分词中，从词串恢复到汉字串仅有唯一的一种方式，所以P(C|S) = 1</li><li>综上所述，比较P(S1|C)和P(S2|C)的大小就可以变成比较P(S1)和P(S2)的大小<ul><li>P(S1) = P(南京市, 长江, 大桥) = P(南京市) <em>P(长江) </em>P(大桥)</li><li>P(S2) = P(南京, 市长, 江大桥) = P(南京) <em>P(市长) </em>P(江大桥)</li><li>P(S1) &gt; P(S2)，选择切分方案S1</li></ul></li></ul><blockquote><script type="math/tex;mode=display">\mathrm{P}(\mathrm{S})=\mathrm{P}\left(\mathrm{w}_{1}, \mathrm{w}_{2}, \ldots, \mathrm{w}_{\mathrm{m}}\right) \approx \mathrm{P}\left(\mathrm{w}_{1}\right) \times \mathrm{P}\left(\mathrm{w}_{2}\right) \times \ldots \times \mathrm{P}\left(\mathrm{w}_{\mathrm{m}}\right) \propto \log \mathrm{P}\left(\mathrm{w}_{1}\right)+\log \mathrm{P}\left(\mathrm{w}_{2}\right)+\ldots+\log \mathrm{P}\left(\mathrm{w}_{\mathrm{m}}\right)</script></blockquote><p>P(w)就是这个词出现在语料库中的概率。因为函数y = log(x)单调递增，因为词的概率小于1，所以取log后结果是负数。</p><ul><li>取log为了防止向下溢出</li><li>结果由乘法转为加法，计算机处理起来速度更快</li></ul><h3 id="一元模型"><a href="#一元模型" class="headerlink" title="一元模型"></a>一元模型</h3><blockquote><p>对于不同的S，M的值都是不一样的，分出的词越多，概率越小（引例）</p></blockquote><script type="math/tex;mode=display">\mathrm{P}(w_{i})=\frac{w_{i}在语料库中的出现次数n}{语料库中的总次数N}</script><p>于是</p><script type="math/tex;mode=display">\log \mathrm{P}\left(\mathrm{w}_{\mathrm{i}}\right)=\log \left(\mathrm{Freq}_{\mathrm{w}}\right)-\log \mathrm{N}</script><p>这个计算公式也叫做<strong>基于一元模型的计算公式</strong>，它综合考虑了切分出的词数和词频</p><h3 id="N元模型"><a href="#N元模型" class="headerlink" title="N元模型"></a>N元模型</h3><blockquote><p>给定一个词猜测下一个词。当给定“NBA”时，下一个词会联想到“篮球”，但不太可能会联想到“足球”</p></blockquote><p><strong>前后两词出现的概率是相互独立的</strong>的假设在实际中是<strong>不成立</strong>的。</p><p>N元模型使用n个单词组成的序列来衡量切分方案的合理性，即概率的链规则。</p><p>P(S) = P(w1, w2, …, wM) = P(w1) <em>P(w2|w1) </em>P(w3|w1, w2) <em>… </em>P(wM|w1, w2, …, wM-1)</p><h2 id="Jieba分词工具"><a href="#Jieba分词工具" class="headerlink" title="Jieba分词工具"></a>Jieba分词工具</h2><blockquote><p>源码地址：<a href="https://github.com/fxsjy/jieba" target="_blank" rel="noopener">https://github.com/fxsjy/jieba</a></p></blockquote><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><h4 id="分词模式"><a href="#分词模式" class="headerlink" title="分词模式"></a>分词模式</h4><ul><li>精确模式：将句子最精确的分开，适合文本分析</li><li>全模式：句子中所有可以成词的词语都扫描出来，速度快，不能解决歧义</li><li>搜索引擎模式：在精确模式的基础上，对长词再次切分，提高召回</li></ul><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><ul><li>语料库：词 + 词频 + 词性</li><li>基于<del><strong>Trie树</strong>结构</del><strong>前缀词典</strong>，使用<strong>前向遍历</strong>实现词图扫描，生成句子中汉字所有可能成词情况所构成的有向无环图DAG<ul><li>Python中实现的trie树是基于dict类型的数据结构而且dict中又嵌套dict 类型，这样嵌套很深，<strong>导致内存耗费严重</strong></li><li>前缀词典储存词语及其前缀，如<code>set([&#39;数&#39;, &#39;数据&#39;, &#39;数据结&#39;, &#39;数据结构&#39;])</code>。在句子中按字正向查找词语，在前缀列表中就继续查找，直到不在前缀列表中或超出句子范围。大约比原词库增加40%词条。</li></ul></li><li>采用<strong>动态规划</strong>DP查找最大概率路径，找出基于词频的最大切分组合</li><li>对于未登录词，基于<strong>二元模型</strong>，采用基于汉字成词能力的<strong>HMM</strong>模型，使用<strong>Viterbi算法</strong></li></ul><h4 id="具体步骤"><a href="#具体步骤" class="headerlink" title="具体步骤"></a>具体步骤</h4><ol><li>给定待分词的句子, 使用正则(re_han)获取匹配的中文字符(和英文字符)切分成的短语列表；</li><li>利用get_DAG(sentence)函数获得待切分句子的DAG，首先检测(check_initialized)进程是否已经加载词库，若未初始化词库则调用initialize函数进行初始化，initialize中判断有无已经缓存的前缀词典cache_file文件，若有相应的cache文件则直接使用 marshal.load 方法加载前缀词典，若无则通过gen_pfdict对指定的词库dict.txt进行计算生成前缀词典，到jieba进程的初始化工作完成后就调用get_DAG获得句子的DAG；</li><li>根据cut_block指定具体的方法(__cut_all,__cut_DAG,__cut_DAG_NO_HMM)对每个短语使用DAG进行分词 ，如cut_block=__cut_DAG时则使用DAG(查字典)和动态规划, 得到最大概率路径, 对DAG中那些没有在字典中查到的字, 组合成一个新的片段短语, 使用HMM模型进行分词, 也就是作者说的识别新词, 即识别字典外的新词；</li><li>使用python的yield 语法生成一个词语生成器, 逐词语返回</li></ol><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">源码地址：</span></span><br><span class="line"><span class="string">https://github.com/ustcdane/annotated_jieba/blob/master/jieba/__init__.py</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># jieba分词的主函数,返回结果是一个可迭代的 generator</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cut</span><span class="params">(self, sentence, cut_all=False, HMM=True)</span>:</span></span><br><span class="line">        <span class="string">'''</span></span><br><span class="line"><span class="string">        The main function that segments an entire sentence that contains</span></span><br><span class="line"><span class="string">        Chinese characters into seperated words.</span></span><br><span class="line"><span class="string">        Parameter:</span></span><br><span class="line"><span class="string">            - sentence: The str(unicode) to be segmented.</span></span><br><span class="line"><span class="string">            - cut_all: Model type. True for full pattern, False for accurate pattern.</span></span><br><span class="line"><span class="string">            - HMM: Whether to use the Hidden Markov Model.</span></span><br><span class="line"><span class="string">        '''</span></span><br><span class="line">        sentence = strdecode(sentence) <span class="comment"># 解码为unicode</span></span><br><span class="line">        <span class="comment"># 不同模式下的正则</span></span><br><span class="line">        <span class="keyword">if</span> cut_all:</span><br><span class="line">            re_han = re_han_cut_all</span><br><span class="line">            re_skip = re_skip_cut_all</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            re_han = re_han_default</span><br><span class="line">            re_skip = re_skip_default</span><br><span class="line"></span><br><span class="line">         <span class="comment"># 设置不同模式下的cut_block分词方法</span></span><br><span class="line">        <span class="keyword">if</span> cut_all:</span><br><span class="line">            cut_block = self.__cut_all</span><br><span class="line">        <span class="keyword">elif</span> HMM:</span><br><span class="line">            cut_block = self.__cut_DAG</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cut_block = self.__cut_DAG_NO_HMM</span><br><span class="line">        <span class="comment"># 先用正则对句子进行切分</span></span><br><span class="line">        blocks = re_han.split(sentence)</span><br><span class="line">        <span class="keyword">for</span> blk <span class="keyword">in</span> blocks:</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> blk:</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="keyword">if</span> re_han.match(blk): <span class="comment"># re_han匹配的串</span></span><br><span class="line">                <span class="keyword">for</span> word <span class="keyword">in</span> cut_block(blk):<span class="comment"># 根据不同模式的方法进行分词</span></span><br><span class="line">                    <span class="keyword">yield</span> word</span><br><span class="line">            <span class="keyword">else</span>:<span class="comment"># 按照re_skip正则表对blk进行重新切分</span></span><br><span class="line">                tmp = re_skip.split(blk)<span class="comment"># 返回list</span></span><br><span class="line">                <span class="keyword">for</span> x <span class="keyword">in</span> tmp:</span><br><span class="line">                    <span class="keyword">if</span> re_skip.match(x):</span><br><span class="line">                        <span class="keyword">yield</span> x</span><br><span class="line">                    <span class="keyword">elif</span> <span class="keyword">not</span> cut_all: <span class="comment"># 精准模式下逐个字符输出</span></span><br><span class="line">                        <span class="keyword">for</span> xx <span class="keyword">in</span> x:</span><br><span class="line">                            <span class="keyword">yield</span> xx</span><br><span class="line">                    <span class="keyword">else</span>: </span><br><span class="line">                        <span class="keyword">yield</span> x</span><br></pre></td></tr></table></figure><p><img src="https://image.alessa0.cn/140354.png" alt="jieba"></p><h4 id="前缀词典"><a href="#前缀词典" class="headerlink" title="前缀词典"></a>前缀词典</h4><blockquote><p>对应代码中Tokenizer.FREQ字典</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gen_pfdict</span><span class="params">(self, f_name)</span>:</span></span><br><span class="line">    lfreq = &#123;&#125; <span class="comment"># 字典存储  词条:出现次数</span></span><br><span class="line">    ltotal = <span class="number">0</span> <span class="comment"># 所有词条的总的出现次数</span></span><br><span class="line">    <span class="keyword">with</span> open(f_name, <span class="string">'rb'</span>) <span class="keyword">as</span> f: <span class="comment"># 打开文件 dict.txt </span></span><br><span class="line">        <span class="keyword">for</span> lineno, line <span class="keyword">in</span> enumerate(f, <span class="number">1</span>): <span class="comment"># 行号,行</span></span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                line = line.strip().decode(<span class="string">'utf-8'</span>) <span class="comment"># 解码为Unicode</span></span><br><span class="line">                word, freq = line.split(<span class="string">' '</span>)[:<span class="number">2</span>] <span class="comment"># 获得词条 及其出现次数</span></span><br><span class="line">                freq = int(freq)</span><br><span class="line">                lfreq[word] = freq</span><br><span class="line">                ltotal += freq</span><br><span class="line">                <span class="keyword">for</span> ch <span class="keyword">in</span> xrange(len(word)):<span class="comment"># 处理word的前缀</span></span><br><span class="line">                    wfrag = word[:ch + <span class="number">1</span>]</span><br><span class="line">                    <span class="keyword">if</span> wfrag <span class="keyword">not</span> <span class="keyword">in</span> lfreq: <span class="comment"># word前缀不在lfreq则其出现频次置0 </span></span><br><span class="line">                        lfreq[wfrag] = <span class="number">0</span></span><br><span class="line">            <span class="keyword">except</span> ValueError:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(</span><br><span class="line">                    <span class="string">'invalid dictionary entry in %s at Line %s: %s'</span> % (f_name, lineno, line))</span><br><span class="line">    <span class="keyword">return</span> lfreq, ltotal</span><br></pre></td></tr></table></figure><h4 id="DAG"><a href="#DAG" class="headerlink" title="DAG"></a>DAG</h4><blockquote><p>对一个sentence DAG是以{key:list[i,j…], …}的字典结构存储, key是词的在sentence中的位置, list存放的是sentence中以位置key开始的可能的词语的结束位置.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DAG中是以&#123;key:list,...&#125;的字典结构存储</span></span><br><span class="line"><span class="comment"># key是字的开始位置</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_DAG</span><span class="params">(self, sentence)</span>:</span></span><br><span class="line">    self.check_initialized()</span><br><span class="line">    DAG = &#123;&#125;</span><br><span class="line">    N = len(sentence)</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> xrange(N):</span><br><span class="line">        tmplist = []</span><br><span class="line">        i = k</span><br><span class="line">        frag = sentence[k]</span><br><span class="line">        <span class="keyword">while</span> i &lt; N <span class="keyword">and</span> frag <span class="keyword">in</span> self.FREQ:</span><br><span class="line">            <span class="keyword">if</span> self.FREQ[frag]:</span><br><span class="line">                tmplist.append(i)</span><br><span class="line">            i += <span class="number">1</span></span><br><span class="line">            frag = sentence[k:i + <span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> tmplist:</span><br><span class="line">            tmplist.append(k)</span><br><span class="line">        DAG[k] = tmplist</span><br><span class="line">    <span class="keyword">return</span> DAG</span><br></pre></td></tr></table></figure><h4 id="基于词频最大切分组合"><a href="#基于词频最大切分组合" class="headerlink" title="基于词频最大切分组合"></a>基于词频最大切分组合</h4><blockquote><p>有了词库(dict.txt)的前缀字典和待分词句子sentence的DAG，使用动态规划方法，从后往前遍历，选择一个频度得分最大的一个切分组合。</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#动态规划，计算最大概率的切分组合</span></span><br><span class="line">   <span class="function"><span class="keyword">def</span> <span class="title">calc</span><span class="params">(self, sentence, DAG, route)</span>:</span></span><br><span class="line">       N = len(sentence)</span><br><span class="line">       route[N] = (<span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">        <span class="comment"># 对概率值取对数之后的结果(可以让概率相乘的计算变成对数相加,防止相乘造成下溢)</span></span><br><span class="line">       logtotal = log(self.total)</span><br><span class="line">       <span class="comment"># 从后往前遍历句子 反向计算最大概率</span></span><br><span class="line">       <span class="keyword">for</span> idx <span class="keyword">in</span> xrange(N - <span class="number">1</span>, <span class="number">-1</span>, <span class="number">-1</span>):</span><br><span class="line">          <span class="comment"># 列表推倒求最大概率对数路径</span></span><br><span class="line">          <span class="comment"># route[idx] = max([ (概率对数，词语末字位置) for x in DAG[idx] ])</span></span><br><span class="line">          <span class="comment"># 以idx:(概率对数最大值，词语末字位置)键值对形式保存在route中</span></span><br><span class="line">          <span class="comment"># route[x+1][0] 表示 词路径[x+1,N-1]的最大概率对数,</span></span><br><span class="line">          <span class="comment"># [x+1][0]即表示取句子x+1位置对应元组(概率对数，词语末字位置)的概率对数</span></span><br><span class="line">           route[idx] = max((log(self.FREQ.get(sentence[idx:x + <span class="number">1</span>]) <span class="keyword">or</span> <span class="number">1</span>) -</span><br><span class="line">                             logtotal + route[x + <span class="number">1</span>][<span class="number">0</span>], x) <span class="keyword">for</span> x <span class="keyword">in</span> DAG[idx])</span><br></pre></td></tr></table></figure><blockquote><p>例：广州本田雅阁汽车</p></blockquote><ul><li>P(车) = -8.80006921905【语料库“车”词频取log】</li><li>P(汽) = -12.897543648【语料库“汽”词频取log】</li><li>P(汽车) = -8.78007494718【语料库“汽车”词频取log】</li><li>P(汽车) &gt; P(汽) + P(车)，所以Route概率使用P(汽车)</li><li>……</li></ul><figure class="highlight gcode"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Route: &#123;<span class="number">0</span>: <span class="comment">(-33.271126717488308, 1)</span>,</span><br><span class="line">        <span class="number">1</span>: <span class="comment">(-32.231489259807965, 1)</span>,</span><br><span class="line">        <span class="number">2</span>: <span class="comment">(-23.899234625632083, 5)</span>,</span><br><span class="line">        <span class="number">3</span>: <span class="comment">(-31.523246813843940, 3)</span>,</span><br><span class="line">        <span class="number">4</span>: <span class="comment">(-22.214895405024865, 5)</span>,</span><br><span class="line">        <span class="number">5</span>: <span class="comment">(-19.008467873683230, 5)</span>,</span><br><span class="line">        <span class="number">6</span>: <span class="comment">(-8.7800749471799175, 7)</span>,</span><br><span class="line">        <span class="number">7</span>: <span class="comment">(-8.8000692190498415, 7)</span>,</span><br><span class="line">        <span class="number">8</span>: <span class="comment">(0.0, '')</span>&#125;</span><br></pre></td></tr></table></figure><p><img src="https://image.alessa0.cn/143320.png" alt="route"></p><h3 id="隐马尔可夫模型HMM"><a href="#隐马尔可夫模型HMM" class="headerlink" title="隐马尔可夫模型HMM"></a>隐马尔可夫模型HMM</h3><h4 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h4><blockquote><p>一个随机过程模型，它表述了一系列可能的事件，在这个系列当中每一个事件的概率仅依赖于前一个事件。</p></blockquote><ul><li>参数<ul><li><strong>状态</strong>：由数字表示，假设共有M个</li><li><strong>初始概率</strong>：$\pi<em>{k}=P\left(S</em>{1}=k\right) \quad \mathrm{k}=1,2, \ldots, \mathrm{M}$</li><li><strong>状态转移概率</strong>：$a<em>{k, l}=P\left(S</em>{t+1}=l | S_{t}=k\right) \quad \mathrm{k}, 1=1,2, \ldots, \mathrm{M}$</li></ul></li></ul><p><img src="https://image.alessa0.cn/011258.png" alt="马尔可夫"></p><ul><li>例子：<strong>天气</strong><ul><li>状态：{晴天, 雨天, 多云, ……}</li><li>初始概率：P(晴天), P(雨天), ……</li><li>状态转移概率：P(晴天|雨天), P(雨天|多云), ……</li></ul></li><li><p>参数估计</p><ul><li>最大似然法<ul><li><strong>初始概率</strong>：P(S1 = k) = (k作为序列开始的次数) / (观测序列总数)</li><li><strong>状态转移概率</strong>：P(St + 1 = l |St = k) = (l紧跟k出现的次数) / (k出现的总次数)</li></ul></li></ul></li><li><p><strong>小结</strong></p><ul><li>马尔可夫链是对一个序列数据建模</li></ul></li></ul><h4 id="隐马尔可夫模型"><a href="#隐马尔可夫模型" class="headerlink" title="隐马尔可夫模型"></a>隐马尔可夫模型</h4><p>HMM 是一个<strong>关于时序的概率模型</strong>，它的<strong>变量分为两组</strong>：</p><ul><li>状态变量 (隐变量)：由马尔可夫链随机生成</li><li>观测变量 ：状态序列每个状态对应生成一个观测结果</li></ul><p>状态变量和观测变量各自都是一个时间序列，每个状态/观测值都和一个时刻相对应</p><blockquote><p><strong>假设1</strong>：假设隐藏的马尔可夫链在任意时刻 tt 的状态只依赖于前一个时刻（t − 1时）的状态，与其他时刻的状态及观测无关，也与时刻 t 无关。</p><p><strong>假设2</strong>：假设任意时刻的观测只依赖于该时刻的马尔可夫链状态，与其他观测及状态无关。</p></blockquote><ul><li><p>参数</p><ul><li><p>状态：由数字表示，假设共有M个，状态序列S</p></li><li><p><strong>观测</strong>：由数字表示，假设共有N个，观测序列O</p></li><li><p>状态转移概率：$由a_{k, l}表示, 通常记作矩阵A$</p></li><li><p><strong>发射概率</strong>：$b<em>{k}(u)=\mathrm{P}\left(O</em>{t}=u | S_{t}=k\right) \quad u=1,2, \ldots, N ; k=1,2, \dots, M, 通常记作矩阵B$</p></li><li><p>初始概率：$由\pi_{k}表示$</p></li></ul></li></ul><p><img src="https://image.alessa0.cn/135221.png" alt="HMM"></p><h5 id="HMM解决三类问题"><a href="#HMM解决三类问题" class="headerlink" title="HMM解决三类问题"></a>HMM解决三类问题</h5><ul><li><p>概率计算问题（又称评价问题）</p><ul><li><p>已知：</p><ul><li>模型$\lambda=[A, B, \pi]$</li><li>观测序列O</li></ul></li><li><p>求解：</p><ul><li>给定观测序列，求它和评估模型之间的匹配度$P(O | \lambda)$</li></ul></li><li>方案：<ul><li>前向-后向算法</li></ul></li></ul></li><li><p>预测问题（又称解码问题）</p><ul><li>已知：<ul><li>模型$\lambda=[A, B, \pi]$</li><li>观测序列O</li></ul></li><li>求解：<ul><li>给定观测序列，求最有可能与之对应的状态序列S</li></ul></li><li>方案：<ul><li>Viterbi算法</li></ul></li></ul></li><li><p>学习问题（又称训练问题）</p><ul><li>已知：<ul><li>观测序列O</li><li>或许会给与之对应的状态序列S</li></ul></li><li>求解：<ul><li>训练模型$\lambda=[A, B, \pi]$，使其$P(O | \lambda)$最大，最好地描述观测数据</li></ul></li><li>方案：<ul><li>有监督/无监督</li></ul></li></ul></li></ul><blockquote><p>相关文章：<a href="http://www.52nlp.cn/hmm相关文章索引" target="_blank" rel="noopener">52nlp</a></p></blockquote><h4 id="Jieba-HMM"><a href="#Jieba-HMM" class="headerlink" title="Jieba HMM"></a>Jieba HMM</h4><ul><li><p>参数</p><ul><li>初始概率<ul><li>BEMS位置信息</li><li>词性</li><li>例: {(‘B’, ‘mq’): -6.78695300139688, ……}</li></ul></li><li>转移概率<ul><li>例: {(‘B’, ‘ad’): {(‘E’, ‘ad’): -0.0007479013978476627}, ……}</li></ul></li><li>发射概率<ul><li>例: {(‘B’, ‘df’): {u’不’: 0.0}……}</li></ul></li></ul></li><li><p>Viterbi算法实现</p></li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#状态转移矩阵，比如B状态前只可能是E或S状态  </span></span><br><span class="line">PrevStatus = &#123;  </span><br><span class="line">    <span class="string">'B'</span>:(<span class="string">'E'</span>,<span class="string">'S'</span>),  </span><br><span class="line">    <span class="string">'M'</span>:(<span class="string">'M'</span>,<span class="string">'B'</span>),  </span><br><span class="line">    <span class="string">'S'</span>:(<span class="string">'S'</span>,<span class="string">'E'</span>),  </span><br><span class="line">    <span class="string">'E'</span>:(<span class="string">'B'</span>,<span class="string">'M'</span>)  </span><br><span class="line">&#125;  </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">viterbi</span><span class="params">(obs, states, start_p, trans_p, emit_p)</span>:</span></span><br><span class="line">    V = [&#123;&#125;]  <span class="comment"># 状态概率矩阵  </span></span><br><span class="line">    path = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> states:  <span class="comment"># 初始化状态概率</span></span><br><span class="line">        V[<span class="number">0</span>][y] = start_p[y] + emit_p[y].get(obs[<span class="number">0</span>], MIN_FLOAT)</span><br><span class="line">        path[y] = [y] <span class="comment"># 记录路径</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> xrange(<span class="number">1</span>, len(obs)):</span><br><span class="line">        V.append(&#123;&#125;)</span><br><span class="line">        newpath = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> y <span class="keyword">in</span> states:</span><br><span class="line">            em_p = emit_p[y].get(obs[t], MIN_FLOAT)</span><br><span class="line">            <span class="comment"># t时刻状态为y的最大概率(从t-1时刻中选择到达时刻t且状态为y的状态y0)</span></span><br><span class="line">            (prob, state) = max([(V[t - <span class="number">1</span>][y0] + trans_p[y0].get(y, MIN_FLOAT) + em_p, y0) <span class="keyword">for</span> y0 <span class="keyword">in</span> PrevStatus[y]])</span><br><span class="line">            V[t][y] = prob</span><br><span class="line">            newpath[y] = path[state] + [y] <span class="comment"># 只保存概率最大的一种路径 </span></span><br><span class="line">        path = newpath </span><br><span class="line">    <span class="comment"># 求出最后一个字哪一种状态的对应概率最大，最后一个字只可能是两种情况：E(结尾)和S(独立词)  </span></span><br><span class="line">    (prob, state) = max((V[len(obs) - <span class="number">1</span>][y], y) <span class="keyword">for</span> y <span class="keyword">in</span> <span class="string">'ES'</span>)</span><br></pre></td></tr></table></figure><p><br></p><meting-js id="525086802" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;TF-IDF, LCS, HMM&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/122942.jpg&quot; alt=&quot;ole-witt-vp7gEXuon08-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="复习笔记" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="TF-IDF" scheme="https://alessa0.cn/tags/TF-IDF/"/>
    
      <category term="LCS" scheme="https://alessa0.cn/tags/LCS/"/>
    
      <category term="HMM" scheme="https://alessa0.cn/tags/HMM/"/>
    
      <category term="中文分词" scheme="https://alessa0.cn/tags/%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D/"/>
    
  </entry>
  
  <entry>
    <title>BigData复习笔记01：HDFS1.0与MapReduce</title>
    <link href="https://alessa0.cn/posts/34c278f3/"/>
    <id>https://alessa0.cn/posts/34c278f3/</id>
    <published>2019-07-17T13:22:29.000Z</published>
    <updated>2019-08-05T07:19:19.306Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --><p></p><p class="description">HDFS1.0与MapReduce</p><br><img src="https://image.alessa0.cn/124000.jpg" alt="troy-t-9sQgt_cR50c-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Chapter01. MapReduce &amp; HDFS1.0</p></blockquote><h1 id="海量数据分流处理技术"><a href="#海量数据分流处理技术" class="headerlink" title="海量数据分流处理技术"></a>海量数据分流处理技术</h1><blockquote><p>分而治之</p></blockquote><ul><li><p>大数据量</p><ul><li>早期搜索引擎的网页存储系统，单机存储数千万网页，几十亿的网页需要通过几百台单机服务器存储，url为Key</li><li>分布式文件系统，按Block(64M-256M)来划分组织文件<ul><li>稳定性</li><li>容错能力</li><li>数据一致性</li></ul></li></ul></li><li><p>大流量</p><ul><li>覆盖的大流量互联网服务</li><li>南方流量分到电信机房，北方流量分到联通机房</li><li>搜索引擎将query作为Key来分流</li></ul></li><li><p>大计算</p><ul><li>根据输入数据划分计算任务</li><li>MapReduce 按输入数据来划分</li></ul></li></ul><h2 id="传统Hash方法"><a href="#传统Hash方法" class="headerlink" title="传统Hash方法"></a>传统Hash方法</h2><blockquote><p>如何将大数据流量均分到N台服务器，做到负载均衡？</p></blockquote><p>思路：</p><ul><li><p>找到合理的Key，<strong>Hash(Key)</strong>尽量分布均匀</p><ul><li><p>Hash(Key) mod N == 0 分到第 0 台</p></li><li><p>Hash(Key) mod N == 1 分到第 1 台</p></li><li><p>……</p></li><li><p>Hash(Key) mod N == i 分到第 i 台</p></li><li><p>……</p></li><li><p>Hash(Key) mod N == N - 1 分到第N - 1台</p></li></ul></li><li><p>一般以<strong>时间戳</strong>为Key</p></li></ul><h2 id="随机划分"><a href="#随机划分" class="headerlink" title="随机划分"></a>随机划分</h2><h2 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h2><blockquote><p>支持动态增长， 更高级的划分方法，解决热点(Hot spot)问题</p></blockquote><p>案例：</p><ul><li>服务器A承压50%</li><li>服务器B承压30%</li><li>服务器C承压20%</li></ul><p>如图，用户按Hash(Key)顺时针访问不同服务器。</p><ul><li><p>若服务器B挂掉，则</p><ul><li><p>服务器B承压30% * 5/7 -&gt; 交付服务器A</p></li><li><p>服务器B承压30% * 2/7 -&gt; 交付服务器C</p></li></ul></li></ul><p><img src="https://image.alessa0.cn/150046.png" alt="一致性Hash"></p><h1 id="MapReduce"><a href="#MapReduce" class="headerlink" title="MapReduce"></a>MapReduce</h1><blockquote><p>用于处理海量数据的<strong>分布式</strong>计算框架</p></blockquote><h2 id="前提：分布式存储架构"><a href="#前提：分布式存储架构" class="headerlink" title="前提：分布式存储架构"></a>前提：分布式存储架构</h2><p>角色：</p><ul><li>Master</li><li>Slave</li><li>Client</li></ul><p><img src="https://image.alessa0.cn/062837.png" alt="GFS存储"></p><h2 id="MapReduce基本思想"><a href="#MapReduce基本思想" class="headerlink" title="MapReduce基本思想"></a>MapReduce基本思想</h2><blockquote><p>分而治之</p><blockquote><p>分解 &gt;&gt; 求解 &gt;&gt; 合并</p></blockquote></blockquote><p>案例Demo：分面值数钞票</p><ul><li><p>方式1: 单点策略</p><ul><li>一个人数出所有的钞票，数出各面值各有多少张</li></ul></li><li><p>方式2: 分治策略</p><ul><li>每个人分得一部分钞票，数出各面值有多少张</li><li>汇总，每个人负责统计一种面值</li></ul></li></ul><h2 id="MapReduce计算流程"><a href="#MapReduce计算流程" class="headerlink" title="MapReduce计算流程"></a>MapReduce计算流程</h2><h3 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h3><ol><li>将数据输入到HDFS上</li><li>对输入数据进行处理</li><li>对处理的数据进行切片</li><li>根据就近原则，对切片数据进行对应节点的Map操作，结果暂存在内存缓冲区</li><li>当缓冲区数据大小到达阈值时<ol><li>锁住缓冲区</li><li>对切片结果按partition和key进行排序<strong>【默认快速排序，第一关键字为分区号，第二关键字为key】</strong>，写入磁盘</li><li>将磁盘上的切片结果进行归并排序{partition, key, value}</li></ol></li><li>将Map结果按partition传输到对应Reduce节点</li><li>Reduce节点将不同Map节点传输的数据按partition分区信息合并，进行Reduce操作</li><li>结果处理后输出到HDFS</li></ol><h3 id="详解"><a href="#详解" class="headerlink" title="详解"></a>详解</h3><ul><li>File<ul><li>文件存储在HDFS中，每个文件切分成多个一定大小（默认64M）的Block，存储在多个DataNode节点上（默认3备份）</li><li>TextFile（明文标准输出）<ul><li><code>hadoop fs -cat /xxx</code>查看</li></ul></li><li>SequenceFile（二进制输出）<ul><li><code>hadoop fs -text /xxx</code>查看</li></ul></li></ul></li><li>InputFormat<ul><li>MR框架基础类之一（Java接口）<ul><li>数据分割（Data Splits）<ul><li>每个Split包含后一个Block的开头部分的数据（解决记录跨Block问题）</li><li>如记录跨跃存储在两个Block中，这条记录属于前一个Block对应的Split</li></ul></li><li>记录读取器（Record Reader）<ul><li>将读取到Split导入Map</li><li>每读取一条记录，将记录作为参数，调用一次Map函数</li><li>继续这个过程，读取下一条记录直到Split尾部</li></ul></li></ul></li></ul></li><li>Map</li><li>Shuffle<ul><li>Partition， Sort， Spill， Merge， Combiner， Copy， Memory， Disk……</li><li><strong>性能优化的重点</strong><ul><li>Partition<ul><li>决定数据由哪个Reducer处理，从而分区（如Hash法）</li></ul></li><li>MemoryBuffer<ul><li>内存缓冲区，每个Map的结果和Partition处理的Key Value结果都保存在缓存中</li><li>缓冲区大小：默认100M</li><li>溢写阈值：100M * 0.8 = 80M</li><li>缓冲区中的数据：{partition, key, value}三元组</li></ul></li><li>Spill<ul><li>内存缓冲区达到阈值时，溢写Spill线程锁住这80M的缓冲区，开始将数据写到本地磁盘中，然后释放内存</li><li>每次溢写都生成一个数据文件</li><li>溢出的数据到磁盘前会对数据进行Key排序Sort，以及合并Combiner</li><li>发送相同Reduce的Key数量，会拼接到一起，减少Partition的索引数量<ul><li>Sort<ul><li>缓冲区数据按照Key进行排序</li></ul></li><li>Combiner<ul><li>数据合并，相同Key的数据，Value值合并，减少输出传输量</li><li>Combiner函数事实上是Reducer函数，满足<strong>Combiner处理不影响{sum, max等}最终Reduce等结果时</strong>，可以极大提升性能</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>Reduce<ul><li>多个Reduce任务输入的数据都属于不同的Partition，因此结果数据的Key不重复</li><li>合并Reduce输出文件即可得到最终的结果</li></ul></li></ul><h3 id="配置注意事项"><a href="#配置注意事项" class="headerlink" title="配置注意事项"></a>配置注意事项</h3><ul><li>文件句柄个数<ul><li>ulimit命令</li><li>报错“当前打开文件超出最大个数”时使用</li></ul></li><li>合适的slot<ul><li>单机map、reduce个数【相互隔离】</li><li><code>mapred.tasktracker.map.tasks.maximum</code>配置Map的slot数（默认2）</li><li><code>mapreduce.tasktracker.tasks.reduce.maximum</code>配置Reduce的slot数（默认2）</li><li>内存限制</li><li>Slot数 = CPU核数 - 1</li><li>多机集群分离</li></ul></li><li>磁盘情况<ul><li>适合单机多磁盘（Raid阵列）</li><li><code>mapred.local.dir</code>Map中间结果存储路径</li><li><code>dfs.data.dir</code>HDFS数据存储路径</li></ul></li><li>配置加载<ul><li>简单配置通过提交作业时-file分发</li><li>复杂较大配置<ul><li>传入HDFS</li><li>Map中打开文件读取</li><li>建立内存结构</li></ul></li></ul></li><li>确定Map任务数依次优先参考如下几个原则<ul><li>每个Map任务使用的内存不超过800M， 尽量在500M以下</li><li>每个Map任务运行时间控制在大约20分钟，最好1-3分钟</li><li>每个Map任务处理的最大数据量为一个HDFS块大小，一个Map任务处理的输入不能跨文件</li><li>Map任务总数不能超过平台可用的任务槽位</li></ul></li><li>Map要点<ul><li>Map个数为Split份数</li><li>压缩文件不可切分【通常压缩文件用于控制Map个数】</li><li>非压缩文件和Sequence文件可以切分</li><li><code>dfs.block.size</code>决定block大小</li></ul></li><li>确定Reduce任务数依次优先参考如下几个原则<ul><li>每个Reduce任务使用的内存不超过800M， 尽量在500M以下</li><li>每个Reduce任务运行时间控制在大约20分钟，最好1-3分钟</li><li>整个Reduce阶段的输入数据总量</li><li>每个Reduce任务处理的数据量控制在500M以内</li><li>Map任务数与Reduce任务数乘积</li><li>输出数据要求</li></ul></li><li>Reduce个数设置<ul><li><code>mapred.reduce.tasks</code>默认为1</li><li>Reduce个数太少<ul><li>单次执行慢</li><li>出错再试成本高</li></ul></li><li>Reduce个数太大<ul><li>Shuffle开销大</li><li>输出大量小文件</li></ul></li></ul></li></ul><p><img src="https://image.alessa0.cn/071824.png" alt="MapReduce"></p><h2 id="MapReduce重要进程（HDFS1-0）"><a href="#MapReduce重要进程（HDFS1-0）" class="headerlink" title="MapReduce重要进程（HDFS1.0）"></a>MapReduce重要进程（HDFS1.0）</h2><ul><li><p><strong>JobTracker</strong></p><ul><li>主进程，负责接收客户作业提交，调度任务到作业节点上运行，并提供诸如监控工作节点状态及任务进度等管理功能，1个MapReduce集群有1个JobTracker，一般运行在可靠的硬件上</li><li>TaskTracker是通过周期性的心跳来通知JobTracker其当前的健康状态，每一次心跳包含了可用的map和reduce任务数目，占用的数目及运行中任务的详细信息。JobTracker利用一个<strong>线程池</strong>来<strong>同时</strong>处理心跳和客户请求。</li><li>等待JobClient提交作业</li></ul></li><li><p><strong>TaskTracker</strong></p><ul><li>由JobTracker指派任务，实例化用户程序，在本地执行任务并周期性地向JobTracker汇报状态。在每一个工作节点上永远只会有<strong>1个</strong>TaskTracker。</li><li>每3s主动向JobTracker发送心跳询问有没有任务，如果有，让其派发任务给它执行</li></ul></li></ul><p>MapReduce采用<strong>多进程</strong>并发</p><ul><li>优点：<ul><li>方便任务资源控制和调配</li><li>运行稳定</li></ul></li><li>缺点：<ul><li>消耗更多的启动时间【不适合低延时作业】</li></ul></li></ul><h2 id="MapReduce作业提交流程"><a href="#MapReduce作业提交流程" class="headerlink" title="MapReduce作业提交流程"></a>MapReduce作业提交流程</h2><ol><li>客户端Client提交作业请求</li><li>Master的JobTracker接收请求分配Job ID</li><li>客户端在HDFS对应Job ID目录上传资源</li><li>Client向JobTracker正式提交任务</li><li>JobTracker对任务进行初始化</li><li>JobTracker将HDFS对应Job ID目录文件分发到各个TaskTracker节点</li><li>TaskTracker向JobTracker发送心跳</li><li>TaskTracker向HDFS分发Job资源</li><li>TaskTracker执行任务</li></ol><h2 id="MapReduce作业调度"><a href="#MapReduce作业调度" class="headerlink" title="MapReduce作业调度"></a>MapReduce作业调度</h2><ul><li>默认<strong>先进先出（FIFO）</strong>队列调度模式<ul><li>优先级：very_high, high, normal, low, very low</li></ul></li></ul><h2 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h2><blockquote><p>MapReduce和HDFS采用Java实现，默认提供Java编程接口</p><p>Streaming框架允许任何程序语言实现的程序在Hadoop MapReduce中使用</p><p>Streaming方便已有程序向Hadoop平台移植</p></blockquote><h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><ul><li>开发效率高<ul><li>方便移植Hadoop平台，仅需按照一定的格式从标准输入读取数据，向标准输出写数据</li><li>原有单机程序稍加改动即可在Hadoop平台进行分布式处理</li><li>容易单机调试<ul><li><code>cat input | mapper | sort | reducer &gt; output</code></li></ul></li></ul></li><li>便于平台进行资源控制<ul><li>Streaming框架中通过limit等方式可以灵活地限制应用程序使用的内存等资源</li></ul></li></ul><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><ul><li>Streaming默认仅能处理文本数据，如要对二进制数据进行处理，比较好的方法是将二进制的key和value进行base64的编码转换成文本</li><li>两次数据拷贝和解析（分割），带来一定开销</li></ul><h3 id="命令行要点"><a href="#命令行要点" class="headerlink" title="命令行要点"></a>命令行要点</h3><ul><li>input<ul><li>指定作业的输入文件HDFS路径，支持使用*通配符，支持指定多个文件或目录，可多次使用</li></ul></li><li>output<ul><li>指定作业的输出文件HDFS路径，路径必须不存在，并且执行作业用户需要具备创建该目录的权限，只能使用一次</li></ul></li><li>mapper<ul><li>用户自己写的Map程序</li></ul></li><li>reducer<ul><li>用户自己写的Reduce程序</li></ul></li><li>file<ul><li>打包本地文件到提交的Job中<ul><li>map和reduce的执行文件</li><li>map和reduce要用输入的文件，如配置文件</li></ul></li><li>类似的配置还有<ul><li>cacheFile 提交HDFS文件到提交的Job中</li><li>cacheArchive 提交HDFS压缩文件到提交的Job中</li></ul></li></ul></li><li>jobconf<ul><li>提交作业的一些配置属性</li><li>常见配置<ul><li><code>mapred.map.tasks</code>map task数目</li><li><code>mapred.reduce.tasks</code>reduce task数目</li><li><code>stream.num.map.output.key.field</code>指定map task输出记录中key所占的域数目</li><li><code>num.key.dields.for.partition</code>指定对key分出来的前几部分做partition而不是整个key</li></ul></li></ul></li></ul><h1 id="HDFS1-0"><a href="#HDFS1-0" class="headerlink" title="HDFS1.0"></a>HDFS1.0</h1><h2 id="HDFS1-0基础"><a href="#HDFS1-0基础" class="headerlink" title="HDFS1.0基础"></a>HDFS1.0基础</h2><ul><li>HDFS1.0系统架构<ul><li>Master<ul><li>NameNode<ul><li>管理着文件系统命名空间<ul><li>维护着文件系统树及树中的所有文件和目录</li></ul></li><li>存储元数据<ul><li>NameNode保存元信息的种类<ul><li>文件名目录名及它们之间的层级关系</li><li>文件目录的所有者及其权限</li><li>每个文件块的名及文件有哪些块组成</li></ul></li></ul></li><li><strong>元数据保存在内存中</strong><ul><li>NameNode元信息并不包含每个块的位置信息</li></ul></li><li>保存文件/Block/DataNode之间的<strong>映射</strong>关系<ul><li>文件名 -&gt; Block</li><li>Block -&gt; DataNode</li></ul></li><li>运行NameNode会占用大量内存和I/O资源，一般NameNode不会存储用户数据或执行MapReduce任务</li><li>全Hadoop系统仅一个NameNode<ul><li>单点问题<ul><li>方案1：将Hadoop元数据写入到本地文件系统时同步到远程挂载的网络文件系统NFS</li><li>方案2：运行SecondaryNameNode进程，持久化到磁盘</li></ul></li></ul></li></ul></li><li>SecondaryNameNode<ul><li><strong>并不是NameNode</strong>，不取代NameNode也不是NameNode的备份</li><li>作用是与NameNode交互，定期通过编辑日志文件合并命名空间镜像</li><li>当NameNode发生故障，NameNode会通过自己合并的命名空间镜像副本来恢复数据</li><li>SecondaryNameNode保存的NameNode元信息总是<strong>滞后于NameNode</strong>的，会导致部分数据丢失</li></ul></li></ul></li><li>Worker<ul><li>DataNode<ul><li>保存Block -&gt; Path的映射关系</li><li>负责存储数据块，负责为系统客户端提供数据块的读写服务</li><li>根据NameNode的指示进行创建/删除和复制等操作</li><li>心跳机制，定期报告文件块列表信息</li><li>DataNode间通信，进行块的副本处理<ul><li>数据块<ul><li>HDFS默认数据块大小为64M</li><li>磁盘块一般为512B</li><li>块增大可以减少寻址时间，降低寻址时间/文件传输时间</li><li>数据块过大导致整体任务量过小，降低作业处理速度</li></ul></li></ul></li></ul></li></ul></li></ul></li><li>Hadoop更倾向存储大文件<ul><li>一般来说，一条元信息记录会占用200byte内存空间。</li><li>假设块大小为64M，备份数量是3，那么一个1G大小的文件将占用16 * 3 = 48 个文件块</li><li>如现在有1000个1M大小的文件，则会占用 1000 * 3 = 3000 个文件块（多个文件不能放到一个块中）</li><li>如果文件越小，存储同等大小的文件所需要的元信息就越多</li></ul></li><li>元信息持久化<ul><li>在NameNode中存放元信息的文件是fsimage</li><li>在系统运行期间所有对元信息的操作都保存在内存中并被持久化到另一个文件edits中</li><li>fsimage文件与edits文件会被SecondaryNameNode进程周期性合并</li></ul></li></ul><p><img src="https://image.alessa0.cn/141922.png" alt="SecondaryNameNode"></p><h2 id="机架感知策略"><a href="#机架感知策略" class="headerlink" title="机架感知策略"></a>机架感知策略</h2><blockquote><p>默认3副本</p></blockquote><ul><li>第一个副本，放在与客户端相同的节点（如客户端是集群外的一台机器，就随机算节点，但是系统会避免挑选太满或太忙的节点）</li><li>第二个副本，放在不同机架（随机选择）的节点</li><li>第三个副本，放在与第二个副本同机架但是不同节点上</li><li>distance<ul><li>distance = 0, 相同DataNode</li><li>distance = 2, 相同Rack下的不同DataNode</li><li>distance = 4, 相同IDC下的不同DataNode</li><li>distance = 6, 不同IDC下的DataNode</li></ul></li></ul><h2 id="数据完整性校验"><a href="#数据完整性校验" class="headerlink" title="数据完整性校验"></a>数据完整性校验</h2><ul><li><p>不希望在存储和处理数据时丢失或损坏任何数据</p></li><li><p>HDFS会对写入的数据计算校验和，并在读取时验证校验和</p></li><li><p>两种校验方法</p><ul><li><p>校验和</p><ul><li>检测损坏数据的常用方法时在第一次写入系统时计算数据的校验和，在通道传输过程中，如果新生成的校验和不完全匹配原始的校验和，那么数据就会被认定为是被损坏的（<strong>默认512字节创建1个校验码</strong>）</li></ul></li><li><p>数据块检测程序DataBlockScanner</p><ul><li>在DataNode节点上开启一个后台进程，来定期验证存储在它上的所有块，这个是防止物理介质出现损减情况而造成的数据损坏（损坏数据从其他DataNode拷贝）</li></ul></li></ul></li></ul><h2 id="可靠性措施"><a href="#可靠性措施" class="headerlink" title="可靠性措施"></a>可靠性措施</h2><ul><li>一个名字节点和多个数据节点</li><li>数据复制（冗余机制）<ul><li>存放位置（机架感知策略）</li><li>并不是3副本写完才返回ack，三副本中有1个写成功就返回ack</li></ul></li><li>故障检测<ul><li>数据节点<ul><li>心跳包（检测是否宕机）</li><li>块报告（安全模式下检测）</li><li>数据完整性检测（校验和比较）</li></ul></li><li>名字节点<ul><li>日志文件</li><li>镜像文件</li></ul></li></ul></li><li>空间回收机制<ul><li>Trash目录（修改core-site.xml）</li></ul></li></ul><h2 id="HDFS-amp-MapReduce本地模式"><a href="#HDFS-amp-MapReduce本地模式" class="headerlink" title="HDFS&amp;MapReduce本地模式"></a>HDFS&amp;MapReduce本地模式</h2><ul><li>Master（小集群）<ul><li>NameNode</li><li>JobTracker</li></ul></li><li>Slave<ul><li>DataNode</li><li>TaskTracker</li></ul></li></ul><h1 id="案例代码"><a href="#案例代码" class="headerlink" title="案例代码"></a>案例代码</h1><blockquote><p>常见实践有：</p><blockquote><p>数据统计</p><blockquote><p>WordCount</p></blockquote><p>数据过滤（清洗）</p><blockquote><p>从日志查找某一个条件等数据</p><p>除去非法数据，保留合法数据</p><p>数据格式整理</p></blockquote><p>同类汇聚</p><blockquote><p>多份日志，相同时间点、用户行为日志Join</p><p>类表格文件存储中，相同主键拼接相关属性</p><p>历史的主数据与新增，修改数据合并</p></blockquote><p>全局排序</p><blockquote><p>混合日志，按时间排列好顺序</p><p>按某个或多个字段有序</p></blockquote><p>容错框架</p><blockquote><p>测试集群状态：在集群上运行一个错误代码Job，进行观察</p><p>使用易出错的服务，365 * 24 运行</p><p>计算规模经常变化调整的服务</p><p>单进程程序，迅速提升执行计算效率</p></blockquote></blockquote></blockquote><h2 id="WordCount"><a href="#WordCount" class="headerlink" title="WordCount"></a>WordCount</h2><h3 id="Python3"><a href="#Python3" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-py"><a href="#map-py" class="headerlink" title="map.py"></a>map.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> ss:</span><br><span class="line">        print(word.strip() + <span class="string">'\t'</span> + <span class="string">'1'</span>)</span><br></pre></td></tr></table></figure><h4 id="reduce-py"><a href="#reduce-py" class="headerlink" title="reduce.py"></a>reduce.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">current_word = <span class="literal">None</span></span><br><span class="line">cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    word, cnt = ss</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        current_word = word</span><br><span class="line">    <span class="keyword">if</span> current_word != word:</span><br><span class="line">        print(current_word.strip() + <span class="string">'\t'</span> + str(cnt_sum))</span><br><span class="line">        current_word = word</span><br><span class="line">        cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    cnt_sum += int(cnt)</span><br><span class="line"></span><br><span class="line">print(current_word.strip() + <span class="string">'\t'</span> + str(cnt_sum))</span><br></pre></td></tr></table></figure><h4 id="The-Man-of-Property-txt"><a href="#The-Man-of-Property-txt" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h4><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“The Forsyte Saga” was <span class="keyword">the</span> title originally destined <span class="keyword">for</span> <span class="keyword">that</span> part <span class="keyword">of</span> <span class="keyword">it</span> which <span class="keyword">is</span> called “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt <span class="keyword">it</span> <span class="keyword">for</span> <span class="keyword">the</span> collected chronicles <span class="keyword">of</span> <span class="keyword">the</span> Forsyte family has indulged <span class="keyword">the</span> Forsytean tenacity <span class="keyword">that</span> <span class="keyword">is</span> <span class="keyword">in</span> all <span class="keyword">of</span> us. The <span class="built_in">word</span> Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> <span class="keyword">the</span> ground <span class="keyword">that</span> <span class="keyword">it</span> connotes <span class="keyword">the</span> heroic <span class="keyword">and</span> <span class="keyword">that</span> there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But <span class="keyword">it</span> <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> all, this long tale, though <span class="keyword">it</span> may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> <span class="keyword">the</span> essential heat <span class="keyword">of</span> conflict. Discounting <span class="keyword">for</span> <span class="keyword">the</span> gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> old days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, <span class="keyword">the</span> folk <span class="keyword">of</span> <span class="keyword">the</span> old Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof <span class="keyword">against</span> <span class="keyword">the</span> inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. And <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days <span class="keyword">that</span> never were, seem <span class="keyword">to</span> startle out <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> <span class="keyword">the</span> Victorian era, we may be sure <span class="keyword">that</span> tribal instinct was even <span class="keyword">then</span> <span class="keyword">the</span> prime force, <span class="keyword">and</span> <span class="keyword">that</span> “family” <span class="keyword">and</span> <span class="keyword">the</span> sense <span class="keyword">of</span> home <span class="keyword">and</span> <span class="keyword">property</span> counted <span class="keyword">as</span> they do <span class="keyword">to</span> this <span class="built_in">day</span>, <span class="keyword">for</span> all <span class="keyword">the</span> recent efforts <span class="keyword">to</span> “talk them out.”</span><br></pre></td></tr></table></figure><h4 id="run-sh"><a href="#run-sh" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop命令地址</span></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># hadoop streaming jar包地址</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输入文件路径</span></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/01_mr_wordcount/The_Man_of_Property.txt"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># HDFS 输出文件路径</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/01_mr_wordcount/output/python3"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入文件本地路径</span></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/week01/01_mr_wordcount/The_Man_of_Property.txt"</span></span><br><span class="line"><span class="comment"># 输入文件 HDFS上传路径</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/01_mr_wordcount"</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除HDFS存在目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建HDFS 上传目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="comment"># 将本地输入文件上传到HDFS目录</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 命令行</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py"</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># -file 过时了，2.8.5用-files代替，作为可选参数需放在-input等参数前面</span></span><br></pre></td></tr></table></figure><h2 id="AllSort-1Reduce"><a href="#AllSort-1Reduce" class="headerlink" title="AllSort_1Reduce"></a>AllSort_1Reduce</h2><h3 id="Version-1"><a href="#Version-1" class="headerlink" title="Version 1"></a>Version 1</h3><h4 id="Python3-1"><a href="#Python3-1" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-sort-py"><a href="#map-sort-py" class="headerlink" title="map_sort.py"></a>map_sort.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + int(key)</span><br><span class="line">    print(str(new_key) + <span class="string">'\t'</span> + val)</span><br></pre></td></tr></table></figure><h5 id="red-sort-py"><a href="#red-sort-py" class="headerlink" title="red_sort.py"></a>red_sort.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    new_key, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    key = int(new_key) - base_count</span><br><span class="line">    print(<span class="string">'%s\t%s'</span> % (key, val))</span><br></pre></td></tr></table></figure><h5 id="a-txt"><a href="#a-txt" class="headerlink" title="a.txt"></a>a.txt</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>hadoop</span><br><span class="line"><span class="number">3</span>hadoop</span><br><span class="line"><span class="number">5</span>hadoop</span><br><span class="line"><span class="number">7</span>hadoop</span><br><span class="line"><span class="number">9</span>hadoop</span><br></pre></td></tr></table></figure><h5 id="b-txt"><a href="#b-txt" class="headerlink" title="b.txt"></a>b.txt</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>java</span><br><span class="line"><span class="number">2</span>java</span><br><span class="line"><span class="number">4</span>java</span><br><span class="line"><span class="number">6</span>java</span><br><span class="line"><span class="number">8</span>java</span><br></pre></td></tr></table></figure><h5 id="run-sh-1"><a href="#run-sh-1" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/version1/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 依赖MapReduce框架自身的sort功能：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1</span></span><br><span class="line">    <span class="comment"># -jobconf 可用-D 替代，作为可选参数放在-input等前面</span></span><br></pre></td></tr></table></figure><h3 id="Version-2"><a href="#Version-2" class="headerlink" title="Version 2"></a>Version 2</h3><h4 id="Python3-2"><a href="#Python3-2" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-sort-py-1"><a href="#map-sort-py-1" class="headerlink" title="map_sort.py"></a>map_sort.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    print(line.strip())</span><br></pre></td></tr></table></figure><h5 id="red-sort-py-1"><a href="#red-sort-py-1" class="headerlink" title="red_sort.py"></a>red_sort.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    print(line.strip())</span><br></pre></td></tr></table></figure><h5 id="a-txt-1"><a href="#a-txt-1" class="headerlink" title="a.txt"></a>a.txt</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>hadoop</span><br><span class="line"><span class="number">3</span>hadoop</span><br><span class="line"><span class="number">5</span>hadoop</span><br><span class="line"><span class="number">7</span>hadoop</span><br><span class="line"><span class="number">9</span>hadoop</span><br></pre></td></tr></table></figure><h5 id="b-txt-1"><a href="#b-txt-1" class="headerlink" title="b.txt"></a>b.txt</h5><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>java</span><br><span class="line"><span class="number">2</span>java</span><br><span class="line"><span class="number">4</span>java</span><br><span class="line"><span class="number">6</span>java</span><br><span class="line"><span class="number">8</span>java</span><br></pre></td></tr></table></figure><h5 id="run-sh-2"><a href="#run-sh-2" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/version2/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/02_mr_allsort_1reduce/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/02_mr_allsort_1reduce/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span><br><span class="line">    -D stream.num.map.output.key.fields=1 \</span><br><span class="line">    -D mapreduce.partition.keypartitioner.options=<span class="string">"-k1,1"</span> \</span><br><span class="line">    -D mapreduce.partition.keycomparator.options=<span class="string">"-k1,1n"</span> \</span><br><span class="line">    -D mapreduce.job.reduces=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置单reduce：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.reduces=1 \</span></span><br><span class="line">    <span class="comment"># 控制分发，完成二次排序：</span></span><br><span class="line">    <span class="comment"># -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner \</span></span><br><span class="line">    <span class="comment"># 完成key排序：</span></span><br><span class="line">    <span class="comment"># -D mapreduce.job.output.key.comparator.class=org.apache.hadoop.mapred.lib.KeyFieldBasedComparator \</span></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=1 \</span></span><br><span class="line">    <span class="comment"># 选择哪一部分做partition，-k1,1表示partition的key范围是（1，1），即第1列</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options="-k1,1" \</span></span><br><span class="line">    <span class="comment"># 设置key中需要比较的字段或字节范围，-k1,1表示sort的key范围是（1，1），即第1列，n表示按数字number类型排序</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keycomparator.options="-k1,1n" \</span></span><br></pre></td></tr></table></figure><h2 id="AllSort"><a href="#AllSort" class="headerlink" title="AllSort"></a>AllSort</h2><h3 id="Python3-3"><a href="#Python3-3" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-sort-py-2"><a href="#map-sort-py-2" class="headerlink" title="map_sort.py"></a>map_sort.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">    key, val = ss</span><br><span class="line"></span><br><span class="line">    new_key = base_count + int(key)</span><br><span class="line"></span><br><span class="line">    partition_index = <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> new_key &lt; (<span class="number">10100</span> + <span class="number">10000</span>) / <span class="number">2</span>:</span><br><span class="line">        partition_index = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    print(<span class="string">"%s\t%s\t%s"</span> % (partition_index, new_key, val))</span><br></pre></td></tr></table></figure><h4 id="red-sort-py-2"><a href="#red-sort-py-2" class="headerlink" title="red_sort.py"></a>red_sort.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">base_count = <span class="number">10000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    partition_index, new_key, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    key = int(new_key) - base_count</span><br><span class="line">    print(<span class="string">'\t'</span>.join([str(key), val]))</span><br></pre></td></tr></table></figure><h4 id="a-txt-2"><a href="#a-txt-2" class="headerlink" title="a.txt"></a>a.txt</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>hadoop</span><br><span class="line"><span class="number">3</span>hadoop</span><br><span class="line"><span class="number">5</span>hadoop</span><br><span class="line"><span class="number">7</span>hadoop</span><br><span class="line"><span class="number">9</span>hadoop</span><br></pre></td></tr></table></figure><h4 id="b-txt-2"><a href="#b-txt-2" class="headerlink" title="b.txt"></a>b.txt</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span>java</span><br><span class="line"><span class="number">2</span>java</span><br><span class="line"><span class="number">4</span>java</span><br><span class="line"><span class="number">6</span>java</span><br><span class="line"><span class="number">8</span>java</span><br></pre></td></tr></table></figure><h4 id="run-sh-3"><a href="#run-sh-3" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/03_mr_allsort/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/03_mr_allsort/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/03_mr_allsort/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/03_mr_allsort/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/03_mr_allsort/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/03_mr_allsort/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files map_sort.py,red_sort.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span>,<span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_sort.py"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_sort.py"</span> \</span><br><span class="line">    -partitioner org.apache.hadoop.mapred.lib.KeyFieldBasedPartitioner</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 设置分隔符位置（默认\t）,分隔符之前为key，之后为value，此处以前2列为key</span></span><br><span class="line">    <span class="comment"># -D stream.num.map.output.key.fields=2 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（仅能从头顺序选取范围）用来做分发，此处以第1列做partition</span></span><br><span class="line">    <span class="comment"># -D num.key.fields.for.partition=1 \</span></span><br><span class="line">    <span class="comment"># 设置partition key（可选择中间范围）用来做分发</span></span><br><span class="line">    <span class="comment"># -D mapreduce.partition.keypartitioner.options="-k1,1" \</span></span><br></pre></td></tr></table></figure><h2 id="File-Broadcast"><a href="#File-Broadcast" class="headerlink" title="File_Broadcast"></a>File_Broadcast</h2><h3 id="File"><a href="#File" class="headerlink" title="File"></a>File</h3><h4 id="Python3-4"><a href="#Python3-4" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-1"><a href="#map-py-1" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span><span class="params">(f)</span>:</span></span><br><span class="line">    word_set = set()</span><br><span class="line">    file_in = open(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span><span class="params">(white_list_fd)</span>:</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                print(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="red-py"><a href="#red-py" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span><span class="params">()</span>:</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                sum += count</span><br><span class="line">            print(<span class="string">"%s\t%s"</span> % (current_word, sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(int(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        sum += count</span><br><span class="line">    print(<span class="string">"%s\t%s"</span> % (current_word, str(sum)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="The-Man-of-Property-txt-1"><a href="#The-Man-of-Property-txt-1" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“The Forsyte Saga” was <span class="keyword">the</span> title originally destined <span class="keyword">for</span> <span class="keyword">that</span> part <span class="keyword">of</span> <span class="keyword">it</span> which <span class="keyword">is</span> called “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt <span class="keyword">it</span> <span class="keyword">for</span> <span class="keyword">the</span> collected chronicles <span class="keyword">of</span> <span class="keyword">the</span> Forsyte family has indulged <span class="keyword">the</span> Forsytean tenacity <span class="keyword">that</span> <span class="keyword">is</span> <span class="keyword">in</span> all <span class="keyword">of</span> us. The <span class="built_in">word</span> Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> <span class="keyword">the</span> ground <span class="keyword">that</span> <span class="keyword">it</span> connotes <span class="keyword">the</span> heroic <span class="keyword">and</span> <span class="keyword">that</span> there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But <span class="keyword">it</span> <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> all, this long tale, though <span class="keyword">it</span> may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> <span class="keyword">the</span> essential heat <span class="keyword">of</span> conflict. Discounting <span class="keyword">for</span> <span class="keyword">the</span> gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> old days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, <span class="keyword">the</span> folk <span class="keyword">of</span> <span class="keyword">the</span> old Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof <span class="keyword">against</span> <span class="keyword">the</span> inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. And <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days <span class="keyword">that</span> never were, seem <span class="keyword">to</span> startle out <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> <span class="keyword">the</span> Victorian era, we may be sure <span class="keyword">that</span> tribal instinct was even <span class="keyword">then</span> <span class="keyword">the</span> prime force, <span class="keyword">and</span> <span class="keyword">that</span> “family” <span class="keyword">and</span> <span class="keyword">the</span> sense <span class="keyword">of</span> home <span class="keyword">and</span> <span class="keyword">property</span> counted <span class="keyword">as</span> they do <span class="keyword">to</span> this <span class="built_in">day</span>, <span class="keyword">for</span> all <span class="keyword">the</span> recent efforts <span class="keyword">to</span> “talk them out.”</span><br></pre></td></tr></table></figure><h5 id="white-list"><a href="#white-list" class="headerlink" title="white_list"></a>white_list</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure><h5 id="run-sh-4"><a href="#run-sh-4" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/file/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -files map.py,red.py,white_list \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func white_list"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br></pre></td></tr></table></figure><h3 id="cacheFile"><a href="#cacheFile" class="headerlink" title="cacheFile"></a>cacheFile</h3><h4 id="Python3-5"><a href="#Python3-5" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-2"><a href="#map-py-2" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span><span class="params">(file)</span>:</span></span><br><span class="line">    word_set = set()</span><br><span class="line">    file_in = open(file, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> file_in:</span><br><span class="line">        word = line.strip()</span><br><span class="line">        word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span><span class="params">(white_list)</span>:</span></span><br><span class="line">    word_set = read_local_file_func(white_list)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                print(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="red-py-1"><a href="#red-py-1" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span><span class="params">()</span>:</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        word, cnt = ss</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            print(current_word.strip() + <span class="string">'\t'</span> + str(cnt_sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            cnt_sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        cnt_sum += int(cnt)</span><br><span class="line"></span><br><span class="line">    print(current_word.strip() + <span class="string">'\t'</span> + str(cnt_sum))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="The-Man-of-Property-txt-2"><a href="#The-Man-of-Property-txt-2" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“The Forsyte Saga” was <span class="keyword">the</span> title originally destined <span class="keyword">for</span> <span class="keyword">that</span> part <span class="keyword">of</span> <span class="keyword">it</span> which <span class="keyword">is</span> called “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt <span class="keyword">it</span> <span class="keyword">for</span> <span class="keyword">the</span> collected chronicles <span class="keyword">of</span> <span class="keyword">the</span> Forsyte family has indulged <span class="keyword">the</span> Forsytean tenacity <span class="keyword">that</span> <span class="keyword">is</span> <span class="keyword">in</span> all <span class="keyword">of</span> us. The <span class="built_in">word</span> Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> <span class="keyword">the</span> ground <span class="keyword">that</span> <span class="keyword">it</span> connotes <span class="keyword">the</span> heroic <span class="keyword">and</span> <span class="keyword">that</span> there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But <span class="keyword">it</span> <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> all, this long tale, though <span class="keyword">it</span> may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> <span class="keyword">the</span> essential heat <span class="keyword">of</span> conflict. Discounting <span class="keyword">for</span> <span class="keyword">the</span> gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> old days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, <span class="keyword">the</span> folk <span class="keyword">of</span> <span class="keyword">the</span> old Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof <span class="keyword">against</span> <span class="keyword">the</span> inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. And <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days <span class="keyword">that</span> never were, seem <span class="keyword">to</span> startle out <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> <span class="keyword">the</span> Victorian era, we may be sure <span class="keyword">that</span> tribal instinct was even <span class="keyword">then</span> <span class="keyword">the</span> prime force, <span class="keyword">and</span> <span class="keyword">that</span> “family” <span class="keyword">and</span> <span class="keyword">the</span> sense <span class="keyword">of</span> home <span class="keyword">and</span> <span class="keyword">property</span> counted <span class="keyword">as</span> they do <span class="keyword">to</span> this <span class="built_in">day</span>, <span class="keyword">for</span> all <span class="keyword">the</span> recent efforts <span class="keyword">to</span> “talk them out.”</span><br></pre></td></tr></table></figure><h5 id="white-list-1"><a href="#white-list-1" class="headerlink" title="white_list"></a>white_list</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure><h5 id="run-sh-5"><a href="#run-sh-5" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/cachefile/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/white_list"</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">"/week01/04_mr_file_broadcast/cachefile/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachefile_demo \</span><br><span class="line">    -files map.py,red.py,<span class="string">"hdfs://master:9000/week01/04_mr_file_broadcast/cachefile/white_list#WH"</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 过时了</span></span><br><span class="line">    <span class="comment"># -cacheFile "hdfs://master:9000/week01/04_mr_file_broadcast/cachefile</span></span><br><span class="line">    <span class="comment"># /white_list#WWWHHH" \</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#-cacheFile "$&#123;HDFS_FILE_PATH&#125;#WH" \</span></span><br></pre></td></tr></table></figure><h3 id="cacheArchive"><a href="#cacheArchive" class="headerlink" title="cacheArchive"></a>cacheArchive</h3><h4 id="Python3-6"><a href="#Python3-6" class="headerlink" title="Python3"></a>Python3</h4><h5 id="map-py-3"><a href="#map-py-3" class="headerlink" title="map.py"></a>map.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span><span class="params">(f)</span>:</span></span><br><span class="line">    file_in = open(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span><span class="params">(f)</span>:</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">'/'</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span><span class="params">(f)</span>:</span></span><br><span class="line">    word_set = set()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span><span class="params">(white_list_fd)</span>:</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                print(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="red-py-2"><a href="#red-py-2" class="headerlink" title="red.py"></a>red.py</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span><span class="params">()</span>:</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                sum += count</span><br><span class="line">            print(<span class="string">"%s\t%s"</span> % (current_word, sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(int(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        sum += count</span><br><span class="line">    print(<span class="string">"%s\t%s"</span> % (current_word, str(sum)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h5 id="The-Man-of-Property-txt-3"><a href="#The-Man-of-Property-txt-3" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h5><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“The Forsyte Saga” was <span class="keyword">the</span> title originally destined <span class="keyword">for</span> <span class="keyword">that</span> part <span class="keyword">of</span> <span class="keyword">it</span> which <span class="keyword">is</span> called “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt <span class="keyword">it</span> <span class="keyword">for</span> <span class="keyword">the</span> collected chronicles <span class="keyword">of</span> <span class="keyword">the</span> Forsyte family has indulged <span class="keyword">the</span> Forsytean tenacity <span class="keyword">that</span> <span class="keyword">is</span> <span class="keyword">in</span> all <span class="keyword">of</span> us. The <span class="built_in">word</span> Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> <span class="keyword">the</span> ground <span class="keyword">that</span> <span class="keyword">it</span> connotes <span class="keyword">the</span> heroic <span class="keyword">and</span> <span class="keyword">that</span> there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But <span class="keyword">it</span> <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> all, this long tale, though <span class="keyword">it</span> may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> <span class="keyword">the</span> essential heat <span class="keyword">of</span> conflict. Discounting <span class="keyword">for</span> <span class="keyword">the</span> gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> old days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, <span class="keyword">the</span> folk <span class="keyword">of</span> <span class="keyword">the</span> old Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof <span class="keyword">against</span> <span class="keyword">the</span> inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. And <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days <span class="keyword">that</span> never were, seem <span class="keyword">to</span> startle out <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> <span class="keyword">the</span> Victorian era, we may be sure <span class="keyword">that</span> tribal instinct was even <span class="keyword">then</span> <span class="keyword">the</span> prime force, <span class="keyword">and</span> <span class="keyword">that</span> “family” <span class="keyword">and</span> <span class="keyword">the</span> sense <span class="keyword">of</span> home <span class="keyword">and</span> <span class="keyword">property</span> counted <span class="keyword">as</span> they do <span class="keyword">to</span> this <span class="built_in">day</span>, <span class="keyword">for</span> all <span class="keyword">the</span> recent efforts <span class="keyword">to</span> “talk them out.”</span><br></pre></td></tr></table></figure><h5 id="w-tar-gz"><a href="#w-tar-gz" class="headerlink" title="w.tar.gz"></a>w.tar.gz</h5><h6 id="white-list-1"><a href="#white-list-1" class="headerlink" title="white_list_1"></a>white_list_1</h6><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure><h6 id="white-list-2"><a href="#white-list-2" class="headerlink" title="white_list_2"></a>white_list_2</h6><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">a</span></span><br></pre></td></tr></table></figure><h5 id="run-sh-6"><a href="#run-sh-6" class="headerlink" title="run.sh"></a>run.sh</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/04_mr_file_broadcast/cachearchive/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/04_mr_file_broadcast/w.tar.gz"</span></span><br><span class="line">UPLOAD_PATH_A=<span class="string">"/week01/04_mr_file_broadcast/"</span></span><br><span class="line">UPLOAD_PATH_B=<span class="string">"/week01/04_mr_file_broadcast/cachearchive/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_A&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH_B&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=cachearchive_demo \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">"hdfs://master:9000/week01/04_mr_file_broadcast/cachearchive/w.tar.gz#WH.gz"</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH.gz"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br></pre></td></tr></table></figure><h2 id="Compression"><a href="#Compression" class="headerlink" title="Compression"></a>Compression</h2><h3 id="Python3-7"><a href="#Python3-7" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-py-4"><a href="#map-py-4" class="headerlink" title="map.py"></a>map.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_file_handler</span><span class="params">(f)</span>:</span></span><br><span class="line">    file_in = open(f, <span class="string">'r'</span>)</span><br><span class="line">    <span class="keyword">return</span> file_in</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_cachefile_handlers</span><span class="params">(f)</span>:</span></span><br><span class="line">    f_handlers_list = []</span><br><span class="line">    <span class="keyword">if</span> os.path.isdir(f):</span><br><span class="line">        <span class="keyword">for</span> fd <span class="keyword">in</span> os.listdir(f):</span><br><span class="line">            f_handlers_list.append(get_file_handler(f + <span class="string">'/'</span> + fd))</span><br><span class="line">    <span class="keyword">return</span> f_handlers_list</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_local_file_func</span><span class="params">(f)</span>:</span></span><br><span class="line">    word_set = set()</span><br><span class="line">    <span class="keyword">for</span> cachefile <span class="keyword">in</span> get_cachefile_handlers(f):</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> cachefile:</span><br><span class="line">            word = line.strip()</span><br><span class="line">            word_set.add(word)</span><br><span class="line">    <span class="keyword">return</span> word_set</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">mapper_func</span><span class="params">(white_list_fd)</span>:</span></span><br><span class="line">    word_set = read_local_file_func(white_list_fd)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        ss = line.strip().split(<span class="string">' '</span>)</span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> ss:</span><br><span class="line">            word = s.strip()</span><br><span class="line">            <span class="keyword">if</span> word != <span class="string">""</span> <span class="keyword">and</span> (word <span class="keyword">in</span> word_set):</span><br><span class="line">                print(<span class="string">"%s\t%s"</span> % (s, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h4 id="red-py-3"><a href="#red-py-3" class="headerlink" title="red.py"></a>red.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reducer_func</span><span class="params">()</span>:</span></span><br><span class="line">    current_word = <span class="literal">None</span></span><br><span class="line">    count_pool = []</span><br><span class="line">    sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">        word, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            current_word = word</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> current_word != word:</span><br><span class="line">            <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">                sum += count</span><br><span class="line">            print(<span class="string">"%s\t%s"</span> % (current_word, sum))</span><br><span class="line">            current_word = word</span><br><span class="line">            count_pool = []</span><br><span class="line">            sum = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        count_pool.append(int(val))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> count <span class="keyword">in</span> count_pool:</span><br><span class="line">        sum += count</span><br><span class="line">    print(<span class="string">"%s\t%s"</span> % (current_word, str(sum)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    module = sys.modules[__name__]</span><br><span class="line">    func = getattr(module, sys.argv[<span class="number">1</span>])</span><br><span class="line">    args = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) &gt; <span class="number">1</span>:</span><br><span class="line">        args = sys.argv[<span class="number">2</span>:]</span><br><span class="line">    func(*args)</span><br></pre></td></tr></table></figure><h4 id="The-Man-of-Property-txt-4"><a href="#The-Man-of-Property-txt-4" class="headerlink" title="The_Man_of_Property.txt"></a>The_Man_of_Property.txt</h4><figure class="highlight applescript"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">“The Forsyte Saga” was <span class="keyword">the</span> title originally destined <span class="keyword">for</span> <span class="keyword">that</span> part <span class="keyword">of</span> <span class="keyword">it</span> which <span class="keyword">is</span> called “The Man <span class="keyword">of</span> Property”; <span class="keyword">and</span> <span class="keyword">to</span> adopt <span class="keyword">it</span> <span class="keyword">for</span> <span class="keyword">the</span> collected chronicles <span class="keyword">of</span> <span class="keyword">the</span> Forsyte family has indulged <span class="keyword">the</span> Forsytean tenacity <span class="keyword">that</span> <span class="keyword">is</span> <span class="keyword">in</span> all <span class="keyword">of</span> us. The <span class="built_in">word</span> Saga might be objected <span class="keyword">to</span> <span class="keyword">on</span> <span class="keyword">the</span> ground <span class="keyword">that</span> <span class="keyword">it</span> connotes <span class="keyword">the</span> heroic <span class="keyword">and</span> <span class="keyword">that</span> there <span class="keyword">is</span> little heroism <span class="keyword">in</span> these pages. But <span class="keyword">it</span> <span class="keyword">is</span> used <span class="keyword">with</span> a suitable irony; <span class="keyword">and</span>, <span class="keyword">after</span> all, this long tale, though <span class="keyword">it</span> may deal <span class="keyword">with</span> folk <span class="keyword">in</span> frock coats, furbelows, <span class="keyword">and</span> a gilt-edged period, <span class="keyword">is</span> <span class="keyword">not</span> devoid <span class="keyword">of</span> <span class="keyword">the</span> essential heat <span class="keyword">of</span> conflict. Discounting <span class="keyword">for</span> <span class="keyword">the</span> gigantic stature <span class="keyword">and</span> blood-thirstiness <span class="keyword">of</span> old days, <span class="keyword">as</span> they have come down <span class="keyword">to</span> us <span class="keyword">in</span> fairy-tale <span class="keyword">and</span> legend, <span class="keyword">the</span> folk <span class="keyword">of</span> <span class="keyword">the</span> old Sagas were Forsytes, assuredly, <span class="keyword">in</span> their possessive instincts, <span class="keyword">and</span> <span class="keyword">as</span> little proof <span class="keyword">against</span> <span class="keyword">the</span> inroads <span class="keyword">of</span> beauty <span class="keyword">and</span> passion <span class="keyword">as</span> Swithin, Soames, <span class="keyword">or</span> even Young Jolyon. And <span class="keyword">if</span> heroic figures, <span class="keyword">in</span> days <span class="keyword">that</span> never were, seem <span class="keyword">to</span> startle out <span class="keyword">from</span> their surroundings <span class="keyword">in</span> fashion unbecoming <span class="keyword">to</span> a Forsyte <span class="keyword">of</span> <span class="keyword">the</span> Victorian era, we may be sure <span class="keyword">that</span> tribal instinct was even <span class="keyword">then</span> <span class="keyword">the</span> prime force, <span class="keyword">and</span> <span class="keyword">that</span> “family” <span class="keyword">and</span> <span class="keyword">the</span> sense <span class="keyword">of</span> home <span class="keyword">and</span> <span class="keyword">property</span> counted <span class="keyword">as</span> they do <span class="keyword">to</span> this <span class="built_in">day</span>, <span class="keyword">for</span> all <span class="keyword">the</span> recent efforts <span class="keyword">to</span> “talk them out.”</span><br></pre></td></tr></table></figure><h4 id="white-list-dir-tar-gz"><a href="#white-list-dir-tar-gz" class="headerlink" title="white_list_dir.tar.gz"></a>white_list_dir.tar.gz</h4><h5 id="white-list-1-1"><a href="#white-list-1-1" class="headerlink" title="white_list_1"></a>white_list_1</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">the</span></span><br></pre></td></tr></table></figure><h5 id="white-list-2-1"><a href="#white-list-2-1" class="headerlink" title="white_list_2"></a>white_list_2</h5><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">a</span></span><br></pre></td></tr></table></figure><h4 id="run-sh-7"><a href="#run-sh-7" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH=<span class="string">"/week01/05_mr_compression/The_Man_of_Property.txt"</span></span><br><span class="line">OUTPUT_PATH=<span class="string">"/week01/05_mr_compression/run_1/output/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/05_mr_compression/The_Man_of_Property.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/05_mr_compression/white_list_dir.tar.gz"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/05_mr_compression/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;OUTPUT_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D mapreduce.job.reduces=2 \</span><br><span class="line">    -D mapreduce.job.name=compression_run_1_demo \</span><br><span class="line">    -D mapreduce.map.output.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress=<span class="literal">true</span> \</span><br><span class="line">    -D mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.GzipCodec \</span><br><span class="line">    -files map.py,red.py \</span><br><span class="line">    -archives <span class="string">"hdfs://master:9000/week01/05_mr_compression/white_list_dir.tar.gz#WH.gz"</span> \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map.py mapper_func WH.gz"</span> \</span><br><span class="line">    -reducer <span class="string">"python red.py reducer_func"</span> \</span><br></pre></td></tr></table></figure><h2 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h2><h3 id="Python3-8"><a href="#Python3-8" class="headerlink" title="Python3"></a>Python3</h3><h4 id="map-a-py"><a href="#map-a-py" class="headerlink" title="map_a.py"></a>map_a.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"%s\t1\t%s"</span> % (key, val))</span><br></pre></td></tr></table></figure><h4 id="a-txt-3"><a href="#a-txt-3" class="headerlink" title="a.txt"></a>a.txt</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">aaa1<span class="number">123</span></span><br><span class="line">aaa2<span class="number">123</span></span><br><span class="line">aaa3<span class="number">123</span></span><br><span class="line">aaa4<span class="number">123</span></span><br><span class="line">aaa5<span class="number">123</span></span><br></pre></td></tr></table></figure><h4 id="map-b-py"><a href="#map-b-py" class="headerlink" title="map_b.py"></a>map_b.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, val = line.strip().split(<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    print(<span class="string">"%s\t2\t%s"</span> % (key, val))</span><br></pre></td></tr></table></figure><h4 id="b-txt-3"><a href="#b-txt-3" class="headerlink" title="b.txt"></a>b.txt</h4><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">aaa1</span>hadoop</span><br><span class="line">aaa2hadoop</span><br><span class="line">aaa3hadoop</span><br><span class="line">aaa4hadoop</span><br><span class="line">aaa5hadoop</span><br></pre></td></tr></table></figure><h4 id="red-join-py"><a href="#red-join-py" class="headerlink" title="red_join.py"></a>red_join.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">val_1 = <span class="string">""</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> sys.stdin:</span><br><span class="line">    key, flag, val = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> flag == <span class="string">'1'</span>:</span><br><span class="line">        val_1 = val</span><br><span class="line">    <span class="keyword">elif</span> flag == <span class="string">'2'</span>:</span><br><span class="line">        val_2 = val</span><br><span class="line">        print(<span class="string">"%s\t%s\t%s"</span> % (key, val_1, val_2))</span><br><span class="line">        val_1 = <span class="string">""</span></span><br></pre></td></tr></table></figure><h4 id="run-sh-8"><a href="#run-sh-8" class="headerlink" title="run.sh"></a>run.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/usr/bin/env bash</span></span><br><span class="line"></span><br><span class="line">HADOOP_CMD=<span class="string">"/usr/local/src/hadoop-2.8.5/bin/hadoop"</span></span><br><span class="line">STREAM_JAR_PATH=<span class="string">"/usr/local/src/hadoop-2.8.5/share/hadoop/tools/lib/hadoop-streaming-2.8.5.jar"</span></span><br><span class="line"></span><br><span class="line">INPUT_FILE_PATH_A=<span class="string">"/week01/06_mr_join/a.txt"</span></span><br><span class="line">INPUT_FILE_PATH_B=<span class="string">"/week01/06_mr_join/b.txt"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_A=<span class="string">"/week01/06_mr_join/output/a/python3"</span></span><br><span class="line">OUTPUT_PATH_B=<span class="string">"/week01/06_mr_join/output/b/python3"</span></span><br><span class="line"></span><br><span class="line">OUTPUT_PATH_JOIN=<span class="string">"/week01/06_mr_join/output/join/python3"</span></span><br><span class="line"></span><br><span class="line">LOCAL_FILE_PATH_A=<span class="string">"/mnt/hgfs/Code/week01/06_mr_join/a.txt"</span></span><br><span class="line">LOCAL_FILE_PATH_B=<span class="string">"/mnt/hgfs/Code/week01/06_mr_join/b.txt"</span></span><br><span class="line">UPLOAD_PATH=<span class="string">"/week01/06_mr_join/"</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -rm -r -skipTrash <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span> <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> <span class="variable">$&#123;OUTPUT_PATH_JOIN&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -mkdir -p <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> fs -put <span class="variable">$&#123;LOCAL_FILE_PATH_A&#125;</span> <span class="variable">$&#123;LOCAL_FILE_PATH_B&#125;</span> <span class="variable">$&#123;UPLOAD_PATH&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 1.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map_a.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_A&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_a.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 2.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -files map_b.py \</span><br><span class="line">    -input <span class="variable">$&#123;INPUT_FILE_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"python map_b.py"</span> \</span><br><span class="line"></span><br><span class="line"><span class="comment"># Step 3.</span></span><br><span class="line"><span class="variable">$&#123;HADOOP_CMD&#125;</span> jar <span class="variable">$&#123;STREAM_JAR_PATH&#125;</span> \</span><br><span class="line">    -D stream.num.map.output.key.fields=2 \</span><br><span class="line">    -D num.key.fields.for.partition=1 \</span><br><span class="line">    -files red_join.py \</span><br><span class="line">    -input <span class="variable">$&#123;OUTPUT_PATH_A&#125;</span>,<span class="variable">$&#123;OUTPUT_PATH_B&#125;</span> \</span><br><span class="line">    -output <span class="variable">$&#123;OUTPUT_PATH_JOIN&#125;</span> \</span><br><span class="line">    -mapper <span class="string">"cat"</span> \</span><br><span class="line">    -reducer <span class="string">"python red_join.py"</span> \</span><br></pre></td></tr></table></figure><h2 id="附加项目：pyweb"><a href="#附加项目：pyweb" class="headerlink" title="附加项目：pyweb"></a>附加项目：pyweb</h2><h3 id="Python3-9"><a href="#Python3-9" class="headerlink" title="Python3"></a>Python3</h3><p><strong>首先</strong>请确保使用<code>pip install web.py==0.40-dev1</code></p><h4 id="main-py"><a href="#main-py" class="headerlink" title="main.py"></a>main.py</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> web</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"></span><br><span class="line">urls = (</span><br><span class="line">    <span class="string">'/'</span>, <span class="string">'index'</span>,</span><br><span class="line">    <span class="string">'/test'</span>, <span class="string">'test'</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">app = web.application(urls, globals())</span><br><span class="line"></span><br><span class="line">userid_rec_dict = &#123;&#125;</span><br><span class="line"><span class="keyword">with</span> open(<span class="string">'file.test'</span>, <span class="string">'r'</span>) <span class="keyword">as</span> fd:</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fd:</span><br><span class="line">        ss = line.strip().split(<span class="string">'\t'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(ss) != <span class="number">2</span>:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        userid = ss[<span class="number">0</span>].strip()</span><br><span class="line">        items = ss[<span class="number">1</span>].strip()</span><br><span class="line">        userid_rec_dict[userid] = items</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">index</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span><span class="params">(self)</span>:</span></span><br><span class="line">        params = web.input()</span><br><span class="line">        userid = params.get(<span class="string">'userid'</span>, <span class="string">''</span>)</span><br><span class="line">        <span class="keyword">if</span> userid <span class="keyword">not</span> <span class="keyword">in</span> userid_rec_dict:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'no rec!'</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> <span class="string">'\n'</span>.join(userid_rec_dict[userid].strip().split(<span class="string">''</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">test</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">GET</span><span class="params">(self)</span>:</span></span><br><span class="line">        print(web.input())</span><br><span class="line">        <span class="keyword">return</span> <span class="string">'222'</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    app.run()</span><br></pre></td></tr></table></figure><h4 id="file-test"><a href="#file-test" class="headerlink" title="file.test"></a>file.test</h4><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">zhangsan<span class="number">1</span></span><br><span class="line">lisi<span class="number">2</span></span><br><span class="line">wangwu<span class="number">3</span></span><br></pre></td></tr></table></figure><p>在<strong>终端</strong>输入<code>python main.py 12345</code>启动web服务器</p><ul><li><p>如遇到报错信息</p></li><li><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Traceback (most recent <span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\Program Files\Python\Python37\lib\site-packages\web\utils.py"</span>, line <span class="number">526</span>, <span class="keyword">in</span> take</span><br><span class="line">    yield <span class="keyword">next</span>(seq)</span><br><span class="line">StopIteration</span><br><span class="line">The above <span class="keyword">exception</span> was the direct cause <span class="keyword">of</span> the <span class="keyword">following</span> <span class="keyword">exception</span>:</span><br><span class="line">Traceback (most recent <span class="keyword">call</span> <span class="keyword">last</span>):</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\Python\hello.py"</span>, line <span class="number">6</span>, <span class="keyword">in</span> &lt;<span class="keyword">module</span>&gt;</span><br><span class="line">    app = web.application(urls, globals(),<span class="literal">True</span>)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\Program Files\Python\Python37\lib\site-packages\web\application.py"</span>, line <span class="number">62</span>, <span class="keyword">in</span> __init__</span><br><span class="line">    self.init_mapping(<span class="keyword">mapping</span>)</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\Program Files\Python\Python37\lib\site-packages\web\application.py"</span>, line <span class="number">130</span>, <span class="keyword">in</span> init_mapping</span><br><span class="line">    self.mapping = <span class="keyword">list</span>(utils.group(<span class="keyword">mapping</span>, <span class="number">2</span>))</span><br><span class="line">  <span class="keyword">File</span> <span class="string">"D:\Program Files\Python\Python37\lib\site-packages\web\utils.py"</span>, line <span class="number">531</span>, <span class="keyword">in</span> <span class="keyword">group</span></span><br><span class="line">    x = <span class="keyword">list</span>(take(seq, <span class="keyword">size</span>))</span><br><span class="line">RuntimeError: generator raised StopIteration</span><br></pre></td></tr></table></figure><p>修改Lib\site-packages\web 下的utils.py文件</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="addition">+ try:</span></span><br><span class="line">      yield next(seq) # 526行</span><br><span class="line"><span class="addition">+ except StopIteration:</span></span><br><span class="line"><span class="addition">+     return</span></span><br></pre></td></tr></table></figure></li></ul><p>在<strong>网页</strong>打开<code>http://0.0.0.0:12345/</code>即可访问页面</p><p>输入<strong>网址</strong><code>http://0.0.0.0:12345/?userid=zhangsan</code>页面显示<strong>1</strong></p><p>未来可拓展推荐系统 远程分词服务等</p><p><br></p><meting-js id="506092035" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;HDFS1.0与MapReduce&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/124000.jpg&quot; alt=&quot;troy-t-9sQgt_cR50c-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="复习笔记" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="HDFS1.0" scheme="https://alessa0.cn/tags/HDFS1-0/"/>
    
      <category term="MapReduce" scheme="https://alessa0.cn/tags/MapReduce/"/>
    
  </entry>
  
  <entry>
    <title>BigData复习笔记00：系统架构与常见业务</title>
    <link href="https://alessa0.cn/posts/92bad4a9/"/>
    <id>https://alessa0.cn/posts/92bad4a9/</id>
    <published>2019-07-17T08:10:55.000Z</published>
    <updated>2019-08-05T07:19:19.280Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">数据行业常用工具及常见业务介绍</p><br><img src="https://image.alessa0.cn/132845.jpg" alt="stephen-dawson-qwtCeJ5cLYs-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Chapter00. 软件架构与业务场景</p></blockquote><p></p><div class="text-center"><a class="btn" href="http://data.stats.gov.cn/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>国家数据</a></div><p></p><h1 id="系统架构"><a href="#系统架构" class="headerlink" title="系统架构"></a>系统架构</h1><h2 id="系统工具"><a href="#系统工具" class="headerlink" title="系统工具"></a>系统工具</h2><ul><li>底层架构：分布式文件系统</li><li>存储：分布式数据库</li><li>计算框架：离线批量/在线实时</li><li>工具：SQL封装查询/机器学习</li><li>调度：分布式锁</li><li><strong>算法</strong></li></ul><p><img src="https://image.alessa0.cn/145112.png" alt="系统架构"></p><h2 id="Lambda架构"><a href="#Lambda架构" class="headerlink" title="Lambda架构"></a>Lambda架构</h2><blockquote><p>离线批量+实时处理</p></blockquote><p>批量计算：延时高，可使用复杂算法多次处理，结果相对精确</p><p>实时计算：延时低，能够对新Item进行处理，实时推荐</p><p>Lambda架构结合批量计算和实时处理，能够给出相对完整的推荐结果</p><p><img src="https://image.alessa0.cn/063438.png" alt="未命名文件"></p><h2 id="数据"><a href="#数据" class="headerlink" title="数据"></a>数据</h2><p>数据来源基本来自两类：</p><blockquote><p>PGC：专业机构</p><p>UGC：用户</p></blockquote><p>物品(<strong>item</strong>)数据拥有不同属性（名称/描述/…），统称为<strong>元数据(metadata)</strong></p><p>用户(<strong>user</strong>)数据拥有不同行为（点击/收藏/支付…）</p><h1 id="业务场景"><a href="#业务场景" class="headerlink" title="业务场景"></a>业务场景</h1><h2 id="场景1：推荐流程"><a href="#场景1：推荐流程" class="headerlink" title="场景1：推荐流程"></a>场景1：推荐流程</h2><p>第一阶段（<strong>召回</strong>）：用Token检索Item/用Item检索Item，本质是找候选的过程【<strong>粗排</strong>】</p><p>第二阶段（<strong>过滤</strong>）：把候选集合中劣质的Item过滤掉</p><p>第三阶段（<strong>排序</strong>）：把好的Item排在前面【<strong>精排</strong>】</p><p>第四阶段（<strong>截断</strong>）：取Top-N(和产品形态有关)</p><h3 id="简易版"><a href="#简易版" class="headerlink" title="简易版"></a>简易版</h3><blockquote><ol><li><p>用户<strong>User</strong>点击物品<strong>ItemA</strong>，触发埋点</p></li><li><p>推荐系统引擎接收到埋点信息，发出请求，在<strong>索引</strong>数据库寻找<strong>与ItemA相关的</strong>ItemB、ItemC、ItemD…，并将结果<strong>取Top-N</strong>返回推荐给User</p></li><li><p>索引数据库(NoSQL)日常维护</p><ol><li><p>使用分词技术，将物品库中Item划分出各个特征，构建出<strong>正排表</strong>Item -&gt; TokenA, TokenB, TokenC…</p></li><li><p>根据正排表特征，构建出<strong>倒排表</strong>Token -&gt; ItemA, ItemB, ItermC…</p><blockquote><p>方式1：将倒排表写入索引库（搜索引擎搜索时根据分词token实时计算得出相关Item）</p><p>方式2：根据正排表与倒排表，构建出ItemA -&gt; ItemB, ItemC, ItermD… 写入索引库（索引库维护时根据Item分词token离线计算得出相关Item）</p></blockquote></li></ol></li></ol></blockquote><h3 id="进阶版"><a href="#进阶版" class="headerlink" title="进阶版"></a>进阶版</h3><blockquote><ol><li><p>用户User点击物品ItemA，触发埋点</p></li><li><p>推荐系统引擎接收到埋点信息，发出请求，在<strong>索引数据库A</strong>寻找与ItemA相关的ItemB、ItemC、ItemD…<strong>以算法1打分排序取Top-N1</strong>，在<strong>索引数据库B</strong>寻找与ItemA相关的Item1、Item2、Item3…<strong>以算法2打分排序取Top-N2</strong>，在<strong>索引数据库C</strong>寻找与ItemA相关的Item-I、Item-II、Item-III…</p></li><li><p>将不同索引库所得结果Item<strong>去除分数</strong>放入<strong>打分模型</strong>，按打分高低<strong>取出Top-N</strong>结果返回推荐给User</p></li><li><p><strong>每个</strong>索引数据库(NoSQL)日常维护</p><ol><li><p>使用分词技术，将物品库中Item划分出各个特征，<strong>按打分高低排序</strong>，构建出正排表Item -&gt; <strong>TokenA: ScoreA</strong>, <strong>TokenB: ScoreB</strong>, <strong>TokenC: ScoreC</strong>…</p></li><li><p>根据正排表特征，<strong>按打分高低排序</strong>，构建出倒排表Token -&gt; <strong>ItemA: Score1</strong>, <strong>ItemB: Score2</strong>, <strong>ItermC: Score3</strong>…</p><blockquote><p>方式1：将倒排表写入索引库（搜索引擎搜索时根据分词token实时计算得出相关Item）</p><p>方式2：根据正排表与倒排表，构建出ItemA -&gt; <strong>ItemB: Score-I</strong>, <strong>ItemC: Score-II</strong>, <strong>ItermD: Score-III</strong>… 写入索引库（索引库维护时根据Item分词token离线计算得出相关Item）</p></blockquote></li></ol></li></ol></blockquote><p><img src="https://image.alessa0.cn/082726.png" alt="推荐流程"></p><h2 id="场景2：搜索引擎"><a href="#场景2：搜索引擎" class="headerlink" title="场景2：搜索引擎"></a>场景2：搜索引擎</h2><p>常用搜索场景：人与内容（PC时代） -&gt; <strong>人与服务</strong>（移动时代）</p><blockquote><p>各大门户网站利用平台优势聚合大量信息，为用户提供桥梁，<strong>“有求必应”</strong></p><p>连接用户与内容，连接用户与服务</p></blockquote><p><strong>搜索引擎解决方案Demo</strong>：使用的基于MapReduce的建库系统(建库流)</p><ul><li>目的：构建供检索使用的索引和摘要</li><li>输入：网页</li><li>输出：索引和摘要</li><li>处理方法：多轮Map-Reduce</li><li>页面解析并处理</li><li>页面属性输出正排表</li><li>分析构建倒排表</li><li>结果分析Merge合并</li></ul><p><img src="https://image.alessa0.cn/140821.png" alt="搜索引擎三段式结构"></p><h2 id="场景3：广告系统"><a href="#场景3：广告系统" class="headerlink" title="场景3：广告系统"></a>场景3：广告系统</h2><blockquote><ul><li>参与者：网民/广告主/平台</li><li>广告触发：Keyword Targeting<ul><li>广告主/网民通过关键字表达需求</li><li>网民输入query与广告主购买的Keyword进行匹配</li></ul></li><li>CTR点击率预估：机器学习<ul><li>点击率用于广告排序</li><li>提升搜索引擎收益</li><li>保护网民利益</li></ul></li><li>广告排序：关键词广告拍卖<ul><li>每次动态广告展现都是一次动态的拍卖</li><li>排序函数</li></ul></li></ul></blockquote><p>基本流程：</p><ol><li>产品发布，广告主向平台购买相对应关键词Token</li><li>平台将产品加入广告库，同时更新广告索引库</li><li>索引库维护，更新倒排表中产品排序</li><li>平台根据索引库产品排序，在平台展现产品广告给网民</li><li>网民主动点击广告，或根据网民搜索输入的query与广告库索引进行匹配检索，展现给网民</li></ol><h1 id="项目结构Demo"><a href="#项目结构Demo" class="headerlink" title="项目结构Demo"></a>项目结构Demo</h1><p><img src="https://image.alessa0.cn/142106.png" alt="项目结构Demo"></p><p><br></p><meting-js id="30431364" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="http://www.hui-wang.info/2017/01/20/移动应用架构之IO蒸馏/">移动应用架构之IO蒸馏</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;数据行业常用工具及常见业务介绍&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/132845.jpg&quot; alt=&quot;stephen-dawson-qwtCeJ5cLYs-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="复习笔记" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="业务" scheme="https://alessa0.cn/tags/%E4%B8%9A%E5%8A%A1/"/>
    
      <category term="架构" scheme="https://alessa0.cn/tags/%E6%9E%B6%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>Flink电商团购项目（一）</title>
    <link href="https://alessa0.cn/posts/451f3483/"/>
    <id>https://alessa0.cn/posts/451f3483/</id>
    <published>2019-05-17T08:20:11.000Z</published>
    <updated>2019-08-05T07:19:19.281Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Flink项目环境搭建</p><br><img src="https://image.alessa0.cn/090812.jpg" alt="daniel-chen-546446-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>第一章 大数据集群搭建</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://flink.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Flink</a></div><p></p><h1 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h1><h2 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h2><p>CentOS-7-x86_64-Minimal-1810.iso</p><ul><li><strong>flink-master1</strong> 192.168.69.121 <strong>2core</strong> <strong>2G</strong></li><li><strong>flink-master2</strong> 192.168.69.122 <strong>2core</strong> <strong>2G</strong></li><li><strong>flink-slave1</strong> 192.168.69.123 <strong>1core</strong> <strong>2G</strong></li><li><strong>flink-slave2</strong> 192.168.69.124 <strong>1core</strong> <strong>2G</strong></li><li><strong>flink-slave3</strong> 192.168.69.125 <strong>1core</strong> <strong>2G</strong></li></ul><h2 id="Hadoop集群组件列表"><a href="#Hadoop集群组件列表" class="headerlink" title="Hadoop集群组件列表"></a>Hadoop集群组件列表</h2><div class="table-container"><table><thead><tr><th>组件</th><th style="text-align:center">Master1</th><th style="text-align:center">Master2</th><th style="text-align:center">Slave1</th><th style="text-align:center">Slave2</th><th style="text-align:center">Slave3</th></tr></thead><tbody><tr><td>jdk1.8.0_212</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>scala-2.11.12</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>miniconda3</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>hadoop2.7.0</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>kafka0.11</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>mariadb/mariadb-server</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td>Hive2.2.0</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td>zookeeper 3.4.9</td><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>Flume1.9</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr><tr><td>Flink1.7</td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td><td style="text-align:center"><strong>√</strong></td></tr></tbody></table></div><blockquote><p>组件安装步骤参考往期系列文章</p><p><a href="https://alessa0.cn/posts/aaa0d5f4/">Flink电商团购项目（零）</a><br><a href="https://alessa0.cn/categories/技术/大数据/环境搭建/">Hadoop环境搭建</a></p></blockquote><p><br></p><meting-js id="1338746736" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="https://blogs.kainy.cn/2013/06/通行证项目前端开发小结/">通行证项目前端开发小结</a></li><li><a href="https://blogs.kainy.cn/2013/04/拾贝电台开源了/">拾贝电台开源了</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Flink项目环境搭建&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/090812.jpg&quot; alt=&quot;daniel-chen-546446-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="项目实战" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
      <category term="Flink电商团购" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Flink%E7%94%B5%E5%95%86%E5%9B%A2%E8%B4%AD/"/>
    
      <category term="01-大数据集群搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Flink%E7%94%B5%E5%95%86%E5%9B%A2%E8%B4%AD/01-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Flink" scheme="https://alessa0.cn/tags/Flink/"/>
    
      <category term="项目" scheme="https://alessa0.cn/tags/%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="电商" scheme="https://alessa0.cn/tags/%E7%94%B5%E5%95%86/"/>
    
  </entry>
  
  <entry>
    <title>Flink电商团购项目（零）：环境搭建</title>
    <link href="https://alessa0.cn/posts/8d61cd2a/"/>
    <id>https://alessa0.cn/posts/8d61cd2a/</id>
    <published>2019-05-17T08:20:10.000Z</published>
    <updated>2019-08-05T07:19:19.283Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --><p></p><p class="description">Flink项目环境搭建</p><br><img src="https://image.alessa0.cn/045237.jpg" alt="janko-ferlic-214224-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>第一章 大数据集群搭建</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://flink.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Flink</a></div><p></p><h1 id="集群组件安装"><a href="#集群组件安装" class="headerlink" title="集群组件安装"></a>集群组件安装</h1><h2 id="安装JDK"><a href="#安装JDK" class="headerlink" title="安装JDK"></a>安装JDK</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp jdk-8u212-linux-x64.tar.gz /usr/aboutyun</li><li>cd /usr/aboutyun</li><li>tar zxvf jdk-8u212-linux-x64.tar.gz</li><li>rm -rf jdk-8u212-linux-x64.tar.gz</li><li>mv jdk1.8.0_212 jdk</li></ul><p><strong>#配置JDK环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET JAVA PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/aboutyun/jdk </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">CLASSPATH</span>=.:$CLASSPATH:$JAVA_HOME/lib </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><h2 id="安装Scala"><a href="#安装Scala" class="headerlink" title="安装Scala"></a>安装Scala</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp scala-2.11.12.tgz /usr/aboutyun</li><li>cd /usr/aboutyun</li><li>tar zxvf scala-2.11.12.tgz</li><li>rm -rf scala-2.11.12.tgz</li><li>mv scala-2.11.12 scala</li></ul><p><strong>#配置Scala环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET SCALA PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SCALA_HOME</span>=/usr/aboutyun/scala </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$SCALA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><h2 id="安装miniconda3"><a href="#安装miniconda3" class="headerlink" title="安装miniconda3"></a>安装miniconda3</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp Miniconda3-latest-Linux-x86_64.sh /usr/local/src/</li><li>cd /usr/local/src</li><li>sudo yum -y install bzip2</li><li>sh Miniconda3-latest-Linux-x86_64.sh</li><li>rm -rf Miniconda3-latest-Linux-x86_64.sh</li></ul><p><strong>#配置环境变量：</strong></p><ul><li>source ~/.bashrc</li></ul><p><strong>#更新conda环境：</strong></p><ul><li>conda update —all</li></ul><h2 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h2><span class="label danger">仅在Slave节点</span><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp zookeeper-3.4.9.tar.gz /usr/aboutyun/</li><li>cd /usr/aboutyun/</li><li>tar zxvf zookeeper-3.4.9.tar.gz</li><li>rm -rf zookeeper-3.4.9.tar.gz</li><li>mv zookeeper-3.4.9 zookeeper</li><li>cd zookeeper</li></ul><p><strong>#配置Zookeeper环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET ZOOKEEPER PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">ZOOKEEPER_HOME</span>=/usr/aboutyun/zookeeper </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#修改Zookeeper配置</strong></p><ul><li>mkdir data</li><li>mkdir logs</li><li>cd conf</li><li>cp zoo_sample.cfg zoo.cfg</li><li>vim zoo.cfg</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataDir</span>=/usr/aboutyun/zookeeper/data </span><br><span class="line"><span class="attr">dataLogDir</span>=/usr/aboutyun/zookeeper/logs </span><br><span class="line"><span class="attr">server.1</span>=flink-slave1:<span class="number">2888</span>:<span class="number">3888</span> </span><br><span class="line"><span class="attr">server.2</span>=flink-slave2:<span class="number">2888</span>:<span class="number">3888</span> </span><br><span class="line"><span class="attr">server.3</span>=flink-slave3:<span class="number">2888</span>:<span class="number">3888</span></span><br></pre></td></tr></table></figure><p><strong>#分别添加ID</strong></p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#Slave1 </span></span><br><span class="line">echo <span class="string">"1"</span> &gt; <span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/zookeeper/</span>data/myid </span><br><span class="line"><span class="meta">#Slave2 </span></span><br><span class="line">echo <span class="string">"2"</span> &gt; <span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/zookeeper/</span>data/myid </span><br><span class="line"><span class="meta">#Slave3 </span></span><br><span class="line">echo <span class="string">"3"</span> &gt; <span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/zookeeper/</span>data/myid</span><br></pre></td></tr></table></figure><p><strong>#启动Zookeeper服务</strong></p><ul><li>zkServer.sh start</li></ul><p><strong>#查看运行状态</strong></p><ul><li><p>zkServer.sh status</p></li><li><p>jps</p></li></ul><p><strong>#关闭Zookeeper服务</strong></p><ul><li>zkServer.sh stop</li></ul><h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp hadoop-2.7.0.tar.gz /usr/aboutyun/</li><li>cd /usr/aboutyun/</li><li>tar zxvf hadoop-2.7.0.tar.gz</li><li>rm -rf hadoop-2.7.0.tar.gz</li><li>mv hadoop-2.7.0 hadoop</li><li>cd hadoop</li></ul><p><strong>#配置Hadoop环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET HADOOP PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/aboutyun/hadoop</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/bin </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/sbin</span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_CONF_DIR</span>=<span class="variable">$HADOOP_HOME</span>/etc/hadoop</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#创建临时目录和文件目录</strong></p><ul><li>mkdir -p /usr/aboutyun/hadoop/dfs/name</li><li>mkdir -p /usr/aboutyun/hadoop/dfs/data</li><li>mkdir -p /usr/aboutyun/hadoop/tmp/dfs</li><li>mkdir -p /usr/aboutyun/hadoop/journal</li><li>mkdir -p /usr/aboutyun/hadoop/yarn/logs</li></ul><p><strong>#修改Hadoop配置文件</strong></p><ul><li>cd etc/hadoop</li><li>vim hadoop-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/aboutyun/jdk</span><br></pre></td></tr></table></figure><ul><li>vim yarn-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/aboutyun/jdk</span><br></pre></td></tr></table></figure><ul><li>vim slaves</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink-slave1 </span><br><span class="line">flink-slave2</span><br><span class="line">flink-slave3</span><br></pre></td></tr></table></figure><ul><li>vim core-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>fs.defaultFS<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>hdfs:<span class="comment">//mycluster&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>默认文件系统的名称。一个URI，其方案和权限决定了FileSystem的实现。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>ha.zookeeper.quorum<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-slave1:<span class="number">2181</span>,flink-slave2:<span class="number">2181</span>,flink-slave3:<span class="number">2181</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>由逗号分隔的ZooKeeper服务器地址列表，由ZKFailoverController在自动故障转移中使用。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>hadoop.tmp.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hadoop/</span>tmp<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>数据目录目录<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.ha.fencing.methods<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>sshfence</span><br><span class="line">shell(<span class="meta-keyword">/bin/</span>true)<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>用于服务防护的防护方法列表。可能包含内置方法（例如shell和sshfence）或用户定义的方法。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/home/</span>aboutyun/.ssh/id_rsa<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>用于内置sshfence fencer的SSH私钥文件。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>io.file.buffer.size<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">131072</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>SequenceFiles中使用的读/写缓冲区的大小。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>ipc.client.connect.max.retries<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">100</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>客户端为建立服务器连接而重试的次数。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>ipc.client.connect.retry.interval<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">10000</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>客户端在重试建立服务器连接之前将等待的毫秒数。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><ul><li>vim hdfs-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.nameservices<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>mycluster<span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.ha.namenodes.mycluster<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-master1,flink-master2<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>给定名称服务的前缀包含给定名称服务的逗号分隔的名称节点列表。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.rpc-address.mycluster.flink-master1<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-master1:<span class="number">8020</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.rpc-address.mycluster.flink-master2<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-master2:<span class="number">8020</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.http-address.mycluster.flink-master1<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-master1:<span class="number">50070</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.http-address.mycluster.flink-master2<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>flink-master2:<span class="number">50070</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.shared.edits.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>qjournal:<span class="comment">//flink-slave1:8485;flink-slave2:8485;flink-slave3:8485/mycluster&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>HA群集中多个名称节点之间的共享存储上的目录。此目录将由活动写入并由备用数据库读取，以保持命名空间同步。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>配置Java类的名称，DFS客户端将使用该名称来确定哪个NameNode是当前的Active，以及哪个NameNode当前正在为客户端请求提供服务。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.ha.automatic-failover.enabled<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>true<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>是否启用自动故障转移。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.replication<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">3</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.permissions.enabled<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>false<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>如果为“true”，则启用HDFS中的权限检查。如果为“false”，则关闭权限检查，但所有其他行为都保持不变。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.journalnode.edits.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hadoop/</span>journal<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>指定JournalNode在本地磁盘存放数据的位置<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.name.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:<span class="comment">///usr/aboutyun/hadoop/dfs/name&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>设置namenode存放路径<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.datanode.data.dir<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>file:<span class="comment">///usr/aboutyun/hadoop/dfs/data&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>设置datanode存放径路<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.blocksize<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">268435456</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>大型文件系统的HDFS块大小为<span class="number">256</span>MB。<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>dfs.namenode.handler.count<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">100</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>namenode的服务器线程数<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><ul><li>mv mapred-site.xml.template mapred-site.xml</li><li>vim mapred-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.framework.name<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span>yarn<span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>指定mr框架为yarn方式<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.map.memory.mb<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">512</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">        <span class="params">&lt;description&gt;</span>每个Map任务的物理内存限制<span class="params">&lt;/description&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.reduce.memory.mb<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">512</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">        <span class="params">&lt;description&gt;</span>每个Reduce任务的物理内存限制<span class="params">&lt;/description&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.jobhistory.address<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">10020</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>MapReduce JobHistory服务器IPC主机：端口<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.jobhistory.webapp.address<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">0.0</span><span class="number">.0</span><span class="number">.0</span>:<span class="number">19888</span><span class="params">&lt;/value&gt;</span></span><br><span class="line">        <span class="params">&lt;description&gt;</span>MapReduce JobHistory服务器Web浏览时的主机：端口<span class="params">&lt;/description&gt;</span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br><span class="line">    <span class="params">&lt;property&gt;</span></span><br><span class="line">        <span class="params">&lt;name&gt;</span>mapreduce.application.classpath<span class="params">&lt;/name&gt;</span></span><br><span class="line">        <span class="params">&lt;value&gt;</span></span><br><span class="line">          <span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hadoop/</span>etc/hadoop,</span><br><span class="line">          <span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hadoop/</span>share<span class="meta-keyword">/hadoop/</span>common<span class="comment">/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/common/lib/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/hdfs/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/hdfs/lib/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/mapreduce/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/mapreduce/lib/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/yarn/*,</span></span><br><span class="line"><span class="comment">          /usr/aboutyun/hadoop/share/hadoop/yarn/lib/*        </span></span><br><span class="line"><span class="comment">        &lt;/value&gt;</span></span><br><span class="line"><span class="comment">    &lt;/property&gt;</span></span><br><span class="line"><span class="comment">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><ul><li>vim yarn-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.recovery.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>启动后启用RM以恢复状态。如果为true，则必须指定yarn.resourcemanager.store.class。<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.store.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.yarn.server.resourcemanager.recovery.ZKRMStateStore<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>用作持久存储的类。<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink-slave1:2181,flink-slave2:2181,flink-slave3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>ZooKeeper服务的地址，多个地址使用逗号隔开<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>启用RM高可用性。启用时，（1）默认情况下，RM以待机模式启动，并在提示时转换为活动模式。（2）RM集合中的节点列在yarn.resourcemanager.ha.rm-ids中（3）如果明确指定了yarn.resourcemanager.ha.id，则每个RM的id来自yarn.resourcemanager.ha.id或者可以通过匹配yarn.resourcemanager.address。<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>启用HA时群集中的RM节点列表。最少2个<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink-master1:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink-master2:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster-yarn-ha<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>集群HA的id，用于在ZooKeeper上创建节点，区分使用同一个ZooKeeper集群的不同Hadoop集群<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink-master1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>主机名<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>flink-master2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>主机名<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>reducer取数据的方式是mapreduce_shuffle<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.memory-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2048<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>每个节点可用内存,单位MB<span class="tag">&lt;/<span class="name">discription</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.resource.cpu-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>每个节点可用cpu<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>   </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>512<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>单个任务可申请最少内存，默认1024MB<span class="tag">&lt;/<span class="name">discription</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.maximum-allocation-mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>单个任务可申请最大内存，默认8192MB<span class="tag">&lt;/<span class="name">discription</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>最小的cores 1 个，默认的就是一个<span class="tag">&lt;/<span class="name">discription</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.scheduler.minimum-allocation-vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>最多可分配的cores 2 个<span class="tag">&lt;/<span class="name">discription</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.pmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.vmem-check-enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation-enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>是否开启聚合日志<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>定义NM唤醒上载日志文件的频率。默认值为-1。默认情况下，应用程序完成后将上载日志。通过设置此配置，可以在应用程序运行时定期上载日志。可设置的最小滚动间隔秒数为3600。<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log.server.url<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>http://flink-master1:19888/jobhistory/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span> 配置日志服务器的地址<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.log-aggregation.retain-seconds<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span> 在删除聚合日志之前保留多长时间。-1禁用。单位是秒<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.log-dirs<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/aboutyun/hadoop/yarn/logs/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>nodemanager存放container日志的本地路径<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.remote-app-log-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/tmp/logs<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">discription</span>&gt;</span>nodemanager存放container日志的本地路径<span class="tag">&lt;/<span class="name">discription</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.am.max-attempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>The maximum number of application master execution attempts.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>cd /usr/aboutyun/hadoop/sbin</li></ul><p><strong>#编辑 start-dfs.sh，stop-dfs.sh 脚本</strong></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在开始处 #!/usr/bin/env bash 的下面，增加以下内容：</span></span><br><span class="line"><span class="attr">HDFS_DATANODE_USER</span>=root</span><br><span class="line"><span class="attr">HDFS_DATANODE_SECURE_USER</span>=hdfs</span><br><span class="line"><span class="attr">HDFS_ZKFC_USER</span>=root</span><br><span class="line"><span class="attr">HDFS_JOURNALNODE_USER</span>=root</span><br><span class="line"><span class="attr">HDFS_NAMENODE_USER</span>=root</span><br><span class="line"><span class="attr">HDFS_SECONDARYNAMENODE_USER</span>=root</span><br></pre></td></tr></table></figure><p><strong>#编辑 start-yarn.sh，stop-yarn.sh 脚本</strong></p><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在开始处 #!/usr/bin/env bash 的下面，增加以下内容：</span></span><br><span class="line"><span class="attr">YARN_RESOURCEMANAGER_USER</span>=root</span><br><span class="line"><span class="attr">HADOOP_SECURE_DN_USER</span>=yarn </span><br><span class="line"><span class="attr">YARN_NODEMANAGER_USER</span>=root</span><br></pre></td></tr></table></figure><p><strong>#启用JournalNode集群</strong></p><ul><li>hadoop-daemon.sh start journalnode</li></ul><p><strong>#初始化NameNode(仅master1)</strong></p><ul><li>hadoop namenode -format</li></ul><p><strong>#格式化Zookeeper(仅master1)</strong></p><ul><li>hdfs zkfc -formatZK</li></ul><p><strong>#启动NameNode(仅master1)</strong></p><ul><li>hadoop-daemon.sh start namenode</li></ul><p><strong>#将 NameNode 数据复制到备用 NameNode(仅master2)</strong></p><ul><li>hdfs namenode -bootstrapStandby</li><li>hadoop-daemon.sh start namenode</li></ul><p><strong>#启动Hadoop集群</strong></p><ul><li>start-dfs.sh (仅master1)</li><li>start-yarn.sh (仅master1)</li><li>yarn-daemon.sh start resourcemanager(仅master2)</li></ul><p><strong>#监控页面</strong></p><ul><li><a href="http://flink-master1:50070/" target="_blank" rel="noopener">HDFS(master1)</a></li><li><a href="http://flink-master2:50070/" target="_blank" rel="noopener">HDFS(master2)</a></li><li><a href="http://flink-master1:8088/" target="_blank" rel="noopener">YARN(master1)</a></li><li><a href="http://flink-master1:8088/" target="_blank" rel="noopener">YARN(master2)</a></li></ul><h2 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h2><span class="label danger">仅在Master节点</span><p><strong>#安装mysql</strong></p><ul><li>yum -y install mariadb-server mariadb</li><li>rpm -q mariadb mariadb-server</li></ul><p><strong>#设置mysql开机启动</strong></p><ul><li>systemctl enable mariadb</li><li>systemctl daemon-reload</li></ul><p><strong>#开启mysql</strong></p><ul><li>systemctl start mariadb</li></ul><p><strong>#关闭mysql</strong></p><ul><li>systemctl stop mariadb</li></ul><p><strong>#重启mysql</strong></p><ul><li>systemctl restart mariadb</li></ul><p><strong>#查看mysql状态</strong></p><ul><li>systemctl status mariadb</li></ul><p><strong>#通过内置的安全脚本实现对数据库的安全保护</strong></p><ul><li>mysql_secure_installation</li></ul><p><strong>#登录root账户</strong></p><ul><li>mysql -uroot -p</li></ul><p><strong>#创建账户</strong></p><ul><li>CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</li><li>GRANT ALL ON metastore.* TO ‘hive’@’%’ IDENTIFIED BY ‘123’;</li></ul><p><strong>#刷新权限</strong></p><ul><li>flush privileges;</li></ul><h2 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h2><span class="label danger">仅在Master节点</span><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp apache-hive-2.2.0-bin.tar.gz /usr/aboutyun/</li><li>cd /usr/aboutyun/</li><li>tar zxvf apache-hive-2.2.0-bin.tar.gz</li><li>rm -rf apache-hive-2.2.0-bin.tar.gz</li><li>mv apache-hive-2.2.0-bin hive</li></ul><p><strong>#配置Hive环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET Hive PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HIVE_HOME</span>=/usr/aboutyun/hive </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#配置mysql驱动包</strong></p><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp mysql-connector-java-5.1.47.tar.gz /usr/aboutyun/</li><li>cd /usr/aboutyun/</li><li>tar zxvf mysql-connector-java-5.1.47.tar.gz</li><li>rm -rf mysql-connector-java-5.1.47.tar.gz</li><li>cp mysql-connector-java-5.1.47-bin.jar /usr/aboutyun/hive/lib/</li></ul><p><strong>#更换jline包（版本不一致）</strong></p><ul><li>cp hive/lib/jline-2.12.jar /usr/aboutyun/hadoop/share/hadoop/yarn/lib/</li></ul><p><strong>#配置hive</strong></p><ul><li>cd hive</li><li>mkdir -p data/hive/log</li><li>mkdir -p data/hive/tmp</li><li>mkdir -p data/hive/warehouse</li><li>cd conf</li><li>cp hive-env.sh.template hive-env.sh</li><li>vim hive-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/aboutyun/jdk </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/aboutyun/hadoop </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HIVE_HOME</span>=/usr/aboutyun/hive </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HIVE_CONF_DIR</span>=/usr/aboutyun/hive/conf </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HIVE_AUX_JARS</span>=/usr/aboutyun/hive/lib</span><br></pre></td></tr></table></figure><ul><li>cp hive-default.xml.template hive-site.xml</li><li>vim hive-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="params">&lt;configuration&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span>jdbc:mysql:<span class="comment">//localhost:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; </span></span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span>com.mysql.jdbc.Driver<span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span>hive<span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionPassword<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span><span class="number">123</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>hive.metastore.warehouse.dir<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hive/</span>data<span class="meta-keyword">/hive/</span>warehouse<span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>hive.exec.scratchdir<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hive/</span>data<span class="meta-keyword">/hive/</span>tmp<span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;property&gt;</span> </span><br><span class="line"><span class="params">&lt;name&gt;</span>hive.querylog.location<span class="params">&lt;/name&gt;</span> </span><br><span class="line"><span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>aboutyun<span class="meta-keyword">/hive/</span>data<span class="meta-keyword">/hive/</span>log<span class="params">&lt;/value&gt;</span> </span><br><span class="line"><span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><p>把{system:java.io.tmpdir} 改成 /usr/aboutyun/hive/data/hive/tmp</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:%s/$&#123;system<span class="function">:java.io.tmpdir</span>&#125;/\<span class="string">/usr</span>\<span class="string">/aboutyun</span>\<span class="string">/hive</span>\<span class="string">/data</span>\<span class="string">/hive</span>\<span class="string">/tmp/g</span></span><br></pre></td></tr></table></figure><p>把 {system:user.name} 改成 {user.name}</p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">:%s/</span><span class="variable">$&#123;</span><span class="symbol">system:</span>user.name&#125;/aboutyun/g</span><br></pre></td></tr></table></figure><p><strong>#初始化hive(MYSQL版)</strong></p><ul><li>schematool -dbType mysql -initSchema</li></ul><h3 id="安装Flume"><a href="#安装Flume" class="headerlink" title="安装Flume"></a>安装Flume</h3><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp apache-flume-1.9.0-bin.tar.gz /usr/aboutyun/</li><li>cd /usr/aboutyun/</li><li>tar zxvf apache-flume-1.9.0-bin.tar.gz</li><li>rm -rf apache-flume-1.9.0-bin.tar.gz</li><li>mv apache-flume-1.9.0-bin flume</li><li>cd flume</li></ul><p><strong>#Hbase环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET FLUME PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">FLUME_HOME</span>=/usr/aboutyun/flume </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#修改Flume配置</strong></p><ul><li>cd conf</li><li>cp flume-env.sh.template flume-env.sh</li><li>vim flume-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/aboutyun/jdk</span><br></pre></td></tr></table></figure><p><strong>#验证</strong></p><p><strong>Server</strong></p><figure class="highlight stata"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># NetCat </span><br><span class="line">flume-ng agent --<span class="keyword">conf</span> <span class="keyword">conf</span> --<span class="keyword">conf</span>-<span class="keyword">file</span> <span class="keyword">conf</span>/flume-netcat.<span class="keyword">conf</span> --name=agent -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line"># Exec </span><br><span class="line">flume-ng agent --<span class="keyword">conf</span> <span class="keyword">conf</span> --<span class="keyword">conf</span>-<span class="keyword">file</span> <span class="keyword">conf</span>/flume-exec.<span class="keyword">conf</span> --name=agent -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line"># Avro </span><br><span class="line">flume-ng agent --<span class="keyword">conf</span> <span class="keyword">conf</span> --<span class="keyword">conf</span>-<span class="keyword">file</span> <span class="keyword">conf</span>/flume-netcat.<span class="keyword">conf</span> --name=agent -Dflume.root.logger=DEBUG,console</span><br></pre></td></tr></table></figure><p><strong>Client</strong></p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># NetCat </span></span><br><span class="line">flume-ng agent --conf conf --conf-file conf/flume-netcat.conf <span class="attribute">--name</span>=agent -Dflume.root.<span class="attribute">logger</span>=INFO,console</span><br><span class="line"></span><br><span class="line"><span class="comment"># Exec </span></span><br><span class="line"><span class="keyword">while</span> <span class="literal">true</span>;<span class="keyword">do</span> echo `date` &gt;&gt; /data/hadoop/flume/test.txt ; sleep 1; done</span><br><span class="line"></span><br><span class="line"><span class="comment"># Avro </span></span><br><span class="line">telnet master 44444</span><br></pre></td></tr></table></figure><h2 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp kafka_2.11-0.11.0.3.tgz /usr/aboutyun</li><li>cd /usr/aboutyun</li><li>tar zxvf kafka_2.11-0.11.0.3.tgz</li><li>rm -rf kafka_2.11-0.11.0.3.tgz</li><li>mv kafka_2.11-0.11.0.3 kafka</li><li>cd kafka</li></ul><p><strong>#Kafka环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET KAFKA PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">KAFKA_HOME</span>=/usr/aboutyun/kafka </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#修改Kafka配置</strong></p><ul><li>mkdir logs</li><li>cd config</li><li>vim server.properties</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">log.dirs</span>=/usr/aboutyun/kafka/logs </span><br><span class="line"><span class="attr">zookeeper.connect</span>=flink-slave1:<span class="number">2181</span>,flink-slave2:<span class="number">2181</span>,flink-slave3:<span class="number">2181</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">#Master1 </span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="number">0</span></span><br><span class="line"><span class="comment">#Master2 </span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="number">1</span></span><br><span class="line"><span class="comment">#Slave1 </span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="number">2</span> </span><br><span class="line"><span class="comment">#Slave2 </span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="number">3</span></span><br><span class="line"><span class="comment">#Slave3 </span></span><br><span class="line"><span class="attr">broker.id</span>=<span class="number">4</span></span><br></pre></td></tr></table></figure><p><strong>普通启动：</strong></p><ul><li>kafka-server-start.sh -daemon /usr/aboutyun/kafka/config/server.properties</li></ul><p><strong>关闭集群：</strong></p><ul><li>kafka-server-stop.sh</li></ul><h2 id="安装Flink"><a href="#安装Flink" class="headerlink" title="安装Flink"></a>安装Flink</h2><ul><li>cd /mnt/hgfs/aboutyun</li><li>cp flink-1.7.2-bin-hadoop27-scala_2.11.tgz /usr/aboutyun</li><li>cd /usr/aboutyun</li><li>tar zxvf flink-1.7.2-bin-hadoop27-scala_2.11.tgz</li><li>rm -rf flink-1.7.2-bin-hadoop27-scala_2.11.tgz</li><li>mv flink-1.7.2 flink</li><li>cd flink</li></ul><p><strong>#Flink环境变量</strong></p><ul><li>vim /etc/profile</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET FLINK PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">FLINK_HOME</span>=/usr/aboutyun/flink </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$FLINK_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><p><strong>#修改Flink配置</strong></p><ul><li>cd conf</li><li>vim flink-conf.yaml</li></ul><figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改如下内容</span></span><br><span class="line"><span class="attribute">jobmanager.rpc.address</span>: flink-master1</span><br><span class="line"><span class="attribute">high-availability</span>: zookeeper</span><br><span class="line"><span class="attribute">high-availability.zookeeper.path.root</span>: /flink</span><br><span class="line"><span class="attribute">high-availability.cluster-id</span>: flink</span><br><span class="line"><span class="attribute">high-availability.storageDir</span>: hdfs:///flink/ha/</span><br><span class="line"><span class="attribute">high-availability.zookeeper.quorum</span>: flink-slave1:2181,flink-slave2:2181,flink-slave3:2181</span><br><span class="line"><span class="attribute">yarn.application-attempts</span>: 10</span><br></pre></td></tr></table></figure><ul><li>vim masters</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">flink-master1</span><span class="selector-pseudo">:8081</span></span><br><span class="line"><span class="selector-tag">flink-master2</span><span class="selector-pseudo">:8081</span></span><br></pre></td></tr></table></figure><ul><li>vim slaves</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">flink-slave1 </span><br><span class="line">flink-slave2</span><br><span class="line">flink-slave3</span><br></pre></td></tr></table></figure><p><strong>#启动Standalone集群HA</strong></p><ul><li>start-cluster.sh</li></ul><p><strong>#关闭Standalone集群</strong></p><ul><li>stop-cluster.sh</li></ul><p><strong>#启动YARN集群HA</strong></p><ul><li>yarn-session.sh</li></ul><p><strong>#监控网页</strong></p><p><a href="http://flink-master1:8081/" target="_blank" rel="noopener">Flink(master1)</a></p><p><br></p><meting-js id="472361096" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="https://blogs.kainy.cn/2013/06/通行证项目前端开发小结/">通行证项目前端开发小结</a></li><li><a href="https://blogs.kainy.cn/2013/04/拾贝电台开源了/">拾贝电台开源了</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Flink项目环境搭建&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/045237.jpg&quot; alt=&quot;janko-ferlic-214224-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="项目实战" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"/>
    
      <category term="Flink电商团购" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Flink%E7%94%B5%E5%95%86%E5%9B%A2%E8%B4%AD/"/>
    
      <category term="01-大数据集群搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/Flink%E7%94%B5%E5%95%86%E5%9B%A2%E8%B4%AD/01-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Flink" scheme="https://alessa0.cn/tags/Flink/"/>
    
      <category term="项目" scheme="https://alessa0.cn/tags/%E9%A1%B9%E7%9B%AE/"/>
    
      <category term="电商" scheme="https://alessa0.cn/tags/%E7%94%B5%E5%95%86/"/>
    
  </entry>
  
  <entry>
    <title>傻瓜式CDH集群部署指南</title>
    <link href="https://alessa0.cn/posts/5578f504/"/>
    <id>https://alessa0.cn/posts/5578f504/</id>
    <published>2019-05-17T06:40:59.000Z</published>
    <updated>2019-08-05T07:19:19.283Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --><p></p><p class="description">CDH环境配置</p><br><img src="https://image.alessa0.cn/074403.jpg" alt="clay-banks-1554989-unsplash"><a id="more"></a><p></p><blockquote class="blockquote-center"><p>单机内存最低8G</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://www.cloudera.com/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Cloudera</a></div><p></p><h1 id="集群环境"><a href="#集群环境" class="headerlink" title="集群环境"></a>集群环境</h1><h2 id="系统"><a href="#系统" class="headerlink" title="系统"></a>系统</h2><p>CentOS-7-x86_64-Minimal-1810.iso</p><ul><li><strong>cdh-master</strong> 192.168.69.111 <strong>4core</strong> <strong>16G</strong></li><li><strong>cdh-slave1</strong> 192.168.69.112 <strong>4core</strong> <strong>8G</strong></li><li><strong>cdh-slave2</strong> 192.168.69.113 <strong>4core</strong> <strong>8G</strong></li></ul><h1 id="关闭防火墙及修改hosts"><a href="#关闭防火墙及修改hosts" class="headerlink" title="关闭防火墙及修改hosts"></a>关闭防火墙及修改hosts</h1><h2 id="永久关闭内核防火墙"><a href="#永久关闭内核防火墙" class="headerlink" title="永久关闭内核防火墙"></a>永久关闭内核防火墙</h2><ul><li>vim /etc/selinux/config</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 修改如下信息</span></span><br><span class="line"><span class="attr">SELINUX</span>=disabled</span><br></pre></td></tr></table></figure><h2 id="关闭系统防火墙"><a href="#关闭系统防火墙" class="headerlink" title="关闭系统防火墙"></a>关闭系统防火墙</h2><h3 id="停止firewall"><a href="#停止firewall" class="headerlink" title="停止firewall"></a>停止firewall</h3><ul><li>systemctl stop firewalld.service</li></ul><h3 id="禁止firewall开机启动"><a href="#禁止firewall开机启动" class="headerlink" title="禁止firewall开机启动"></a>禁止firewall开机启动</h3><ul><li>systemctl disable firewalld.service</li></ul><h2 id="修改hosts文件"><a href="#修改hosts文件" class="headerlink" title="修改hosts文件"></a>修改hosts文件</h2><ul><li>vim /etc/hosts</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.111</span> <span class="selector-tag">cdh-master</span> </span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.112</span> <span class="selector-tag">cdh-slave1</span> </span><br><span class="line">192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.113</span> <span class="selector-tag">cdh-slave2</span></span><br></pre></td></tr></table></figure><h1 id="SSH互信"><a href="#SSH互信" class="headerlink" title="SSH互信"></a>SSH互信</h1><h2 id="生成密钥对（公钥和私钥）"><a href="#生成密钥对（公钥和私钥）" class="headerlink" title="生成密钥对（公钥和私钥）"></a>生成密钥对（公钥和私钥）</h2><ul><li>ssh-keygen -t rsa -P ‘’</li></ul><h2 id="追加authorized-keys"><a href="#追加authorized-keys" class="headerlink" title="追加authorized_keys"></a>追加authorized_keys</h2><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 追加authorized_keys</span></span><br><span class="line">cat ~<span class="string">/.ssh/id_rsa.pub</span> &gt; ~<span class="string">/.ssh/authorized_keys</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 修改权限</span></span><br><span class="line">chmod g-w ~</span><br><span class="line">chmod 700 ~<span class="string">/.ssh</span> </span><br><span class="line">chmod 600 ~<span class="string">/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure><h2 id="追加密钥到Master"><a href="#追加密钥到Master" class="headerlink" title="追加密钥到Master"></a>追加密钥到Master</h2><ul><li>ssh cdh-slave1 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</li><li>ssh cdh-slave2 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</li></ul><h2 id="复制密钥到从节点"><a href="#复制密钥到从节点" class="headerlink" title="复制密钥到从节点"></a>复制密钥到从节点</h2><ul><li>scp ~/.ssh/authorized_keys cdh-slave1:~/.ssh/authorized_keys</li><li>scp ~/.ssh/authorized_keys cdh-slave2:~/.ssh/authorized_keys</li></ul><h1 id="ntp时间同步"><a href="#ntp时间同步" class="headerlink" title="ntp时间同步"></a>ntp时间同步</h1><h2 id="所有节点安装相关ntp组件"><a href="#所有节点安装相关ntp组件" class="headerlink" title="所有节点安装相关ntp组件"></a>所有节点安装相关ntp组件</h2><ul><li>yum -y install ntp</li></ul><h2 id="所有节点设置时区"><a href="#所有节点设置时区" class="headerlink" title="所有节点设置时区"></a>所有节点设置时区</h2><ul><li>timedatectl set-timezone Asia/Shanghai</li></ul><h2 id="启动ntp，以及设置开机启动"><a href="#启动ntp，以及设置开机启动" class="headerlink" title="启动ntp，以及设置开机启动"></a>启动ntp，以及设置开机启动</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动ntp</span></span><br><span class="line">systemctl start ntpd</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置开机启动</span></span><br><span class="line">systemctl <span class="builtin-name">enable</span> ntpd</span><br></pre></td></tr></table></figure><h2 id="配置ntp服务器-master节点"><a href="#配置ntp服务器-master节点" class="headerlink" title="配置ntp服务器(master节点)"></a>配置ntp服务器(master节点)</h2><ul><li>vim /etc/ntp.conf</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 修改如下几行</span><br><span class="line"><span class="selector-id">#server</span> 0<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 1<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 2<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 3<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"></span><br><span class="line"># 添加如下几行</span><br><span class="line"><span class="selector-tag">restrict</span> 192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.2</span> <span class="selector-tag">mask</span> 255<span class="selector-class">.255</span><span class="selector-class">.255</span><span class="selector-class">.0</span> <span class="selector-tag">nomodify</span> <span class="selector-tag">notrap</span></span><br><span class="line"><span class="selector-tag">server</span> 127<span class="selector-class">.127</span><span class="selector-class">.1</span><span class="selector-class">.0</span></span><br><span class="line"><span class="selector-tag">fudge</span> 127<span class="selector-class">.127</span><span class="selector-class">.1</span><span class="selector-class">.0</span> <span class="selector-tag">stratum</span> 10</span><br></pre></td></tr></table></figure><h2 id="配置ntp服务器-slave节点"><a href="#配置ntp服务器-slave节点" class="headerlink" title="配置ntp服务器(slave节点)"></a>配置ntp服务器(slave节点)</h2><ul><li>vim /etc/ntp.conf</li></ul><figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 修改如下几行</span><br><span class="line"><span class="selector-id">#server</span> 0<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 1<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 2<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"><span class="selector-id">#server</span> 3<span class="selector-class">.centos</span><span class="selector-class">.pool</span><span class="selector-class">.ntp</span><span class="selector-class">.org</span> <span class="selector-tag">iburst</span></span><br><span class="line"></span><br><span class="line"># 添加如下几行(<span class="selector-tag">master</span>节点)</span><br><span class="line"><span class="selector-tag">restrict</span> 192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.2</span> <span class="selector-tag">mask</span> 255<span class="selector-class">.255</span><span class="selector-class">.255</span><span class="selector-class">.0</span> <span class="selector-tag">nomodify</span> <span class="selector-tag">notrap</span></span><br><span class="line"><span class="selector-tag">server</span> 192<span class="selector-class">.168</span><span class="selector-class">.69</span><span class="selector-class">.111</span></span><br></pre></td></tr></table></figure><h2 id="重启ntp服务"><a href="#重启ntp服务" class="headerlink" title="重启ntp服务"></a>重启ntp服务</h2><ul><li>systemctl restart ntpd</li></ul><h2 id="主节点定时服务"><a href="#主节点定时服务" class="headerlink" title="主节点定时服务"></a>主节点定时服务</h2><ul><li>crontab -e</li></ul><figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span><span class="number">-59</span>/<span class="number">10</span> * * * * /usr/sbin/ntpdate -u asia.pool.ntp.org</span><br></pre></td></tr></table></figure><h2 id="手动同步master的时间"><a href="#手动同步master的时间" class="headerlink" title="手动同步master的时间"></a>手动同步master的时间</h2><ul><li>ntpdate -u 192.168.69.111</li></ul><h2 id="查看同步状态"><a href="#查看同步状态" class="headerlink" title="查看同步状态"></a>查看同步状态</h2><ul><li>ntpstat</li></ul><h1 id="配置Cloudera-rpm仓库"><a href="#配置Cloudera-rpm仓库" class="headerlink" title="配置Cloudera rpm仓库"></a>配置Cloudera rpm仓库</h1><h2 id="下载repo文件"><a href="#下载repo文件" class="headerlink" title="下载repo文件"></a>下载repo文件</h2><ul><li>sudo wget <a href="https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/cloudera-manager.repo" target="_blank" rel="noopener">https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/cloudera-manager.repo</a> -P /etc/yum.repos.d/</li></ul><h2 id="使用GPG-key导入仓库"><a href="#使用GPG-key导入仓库" class="headerlink" title="使用GPG key导入仓库"></a>使用GPG key导入仓库</h2><ul><li>sudo rpm —import <a href="https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPM-GPG-KEY-cloudera" target="_blank" rel="noopener">https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPM-GPG-KEY-cloudera</a></li></ul><h2 id="下载parcel文件"><a href="#下载parcel文件" class="headerlink" title="下载parcel文件"></a>下载parcel文件</h2><ul><li>mkdir -p /opt/cloudera/parcel-repo/</li><li>sudo wget <a href="https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel" target="_blank" rel="noopener">https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel</a> /opt/cloudera/parcel-repo/</li><li>sudo wget <a href="https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha256" target="_blank" rel="noopener">https://archive.cloudera.com/cdh6/6.2.0/parcels/CDH-6.2.0-1.cdh6.2.0.p0.967373-el7.parcel.sha256</a> /opt/cloudera/parcel-repo/</li><li>sudo wget <a href="https://archive.cloudera.com/cdh6/6.2.0/parcels/manifest.json" target="_blank" rel="noopener">https://archive.cloudera.com/cdh6/6.2.0/parcels/manifest.json</a> /opt/cloudera/parcel-repo/</li></ul><h1 id="安装-Java（64-bit）"><a href="#安装-Java（64-bit）" class="headerlink" title="安装 Java（64-bit）"></a>安装 Java（64-bit）</h1><h2 id="卸载掉自带的-OpenJdk"><a href="#卸载掉自带的-OpenJdk" class="headerlink" title="卸载掉自带的 OpenJdk"></a>卸载掉自带的 OpenJdk</h2><ul><li>rpm -qa | grep java</li></ul><h2 id="使用Cloudera-Manager-安装-Java"><a href="#使用Cloudera-Manager-安装-Java" class="headerlink" title="使用Cloudera Manager 安装 Java"></a>使用Cloudera Manager 安装 Java</h2><ul><li>sudo yum -y install oracle-j2sdk1.8</li></ul><h2 id="设置环境变量"><a href="#设置环境变量" class="headerlink" title="设置环境变量"></a>设置环境变量</h2><ul><li>vim /etc/profile</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET JAVA PATH </span></span><br><span class="line">export JAVA_HOME=<span class="regexp">/usr/java</span><span class="regexp">/jdk1.8.0_181-cloudera/</span></span><br><span class="line">export CLASSPATH=.:$<span class="symbol">CLASSPATH:</span>$JAVA_HOME/<span class="class"><span class="keyword">lib</span> </span></span><br><span class="line">export PATH=$<span class="symbol">PATH:</span>$JAVA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source /etc/profile</li></ul><h3 id="yum-update报错Error-Delta-RPMs-disabled-because-usr-bin-applydeltarpm-not-installed"><a href="#yum-update报错Error-Delta-RPMs-disabled-because-usr-bin-applydeltarpm-not-installed" class="headerlink" title="yum update报错Error: Delta RPMs disabled because /usr/bin/applydeltarpm not installed."></a>yum update报错<code>Error: Delta RPMs disabled because /usr/bin/applydeltarpm not installed.</code></h3><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装deltarpm</span></span><br><span class="line"><span class="attribute">yum</span> provides <span class="string">'*/applydeltarpm'</span></span><br><span class="line">yum install deltarpm</span><br></pre></td></tr></table></figure><h1 id="安装Cloudera-Manager-Server"><a href="#安装Cloudera-Manager-Server" class="headerlink" title="安装Cloudera Manager Server"></a>安装Cloudera Manager Server</h1><h2 id="安装Cloudera-Manager包"><a href="#安装Cloudera-Manager包" class="headerlink" title="安装Cloudera Manager包"></a>安装Cloudera Manager包</h2><ul><li>sudo yum -y install cloudera-manager-daemons cloudera-manager-agent cloudera-manager-server</li></ul><p>Ps：可以在<a href="https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPMS/x86_64/" target="_blank" rel="noopener">https://archive.cloudera.com/cm6/6.2.0/redhat7/yum/RPMS/x86_64/</a> 提前下好rpm包进行安装。</p><h2 id="启用Auto-TLS"><a href="#启用Auto-TLS" class="headerlink" title="启用Auto-TLS"></a>启用Auto-TLS</h2><p>待续</p><h1 id="安装和配置数据库MariaDB-for-Cloudera-Software-master节点"><a href="#安装和配置数据库MariaDB-for-Cloudera-Software-master节点" class="headerlink" title="安装和配置数据库MariaDB for Cloudera Software(master节点)"></a>安装和配置数据库MariaDB for Cloudera Software(master节点)</h1><h2 id="安装MariaDB"><a href="#安装MariaDB" class="headerlink" title="安装MariaDB"></a>安装MariaDB</h2><ul><li>sudo yum -y install mariadb-server</li></ul><h2 id="配置MariaDB"><a href="#配置MariaDB" class="headerlink" title="配置MariaDB"></a>配置MariaDB</h2><ul><li>vim /etc/my.cnf</li></ul><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">datadir=/var/lib/mysql</span><br><span class="line">socket=/var/lib/mysql/mysql.sock</span><br><span class="line">transaction-isolation = READ-COMMITTED</span><br><span class="line"><span class="comment"># Disabling symbolic-links is recommended to prevent assorted security risks;</span></span><br><span class="line"><span class="comment"># to do so, uncomment this line:</span></span><br><span class="line">symbolic-links = 0</span><br><span class="line"><span class="comment"># Settings user and group are ignored when systemd is used.</span></span><br><span class="line"><span class="comment"># If you need to run mysqld under a different user or group,</span></span><br><span class="line"><span class="comment"># customize your systemd unit file for mariadb according to the</span></span><br><span class="line"><span class="comment"># instructions in http://fedoraproject.org/wiki/Systemd</span></span><br><span class="line"></span><br><span class="line">key_buffer = 16M</span><br><span class="line">key_buffer_size = 32M</span><br><span class="line">max_allowed_packet = 32M</span><br><span class="line">thread_stack = 256K</span><br><span class="line">thread_cache_size = 64</span><br><span class="line">query_cache_limit = 8M</span><br><span class="line">query_cache_size = 64M</span><br><span class="line">query_cache_type = 1</span><br><span class="line"></span><br><span class="line">max_connections = 550</span><br><span class="line"><span class="comment">#expire_logs_days = 10</span></span><br><span class="line"><span class="comment">#max_binlog_size = 100M</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#log_bin should be on a disk with enough free space.</span></span><br><span class="line"><span class="comment">#Replace '/var/lib/mysql/mysql_binary_log' with an appropriate path for your</span></span><br><span class="line"><span class="comment">#system and chown the specified folder to the mysql user.</span></span><br><span class="line">log_bin=/var/lib/mysql/mysql_binary_log</span><br><span class="line"></span><br><span class="line"><span class="comment">#In later versions of MariaDB, if you enable the binary log and do not set</span></span><br><span class="line"><span class="comment">#a server_id, MariaDB will not start. The server_id must be unique within</span></span><br><span class="line"><span class="comment">#the replicating group.</span></span><br><span class="line">server_id=1</span><br><span class="line"></span><br><span class="line">binlog_format = mixed</span><br><span class="line"></span><br><span class="line">read_buffer_size = 2M</span><br><span class="line">read_rnd_buffer_size = 16M</span><br><span class="line">sort_buffer_size = 8M</span><br><span class="line">join_buffer_size = 8M</span><br><span class="line"></span><br><span class="line"><span class="comment"># InnoDB settings</span></span><br><span class="line">innodb_file_per_table = 1</span><br><span class="line">innodb_flush_log_at_trx_commit  = 2</span><br><span class="line">innodb_log_buffer_size = 64M</span><br><span class="line">innodb_buffer_pool_size = 4G</span><br><span class="line">innodb_thread_concurrency = 8</span><br><span class="line">innodb_flush_method = O_DIRECT</span><br><span class="line">innodb_log_file_size = 512M</span><br><span class="line"></span><br><span class="line">[mysqld_safe]</span><br><span class="line">log-error=/var/log/mariadb/mariadb.log</span><br><span class="line">pid-file=/var/run/mariadb/mariadb.pid</span><br><span class="line"></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># include all files from the config directory</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line">!includedir /etc/my.cnf.d</span><br></pre></td></tr></table></figure><h2 id="启动MariaDB"><a href="#启动MariaDB" class="headerlink" title="启动MariaDB"></a>启动MariaDB</h2><h3 id="开机启动MariaDB"><a href="#开机启动MariaDB" class="headerlink" title="开机启动MariaDB"></a>开机启动MariaDB</h3><ul><li>sudo systemctl enable mariadb</li></ul><h3 id="启动MariaDB服务"><a href="#启动MariaDB服务" class="headerlink" title="启动MariaDB服务"></a>启动MariaDB服务</h3><ul><li>sudo systemctl start mariadb</li></ul><h2 id="安全设置"><a href="#安全设置" class="headerlink" title="安全设置"></a>安全设置</h2><ul><li>sudo /usr/bin/mysql_secure_installation</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[...]</span><br><span class="line">Enter current password for root (enter for none):</span><br><span class="line">OK, successfully used password, moving on...</span><br><span class="line">[...]</span><br><span class="line"><span class="keyword">Set</span> root <span class="keyword">password</span>? [Y/n] Y</span><br><span class="line"><span class="keyword">New</span> <span class="keyword">password</span>: <span class="number">123</span></span><br><span class="line">Re-enter <span class="keyword">new</span> <span class="keyword">password</span>: <span class="number">123</span></span><br><span class="line">[...]</span><br><span class="line">Remove anonymous <span class="keyword">users</span>? [Y/n] Y</span><br><span class="line">[...]</span><br><span class="line"><span class="keyword">Disallow</span> root login remotely? [Y/n] Y</span><br><span class="line">[...]</span><br><span class="line">Remove <span class="keyword">test</span> <span class="keyword">database</span> <span class="keyword">and</span> <span class="keyword">access</span> <span class="keyword">to</span> it [Y/n] Y</span><br><span class="line">[...]</span><br><span class="line">Reload privilege <span class="keyword">tables</span> <span class="keyword">now</span>? [Y/n] Y</span><br><span class="line">[...]</span><br><span class="line"><span class="keyword">All</span> done!  <span class="keyword">If</span> you<span class="string">'ve completed all of the above steps, your MariaDB</span></span><br><span class="line"><span class="string">installation should now be secure.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Thanks for using MariaDB!</span></span><br></pre></td></tr></table></figure><h2 id="安装MySQL-JDBC-Driver-for-MariaDB"><a href="#安装MySQL-JDBC-Driver-for-MariaDB" class="headerlink" title="安装MySQL JDBC Driver for MariaDB"></a>安装MySQL JDBC Driver for MariaDB</h2><h3 id="下载驱动包"><a href="#下载驱动包" class="headerlink" title="下载驱动包"></a>下载驱动包</h3><ul><li>wget <a href="https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz" target="_blank" rel="noopener">https://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-5.1.46.tar.gz</a></li></ul><h3 id="解压驱动包"><a href="#解压驱动包" class="headerlink" title="解压驱动包"></a>解压驱动包</h3><ul><li>tar zxvf mysql-connector-java-5.1.46.tar.gz</li><li>rm -rf mysql-connector-java-5.1.46.tar.gz</li></ul><h3 id="复制驱动包"><a href="#复制驱动包" class="headerlink" title="复制驱动包"></a>复制驱动包</h3><ul><li>sudo mkdir -p /usr/share/java/</li><li>cd mysql-connector-java-5.1.46</li><li>sudo cp mysql-connector-java-5.1.46-bin.jar /usr/share/java/mysql-connector-java.jar</li></ul><h2 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h2><h3 id="登录root账户"><a href="#登录root账户" class="headerlink" title="登录root账户"></a>登录root账户</h3><ul><li>mysql -uroot -p</li></ul><h3 id="创建hive数据库"><a href="#创建hive数据库" class="headerlink" title="创建hive数据库"></a>创建hive数据库</h3><ul><li>CREATE DATABASE metastore DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</li><li>CREATE DATABASE scm DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</li><li>CREATE DATABASE oozie DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</li><li>CREATE DATABASE hue DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci;</li></ul><h3 id="创建账户"><a href="#创建账户" class="headerlink" title="创建账户"></a>创建账户</h3><ul><li>GRANT ALL ON metastore.* TO ‘hive’@’%’ IDENTIFIED BY ‘123’;</li><li>GRANT ALL ON scm.* TO ‘scm’@’%’ IDENTIFIED BY ‘123’;</li><li>GRANT ALL ON oozie.* TO ‘oozie’@’%’ IDENTIFIED BY ‘123’;</li><li>GRANT ALL ON hue.* TO ‘hue’@’%’ IDENTIFIED BY ‘123’;</li></ul><h3 id="刷新权限"><a href="#刷新权限" class="headerlink" title="刷新权限"></a>刷新权限</h3><ul><li>flush privileges;</li></ul><h3 id="查看数据库"><a href="#查看数据库" class="headerlink" title="查看数据库"></a>查看数据库</h3><ul><li>SHOW DATABASES;</li></ul><h3 id="查看权限"><a href="#查看权限" class="headerlink" title="查看权限"></a>查看权限</h3><ul><li>SHOW GRANTS FOR ‘hive’@’%’;</li></ul><h1 id="设置Cloudera-Manager数据库-master节点"><a href="#设置Cloudera-Manager数据库-master节点" class="headerlink" title="设置Cloudera Manager数据库(master节点)"></a>设置Cloudera Manager数据库(master节点)</h1><h2 id="设置语法"><a href="#设置语法" class="headerlink" title="设置语法"></a>设置语法</h2><ul><li>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm 123</li></ul><h2 id="准备数据库"><a href="#准备数据库" class="headerlink" title="准备数据库"></a>准备数据库</h2><ul><li>sudo /opt/cloudera/cm/schema/scm_prepare_database.sh mysql scm scm</li></ul><h1 id="安装CDH及其他软件"><a href="#安装CDH及其他软件" class="headerlink" title="安装CDH及其他软件"></a>安装CDH及其他软件</h1><h2 id="【强烈建议】所有节点拍摄快照"><a href="#【强烈建议】所有节点拍摄快照" class="headerlink" title="【强烈建议】所有节点拍摄快照"></a>【强烈建议】所有节点拍摄快照</h2><h2 id="启动Cloudera-Manager-Server-master节点"><a href="#启动Cloudera-Manager-Server-master节点" class="headerlink" title="启动Cloudera Manager Server(master节点)"></a>启动Cloudera Manager Server(master节点)</h2><ul><li>sudo systemctl start cloudera-scm-server</li></ul><h2 id="查看日志-master节点"><a href="#查看日志-master节点" class="headerlink" title="查看日志(master节点)"></a>查看日志(master节点)</h2><ul><li>sudo tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log</li></ul><p>直至出现<code>INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server.</code></p><h2 id="登录web页面"><a href="#登录web页面" class="headerlink" title="登录web页面"></a>登录web页面</h2><ul><li><a href="http://cdh-master:7180" target="_blank" rel="noopener">http://cdh-master:7180</a></li></ul><p>账户：admin<br>密码：admin</p><h2 id="安装组件"><a href="#安装组件" class="headerlink" title="安装组件"></a>安装组件</h2><h3 id="x-接受最终用户许可条款和条件"><a href="#x-接受最终用户许可条款和条件" class="headerlink" title="- [x] 接受最终用户许可条款和条件"></a>- [x] 接受最终用户许可条款和条件</h3><h3 id="选择Cloudera-Express免费版"><a href="#选择Cloudera-Express免费版" class="headerlink" title="选择Cloudera Express免费版"></a>选择Cloudera Express免费版</h3><h3 id="集群安装"><a href="#集群安装" class="headerlink" title="集群安装"></a>集群安装</h3><h4 id="Cluster-Basics"><a href="#Cluster-Basics" class="headerlink" title="Cluster Basics"></a>Cluster Basics</h4><ul><li>CDH</li></ul><h4 id="Specify-Hosts"><a href="#Specify-Hosts" class="headerlink" title="Specify Hosts"></a>Specify Hosts</h4><ul><li>输入<code>cdh-master, cdh-slave1, cdh-slave2</code>点击’搜索’</li></ul><h4 id="选择存储库"><a href="#选择存储库" class="headerlink" title="选择存储库"></a>选择存储库</h4><ul><li>选择<code>Public Cloudera Repository</code></li><li>选择<code>Parcels</code></li><li>其他默认</li></ul><h4 id="JDK-安装选项"><a href="#JDK-安装选项" class="headerlink" title="JDK 安装选项"></a>JDK 安装选项</h4><ul><li>选中<code>安装 Oracle Java SE 开发工具包 (JDK)</code></li></ul><h4 id="设置登录凭据"><a href="#设置登录凭据" class="headerlink" title="设置登录凭据"></a>设置登录凭据</h4><ul><li>选择<code>root</code></li><li>输入密码</li></ul><h4 id="安装agents"><a href="#安装agents" class="headerlink" title="安装agents"></a>安装agents</h4><h4 id="安装Parcels"><a href="#安装Parcels" class="headerlink" title="安装Parcels"></a>安装Parcels</h4><h4 id="Inspect-Hosts"><a href="#Inspect-Hosts" class="headerlink" title="Inspect Hosts"></a>Inspect Hosts</h4><ul><li><p>虚拟内存设置</p><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sysctl -<span class="keyword">w</span> <span class="keyword">vm</span>.swappiness=<span class="number">10</span></span><br><span class="line"><span class="keyword">echo</span> <span class="keyword">vm</span>.swappiness = <span class="number">10</span> &gt;&gt; /etc/sysctl.<span class="keyword">conf</span></span><br></pre></td></tr></table></figure></li><li><p>大内存页设置</p><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 临时</span></span><br><span class="line">echo never&gt;<span class="meta-keyword">/sys/</span>kernel<span class="meta-keyword">/mm/</span>transparent_hugepage/defrag</span><br><span class="line">echo never&gt;<span class="meta-keyword">/sys/</span>kernel<span class="meta-keyword">/mm/</span>transparent_hugepage/enabled</span><br><span class="line"></span><br><span class="line"><span class="meta"># 永久</span></span><br><span class="line">vim <span class="meta-keyword">/etc/</span>rc.local</span><br><span class="line"><span class="meta"># 加入如下信息</span></span><br><span class="line">echo never&gt;<span class="meta-keyword">/sys/</span>kernel<span class="meta-keyword">/mm/</span>transparent_hugepage/defrag</span><br><span class="line">echo never&gt;<span class="meta-keyword">/sys/</span>kernel<span class="meta-keyword">/mm/</span>transparent_hugepage/enabled</span><br><span class="line"><span class="meta"># 设置权限</span></span><br><span class="line">chmod +x <span class="meta-keyword">/etc/</span>rc.d/rc.local</span><br></pre></td></tr></table></figure></li></ul><h4 id="组件列表"><a href="#组件列表" class="headerlink" title="组件列表"></a>组件列表</h4><div class="table-container"><table><thead><tr><th style="text-align:left">组件</th><th style="text-align:left">版本</th></tr></thead><tbody><tr><td style="text-align:left">Supervisord</td><td style="text-align:left">3.0</td></tr><tr><td style="text-align:left">Cloudera Manager Agent</td><td style="text-align:left">6.2.0</td></tr><tr><td style="text-align:left">Cloudera Manager Management Daemon</td><td style="text-align:left">6.2.0</td></tr><tr><td style="text-align:left">Flume NG</td><td style="text-align:left">1.9.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Hadoop</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">HDFS</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">HttpFS</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">hadoop-kms</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">MapReduce 2</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">YARN</td><td style="text-align:left">3.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">HBase</td><td style="text-align:left">2.1.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Lily HBase Indexer</td><td style="text-align:left">1.5+cdh6.2.0</td></tr><tr><td style="text-align:left">Hive</td><td style="text-align:left">2.1.1+cdh6.2.0</td></tr><tr><td style="text-align:left">HCatalog</td><td style="text-align:left">2.1.1+cdh6.2.0</td></tr><tr><td style="text-align:left">Hue</td><td style="text-align:left">4.2.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Impala</td><td style="text-align:left">3.2.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Java 8</td><td style="text-align:left">1.8.0_181</td></tr><tr><td style="text-align:left">Kafka</td><td style="text-align:left">2.1.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Kite（仅限 CDH 5 ）</td><td style="text-align:left">1.0.0+cdh6.2.0</td></tr><tr><td style="text-align:left">kudu</td><td style="text-align:left">1.9.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Oozie</td><td style="text-align:left">5.1.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Parquet</td><td style="text-align:left">1.9.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Pig</td><td style="text-align:left">0.17.0+cdh6.2.0</td></tr><tr><td style="text-align:left">sentry</td><td style="text-align:left">2.1.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Solr</td><td style="text-align:left">7.4.0+cdh6.2.0</td></tr><tr><td style="text-align:left">spark</td><td style="text-align:left">2.4.0+cdh6.2.0</td></tr><tr><td style="text-align:left">Sqoop</td><td style="text-align:left">1.4.7+cdh6.2.0</td></tr><tr><td style="text-align:left">ZooKeeper</td><td style="text-align:left">3.4.5+cdh6.2.0</td></tr></tbody></table></div><h1 id="使用向导设置群集"><a href="#使用向导设置群集" class="headerlink" title="使用向导设置群集"></a>使用向导设置群集</h1><h2 id="选择服务"><a href="#选择服务" class="headerlink" title="选择服务"></a>选择服务</h2><ul><li>选择<code>所有服务</code></li><li><del>选择<code>HBase</code> <code>HDFS</code> <code>Hive</code> <code>Hue</code> <code>Kafka</code> <code>Oozie</code> <code>YARN(MR2 Included)</code> <code>ZooKeeper</code></del></li></ul><h2 id="自定义角色分配"><a href="#自定义角色分配" class="headerlink" title="自定义角色分配"></a>自定义角色分配</h2><ul><li>默认</li></ul><h2 id="数据库设置"><a href="#数据库设置" class="headerlink" title="数据库设置"></a>数据库设置</h2><h3 id="Hive"><a href="#Hive" class="headerlink" title="Hive"></a>Hive</h3><ul><li>MySQL &gt; 否 &gt; cdh-master &gt; metastore &gt; hive &gt; 123</li></ul><h3 id="Oozie"><a href="#Oozie" class="headerlink" title="Oozie"></a>Oozie</h3><ul><li>MySQL &gt; cdh-master &gt; oozie &gt; oozie &gt; 123</li></ul><h3 id="Hue"><a href="#Hue" class="headerlink" title="Hue"></a>Hue</h3><ul><li>MySQL &gt; cdh-master &gt; hue &gt; hue &gt; 123</li></ul><h2 id="审核更改"><a href="#审核更改" class="headerlink" title="审核更改"></a>审核更改</h2><ul><li>默认</li></ul><h2 id="命令详细信息"><a href="#命令详细信息" class="headerlink" title="命令详细信息"></a>命令详细信息</h2><p>Ps：若搭建过程中多次尝试安装，建议删除/dfs/nn下文件，避免HDFS服务报错</p><h2 id="汇总"><a href="#汇总" class="headerlink" title="汇总"></a>汇总</h2><h1 id="错误排查"><a href="#错误排查" class="headerlink" title="错误排查"></a>错误排查</h1><p>推荐链接 &gt;&gt; <a href="https://blog.csdn.net/zzq900503/article/details/53393721" target="_blank" rel="noopener">https://blog.csdn.net/zzq900503/article/details/53393721</a></p><p><br></p><meting-js id="31654478" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:52 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;CDH环境配置&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/074403.jpg&quot; alt=&quot;clay-banks-1554989-unsplash&quot;&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="CDH" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/CDH/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="CDH环境搭建" scheme="https://alessa0.cn/tags/CDH%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十五)：Flink</title>
    <link href="https://alessa0.cn/posts/6cff886e/"/>
    <id>https://alessa0.cn/posts/6cff886e/</id>
    <published>2019-04-25T09:02:34.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Flink：Storm你该回家了…</p><br><img src="https://image.alessa0.cn/090827.jpg" alt="shane-young-769905-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Flink 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://flink.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Flink</a></div><p></p><h1 id="安装Flink"><a href="#安装Flink" class="headerlink" title="安装Flink"></a>安装Flink</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp flink-1.8.0-bin-scala_2.11.tgz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf flink-1.8.0-bin-scala_2.11.tgz</li><li>rm -rf flink-1.8.0-bin-scala_2.11.tgz</li></ul><p><strong>Flink环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET FLINK PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">FLINK_HOME</span>=/usr/local/src/flink-1.8.0 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$FLINK_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Flink配置"><a href="#修改Flink配置" class="headerlink" title="修改Flink配置"></a>修改Flink配置</h1><ul><li>cd flink-1.8.0/conf</li><li>vim flink-conf.yaml</li></ul><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 修改如下信息</span></span><br><span class="line"><span class="symbol">jobmanager.rpc.address:</span> master</span><br></pre></td></tr></table></figure><ul><li>vim masters</li></ul><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 修改如下信息</span></span><br><span class="line"><span class="symbol">master:</span><span class="number">8081</span></span><br></pre></td></tr></table></figure><ul><li>vim slaves</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">slave1</span> </span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h1 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h1><p><strong>启动服务：</strong></p><ul><li>start-cluster.sh</li></ul><p><strong>关闭集群：</strong></p><ul><li>stop-cluster.sh</li></ul><p><strong>监控网页：</strong></p><p>Web：<a href="http://master:8081" target="_blank" rel="noopener">http://master:8081</a></p><p><br></p><meting-js id="449235912" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Flink：Storm你该回家了…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/090827.jpg&quot; alt=&quot;shane-young-769905-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Flink" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Flink/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Flink" scheme="https://alessa0.cn/tags/Flink/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十四)：Storm on Yarn</title>
    <link href="https://alessa0.cn/posts/6a54df13/"/>
    <id>https://alessa0.cn/posts/6a54df13/</id>
    <published>2019-04-25T08:57:22.000Z</published>
    <updated>2019-08-05T07:18:53.184Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Storm-on-Yarn：跟着老大哥有肉吃…</p><br><img src="https://image.alessa0.cn/090019.jpg" alt="max-delsid-479103-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Storm-on-Yarn 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://github.com/yahoo/storm-yarn" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Storm on Yarn</a></div><p></p><h1 id="待续……"><a href="#待续……" class="headerlink" title="待续……"></a>待续……</h1><p><br></p><meting-js id="27804029" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/c6d1abe8/">BigData复习笔记03：推荐算法</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Storm-on-Yarn：跟着老大哥有肉吃…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/090019.jpg&quot; alt=&quot;max-delsid-479103-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Storm-on-Yarn" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Storm-on-Yarn/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Storm-on-Yarn" scheme="https://alessa0.cn/tags/Storm-on-Yarn/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十三)：Storm</title>
    <link href="https://alessa0.cn/posts/9017301c/"/>
    <id>https://alessa0.cn/posts/9017301c/</id>
    <published>2019-04-25T08:42:24.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Storm：我才是流处理！</p><br><img src="https://image.alessa0.cn/084537.jpg" alt="johannes-plenio-247177-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Storm 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://storm.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Storm</a></div><p></p><h1 id="安装Storm"><a href="#安装Storm" class="headerlink" title="安装Storm"></a>安装Storm</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp apache-storm-1.2.2.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf apache-storm-1.2.2.tar.gz</li><li>rm -rf apache-storm-1.2.2.tar.gz</li></ul><p><strong>Storm环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SET STORM PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">STORM_HOME</span>=/usr/local/src/apache-storm-1.2.2 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$STORM_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Storm配置文件"><a href="#修改Storm配置文件" class="headerlink" title="修改Storm配置文件"></a>修改Storm配置文件</h1><ul><li>cd apache-storm-1.2.2</li></ul><p><strong>创建日志文件/数据文件：</strong></p><ul><li>mkdir data</li><li>mkdir logs</li></ul><p><strong>配置文件：</strong></p><ul><li>cd conf</li><li>vim storm.yaml</li></ul><figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 添加如下信息</span></span><br><span class="line"><span class="symbol">storm.zookeeper.servers:</span> </span><br><span class="line"> - <span class="string">"master"</span> </span><br><span class="line"> - <span class="string">"slave1"</span> </span><br><span class="line"> - <span class="string">"slave2"</span> </span><br><span class="line"><span class="symbol">storm.zookeeper.port:</span> <span class="number">2181</span> </span><br><span class="line"><span class="symbol">storm.local.dir:</span> <span class="string">"/usr/local/storm-1.2.2/data"</span> </span><br><span class="line"><span class="symbol">ui.port:</span> <span class="number">8089</span> </span><br><span class="line"><span class="symbol">nimbus.seeds:</span> [<span class="string">"master"</span>] </span><br><span class="line"><span class="symbol">supervisor.slots.ports:</span> </span><br><span class="line"> - <span class="number">6700</span> </span><br><span class="line"> - <span class="number">6701</span> </span><br><span class="line"> - <span class="number">6702</span> </span><br><span class="line"> - <span class="number">6703</span> </span><br><span class="line"> - <span class="number">6704</span> </span><br><span class="line"> - <span class="number">6705</span></span><br></pre></td></tr></table></figure><h1 id="启动Storm集群"><a href="#启动Storm集群" class="headerlink" title="启动Storm集群"></a>启动Storm集群</h1><p><strong>主节点启动：</strong></p><ul><li>storm nimbus &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/nimbus.out 2&gt;&amp;1 &amp;</li><li>storm ui &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/ui.out 2&gt;&amp;1 &amp;</li></ul><p><strong>从节点启动：</strong></p><ul><li>storm supervisor &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/supervisor.out 2&gt;&amp;1 &amp;</li><li>storm logviewer &gt;&gt; /usr/local/src/apache-storm-1.2.2/logs/logviewer.out 2&gt;&amp;1 &amp;</li></ul><p><strong>主节点关闭：</strong></p><ul><li>kill -9 `ps -ef | grep ui.core | awk ‘{print $2}’ | head -n 1`</li><li>kill -9 `ps -ef | grep daemon.nimbus | awk ‘{print $2}’ | head -n 1`</li><li>kill -9 `ps -ef | grep daemon.supervisor | awk ‘{print $2}’ | head -n 1`</li><li>kill -9 `ps -ef | grep daemon.logviewer | awk ‘{print $2}’ | head -n 1`</li></ul><p><strong>WEB监控页面：</strong></p><p>Web： <a href="http://master:8089/index.html" target="_blank" rel="noopener">http://master:8089/index.html</a></p><p><br></p><meting-js id="29836527" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Storm：我才是流处理！&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/084537.jpg&quot; alt=&quot;johannes-plenio-247177-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Storm" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Storm/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十二)：Kafka</title>
    <link href="https://alessa0.cn/posts/eee41037/"/>
    <id>https://alessa0.cn/posts/eee41037/</id>
    <published>2019-04-25T07:41:06.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Kafka：我不是写小说那个…</p><br><img src="https://image.alessa0.cn/082116.jpg" alt="title-page"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Kafka 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://kafka.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Kafka</a></div><p></p><h1 id="安装Kafka"><a href="#安装Kafka" class="headerlink" title="安装Kafka"></a>安装Kafka</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp kafka_2.11-2.2.0.tgz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf kafka_2.11-2.2.0.tgz</li><li>rm -rf kafka_2.11-2.2.0.tgz</li></ul><p><strong>Kafka环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET KAFKA PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">KAFKA_HOME</span>=/usr/local/src/kafka_2.11-2.2.0 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$KAFKA_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Kafka配置"><a href="#修改Kafka配置" class="headerlink" title="修改Kafka配置"></a>修改Kafka配置</h1><ul><li>cd kafka_2.11-2.2.0</li></ul><p><strong>创建日志文件：</strong></p><ul><li>mkdir logs</li></ul><p><strong>配置文件：</strong></p><ul><li>cd config</li><li>vim server.properties</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="attr">log.dirs</span>=/usr/local/src/kafka_2.<span class="number">11</span>-<span class="number">2.2</span>.<span class="number">0</span>/logs </span><br><span class="line"><span class="attr">zookeeper.connect</span>=master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span></span><br></pre></td></tr></table></figure><span class="label danger">仅在Master</span><ul><li>broker.id=0</li></ul><span class="label danger">仅在Slave1</span><ul><li>broker.id=1</li></ul><span class="label danger">仅在Slave2</span><ul><li>broker.id=2</li></ul><h1 id="启动Kafka集群"><a href="#启动Kafka集群" class="headerlink" title="启动Kafka集群"></a>启动Kafka集群</h1><p><strong>普通启动：</strong></p><ul><li>kafka-server-start.sh -daemon /usr/local/src/kafka_2.11-2.2.0/config/server.properties</li></ul><p><strong>关闭集群：</strong></p><ul><li>kafka-server-stop.sh</li></ul><p><br></p><meting-js id="1293886117" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Kafka：我不是写小说那个…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/082116.jpg&quot; alt=&quot;title-page&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Kafka" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Kafka/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Kafka" scheme="https://alessa0.cn/tags/Kafka/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十一)：Flume</title>
    <link href="https://alessa0.cn/posts/41d58b55/"/>
    <id>https://alessa0.cn/posts/41d58b55/</id>
    <published>2019-04-25T07:16:37.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Flume：xx托我给您带个话…</p><br><img src="https://image.alessa0.cn/072006.jpg" alt="clark-young-160446-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Flume 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://flume.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Flume</a></div><p></p><h1 id="安装Flume"><a href="#安装Flume" class="headerlink" title="安装Flume"></a>安装Flume</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp apache-flume-1.9.0-bin.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf apache-flume-1.9.0-bin.tar.gz</li><li>rm -rf apache-flume-1.9.0-bin.tar.gz</li></ul><p><strong>Hbase环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET FLUME PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">FLUME_HOME</span>=/usr/local/src/apache-flume-1.9.0-bin </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$FLUME_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Flume配置"><a href="#修改Flume配置" class="headerlink" title="修改Flume配置"></a>修改Flume配置</h1><ul><li>cd apache-flume-1.9.0-bin/conf</li><li>cp flume-env.sh.template flume-env.sh</li><li>vim flume-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/src/jdk1.8.0_212</span><br></pre></td></tr></table></figure><h1 id="新增配置文件"><a href="#新增配置文件" class="headerlink" title="新增配置文件"></a>新增配置文件</h1><p><strong>NetCat：</strong></p><ul><li>vim flume-netcat.conf</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">agent.sources</span> = r1</span><br><span class="line"><span class="attr">agent.sinks</span> = k1</span><br><span class="line"><span class="attr">agent.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configuration the source</span></span><br><span class="line"><span class="attr">agent.sources.r1.type</span> = netcat</span><br><span class="line"><span class="attr">agent.sources.r1.bind</span> = <span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line"><span class="attr">agent.sources.r1.port</span> = <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">agent.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">agent.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">agent.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">agent.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">agent.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">agent.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure><p><strong>Exec：</strong></p><ul><li>vim flume-exec.conf</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># Name the components on this agent</span></span><br><span class="line"><span class="attr">agent.sources</span> = r1</span><br><span class="line"><span class="attr">agent.sinks</span> = k1</span><br><span class="line"><span class="attr">agent.channels</span> = c1</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configuration the source</span></span><br><span class="line"><span class="attr">agent.sources.r1.type</span> = exec</span><br><span class="line"><span class="attr">agent.sources.r1.command</span> = tail -f /data/hadoop/flume/test.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe the sink</span></span><br><span class="line"><span class="attr">agent.sinks.k1.type</span> = logger</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use a channel which buffers events in memory</span></span><br><span class="line"><span class="attr">agent.channels.c1.type</span> = memory</span><br><span class="line"><span class="attr">agent.channels.c1.capacity</span> = <span class="number">1000</span></span><br><span class="line"><span class="attr">agent.channels.c1.transactionCapacity</span> = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Bind the source and sink to the channel</span></span><br><span class="line"><span class="attr">agent.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">agent.sinks.k1.channel</span> = c1</span><br></pre></td></tr></table></figure><p><strong>Avro：</strong></p><ul><li>vim flume-avro.conf</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># Define a memory channel called c1 on agent</span></span><br><span class="line"><span class="attr">agent.channels.c1.type</span> = memory</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define an avro source alled r1 on agent and  tell it</span></span><br><span class="line"><span class="attr">agent.sources.r1.channels</span> = c1</span><br><span class="line"><span class="attr">agent.sources.r1.type</span> = avro</span><br><span class="line"><span class="attr">agent.sources.r1.bind</span> = <span class="number">127.0</span>.<span class="number">0.1</span></span><br><span class="line"><span class="attr">agent.sources.r1.port</span> = <span class="number">44444</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Describe/configuration the source</span></span><br><span class="line"><span class="attr">agent.sinks.k1.type</span> = hdfs</span><br><span class="line"><span class="attr">agent.sinks.k1.channel</span> = c1</span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.path</span> = hdfs://master:<span class="number">9000</span>/flume_data_pool</span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.filePrefix</span> = events-</span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.fileType</span> = DataStream</span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.writeFormat</span> = Text</span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.rollSize</span> = <span class="number">0</span></span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.rollCount</span>= <span class="number">600000</span></span><br><span class="line"><span class="attr">agent.sinks.k1.hdfs.rollInterval</span> = <span class="number">600</span></span><br><span class="line"></span><br><span class="line"><span class="attr">agent.channels</span> = c1</span><br><span class="line"><span class="attr">agent.sources</span> = r1</span><br><span class="line"><span class="attr">agent.sinks</span> = k1</span><br></pre></td></tr></table></figure><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><p><strong>NetCat：</strong></p><p># 服务端</p><ul><li>flume-ng agent —conf conf —conf-file conf/flume-netcat.conf —name=agent -Dflume.root.logger=INFO,console</li></ul><p># 客户端</p><ul><li>flume-ng agent —conf conf —conf-file conf/flume-netcat.conf —name=agent -Dflume.root.logger=INFO,console</li></ul><p><strong>Exec：</strong></p><p># 服务端</p><ul><li>flume-ng agent —conf conf —conf-file conf/flume-exec.conf —name=agent -Dflume.root.logger=INFO,console</li></ul><p># 客户端</p><p><strong>Avro：</strong></p><p># 服务端</p><ul><li>flume-ng agent —conf conf —conf-file conf/flume-netcat.conf —name=agent -Dflume.root.logger=DEBUG,console</li></ul><p># 客户端</p><ul><li>telnet master 44444</li></ul><p><br></p><meting-js id="449239668" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Flume：xx托我给您带个话…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/072006.jpg&quot; alt=&quot;clark-young-160446-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Flume" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Flume/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Flume" scheme="https://alessa0.cn/tags/Flume/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(十)：Thrift</title>
    <link href="https://alessa0.cn/posts/34d202af/"/>
    <id>https://alessa0.cn/posts/34d202af/</id>
    <published>2019-04-25T06:55:08.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Thrift：行李少的可以从我这儿走…</p><br><img src="https://image.alessa0.cn/035105.jpg" alt="alejandro-escamilla-10-unsplash"><a id="more"></a><p></p><blockquote class="blockquote-center"><p>Thrift 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://thrift.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Thrift</a></div><p></p><h1 id="安装Thrift"><a href="#安装Thrift" class="headerlink" title="安装Thrift"></a>安装Thrift</h1><span class="label danger">仅在Master</span><p><strong>安装依赖环境：</strong></p><ul><li>yum -y install automake libtool flex bison pkgconfig gcc-c++ boost-devel libevent-devel zlib-devel python-devel ruby-devel openssl-devel</li><li>yum -y install boost-devel</li><li>yum -y install libevent-devel</li></ul><p><strong>安装：</strong></p><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp thrift-0.12.0.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf thrift-0.12.0.tar.gz</li><li>rm -rf thrift-0.12.0.tar.gz</li></ul><p><strong>c++三部曲</strong>：</p><ul><li>cd thrift-0.12.0</li><li>./configure —with-cpp=no —with-ruby=no</li><li>make</li><li>make install</li></ul><h1 id="Hbase源码包"><a href="#Hbase源码包" class="headerlink" title="Hbase源码包"></a>Hbase源码包</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp hbase-1.3.3-src.tar.gz /usr/local/src/tmp</li><li>cd /usr/local/src/tmp</li><li>tar zxvf hbase-1.3.3-src.tar.gz</li><li>mv hbase-1.3.3 hbase-1.3.3-src</li><li>rm -rf hbase-1.3.3-src.tar.gz</li><li>mv hbase-1.3.3-src/ ../</li></ul><h1 id="待续……"><a href="#待续……" class="headerlink" title="待续……"></a>待续……</h1><p><br></p><meting-js id="438801442" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Thrift：行李少的可以从我这儿走…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/035105.jpg&quot; alt=&quot;alejandro-escamilla-10-unsplash&quot;&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Thrift" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Thrift/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Thrift" scheme="https://alessa0.cn/tags/Thrift/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(九)：Hbase</title>
    <link href="https://alessa0.cn/posts/497b75db/"/>
    <id>https://alessa0.cn/posts/497b75db/</id>
    <published>2019-04-25T06:21:21.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Hbase：我不认识Hive…</p><br><img src="https://image.alessa0.cn/063435.jpg" alt="campaign-creators-771723-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Hbase 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://hbase.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Hbase</a></div><p></p><h1 id="安装Hbase"><a href="#安装Hbase" class="headerlink" title="安装Hbase"></a>安装Hbase</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp hbase-1.3.3-bin.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf hbase-1.3.3-bin.tar.gz</li><li>rm -rf hbase-1.3.3-bin.tar.gz</li></ul><p><strong>Hbase环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET HBASE PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_HOME</span>=/usr/local/src/hbase-1.3.3 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_CLASSPATH</span>=<span class="variable">$HBASE_HOME</span>/conf </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HBASE_LOG_DIR</span>=<span class="variable">$HBASE_HOME</span>/logs </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Hbase配置"><a href="#修改Hbase配置" class="headerlink" title="修改Hbase配置"></a>修改Hbase配置</h1><ul><li>cd hbase-1.3.3</li></ul><p><strong>创建临时目录和文件目录：</strong></p><ul><li>mkdir logs</li><li>mkdir tmp</li></ul><p><strong>配置文件：</strong></p><ul><li>cd conf</li><li>vim regionservers</li></ul><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="attribute">slave1</span> </span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><ul><li>vim hbase-env.sh</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line">export JAVA_HOME=<span class="regexp">/usr/local</span><span class="regexp">/src/jdk</span>1.<span class="number">8.0_212</span> </span><br><span class="line">export CLASSPATH=.:$<span class="symbol">CLASSPATH:</span>$JAVA_HOME/<span class="class"><span class="keyword">lib</span> </span></span><br><span class="line"><span class="comment"># 禁用Hbase自带独立Zookeeper集群</span></span><br><span class="line">export HBASE_MANAGES_ZK=<span class="literal">false</span></span><br></pre></td></tr></table></figure><ul><li>vim hbase-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 添加如下信息</span></span><br><span class="line"></span><br><span class="line"><span class="params">&lt;configuration&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.tmp.dir<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/src/</span>hbase<span class="number">-1.3</span><span class="number">.3</span>/tmp<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.rootdir<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>hdfs:<span class="comment">//master:9000/hbase&lt;/value&gt; </span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.cluster.distributed<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>true<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.zookeeper.quorum<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>master,slave1,slave2<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.zookeeper.property.dataDir<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/src/</span>zookeeper<span class="number">-3.4</span><span class="number">.14</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hbase.master.info.port<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">60010</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><h1 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h1><span class="label danger">仅在Master</span><p><strong>启动Hbase服务：</strong></p><ul><li>start-hbase.sh</li></ul><p><strong>关闭Hbase服务：</strong></p><ul><li>stop-hbase.sh</li></ul><p><br></p><meting-js id="1325898369" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Hbase：我不认识Hive…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/063435.jpg&quot; alt=&quot;campaign-creators-771723-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="HBase" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/HBase/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="HBase" scheme="https://alessa0.cn/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(八)：Spark</title>
    <link href="https://alessa0.cn/posts/55aa9f3f/"/>
    <id>https://alessa0.cn/posts/55aa9f3f/</id>
    <published>2019-04-25T05:24:37.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Spark：传说中的星二代</p><br><img src="https://image.alessa0.cn/052725.jpg" alt="aziz-acharki-370112-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Spark 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://spark.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Spark</a></div><p></p><h1 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp spark-2.3.3-bin-hadoop2.7.tgz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf spark-2.3.3-bin-hadoop2.7.tgz</li><li>rm -rf spark-2.3.3-bin-hadoop2.7.tgz</li></ul><p><strong>配置Spark环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET SPARK PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_HOME</span>=/usr/local/src/spark-2.3.3-bin-hadoop2.7 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$SPARK_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改spark配置文件"><a href="#修改spark配置文件" class="headerlink" title="修改spark配置文件"></a>修改spark配置文件</h1><ul><li>cd spark-2.3.3-bin-hadoop2.7/conf</li><li>cp spark-env.sh.template spark-env.sh</li><li>vim spark-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SCALA_HOME</span>=/usr/local/src/scala-2.11.12 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/src/jdk1.8.0_212 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/src/hadoop-2.8.5 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_CONF_DIR</span>=<span class="variable">$HADOOP_HOME</span>/etc/hadoop </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">SPARK_DAEMON_JAVA_OPTS</span>=<span class="string">"-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181"</span> </span><br><span class="line"><span class="attribute">SPARK_MASTER_IP</span>=master </span><br><span class="line"><span class="attribute">SPARK_LOCAL_DIRS</span>=/usr/local/src/spark-2.3.3-bin-hadoop2.7 </span><br><span class="line"><span class="attribute">SPARK_DRIVER_MEMORY</span>=1G</span><br></pre></td></tr></table></figure><ul><li>cp slaves.template slaves</li><li>vim slaves</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><h1 id="启动Standalone"><a href="#启动Standalone" class="headerlink" title="启动Standalone"></a>启动Standalone</h1><span class="label danger">仅在Master</span><p><strong>启动集群：</strong></p><ul><li>cd spark-2.3.3-bin-hadoop2.7/sbin</li><li>./start-all.sh</li></ul><p><strong>WEB监控页面：</strong></p><ul><li>Spark：<a href="http://master:8080" target="_blank" rel="noopener">http://master:8080</a></li></ul><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><ul><li>cd spark-2.3.3-bin-hadoop2.7</li></ul><p><strong>本地模式：</strong></p><ul><li>./bin/run-example SparkPi 10 —master local[2]</li></ul><p><strong>集群Standlone：</strong></p><ul><li>./bin/spark-submit —class org.apache.spark.examples.SparkPi —master spark://master:7077 examples/jars/spark-examples_2.11-2.3.3.jar 10</li></ul><p><strong>Spark on yarn：</strong></p><ul><li>./bin/spark-submit —class org.apache.spark.examples.SparkPi —master yarn-cluster examples/jars/spark-examples_2.11-2.3.3.jar 10</li></ul><p><br></p><meting-js id="509512457" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="https://alessa0.cn/posts/c6d1abe8/">BigData复习笔记03：推荐算法</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Spark：传说中的星二代&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/052725.jpg&quot; alt=&quot;aziz-acharki-370112-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Spark" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Spark/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Spark" scheme="https://alessa0.cn/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(七)：Hive</title>
    <link href="https://alessa0.cn/posts/9cf82033/"/>
    <id>https://alessa0.cn/posts/9cf82033/</id>
    <published>2019-04-25T03:03:30.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Hive：不要把我认成Hbase</p><br><img src="https://image.alessa0.cn/035137.jpg" alt="mounzer-awad-348688-unsplash"><a id="more"></a><p></p><blockquote class="blockquote-center"><p>Hive 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://hive.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Hive</a></div><p></p><h1 id="安装Hive"><a href="#安装Hive" class="headerlink" title="安装Hive"></a>安装Hive</h1><span class="label danger">仅在Master</span> <span class="label danger">仅在Client</span><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp apache-hive-2.3.4-bin.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf apache-hive-2.3.4-bin.tar.gz</li><li>rm -rf apache-hive-2.3.4-bin.tar.gz</li></ul><p><strong>配置Hive环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET Hive PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HIVE_HOME</span>=/usr/local/src/apache-hive-2.3.4-bin </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HIVE_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="配置mysql驱动包"><a href="#配置mysql驱动包" class="headerlink" title="配置mysql驱动包"></a>配置mysql驱动包</h1><span class="label danger">仅在Master</span><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp mysql-connector-java-5.1.47.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf mysql-connector-java-5.1.47.tar.gz</li><li>rm -rf mysql-connector-java-5.1.47.tar.gz</li><li>cp mysql-connector-java-5.1.47-bin.jar /usr/local/src/apache-hive-2.3.4-bin/lib/</li></ul><p><strong>更换jline包（版本不一致）：</strong></p><ul><li>cp apache-hive-2.3.4-bin/lib/jline-2.12.jar /usr/local/src/hadoop-2.8.5/share/hadoop/yarn/lib/</li></ul><h1 id="配置hive"><a href="#配置hive" class="headerlink" title="配置hive"></a>配置hive</h1><span class="label danger">仅在Master</span> <span class="label danger">仅在Client</span><ul><li>cd apache-hive-2.3.4-bin</li></ul><p><strong>创建临时目录/日志目录/数仓目录：</strong></p><ul><li>mkdir -p data/hive/log</li><li>mkdir -p data/hive/tmp</li><li>mkdir -p data/hive/warehouse</li></ul><p><strong>配置文件：</strong></p><ul><li>cd conf</li><li>cp hive-env.sh.template hive-env.sh</li><li>vim hive-env.sh</li></ul><figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line">export JAVA_HOME=<span class="regexp">/usr/local</span><span class="regexp">/src/jdk</span>1.<span class="number">8.0_212</span> </span><br><span class="line">export HADOOP_HOME=<span class="regexp">/usr/local</span><span class="regexp">/src/hadoop</span>-<span class="number">2.8</span>.<span class="number">5</span> </span><br><span class="line">export HIVE_HOME=<span class="regexp">/usr/local</span><span class="regexp">/src/apache</span>-hive-<span class="number">2.3</span>.<span class="number">4</span>-bin </span><br><span class="line">export HIVE_CONF_DIR=<span class="regexp">/usr/local</span><span class="regexp">/src/apache</span>-hive-<span class="number">2.3</span>.<span class="number">4</span>-bin/conf </span><br><span class="line">export HIVE_AUX_JARS=<span class="regexp">/usr/local</span><span class="regexp">/src/apache</span>-hive-<span class="number">2.3</span>.<span class="number">4</span>-bin/<span class="class"><span class="keyword">lib</span></span></span><br></pre></td></tr></table></figure><ul><li>cp hive-default.xml.template hive-site.xml</li><li>vim hive-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 添加如下信息</span></span><br><span class="line"></span><br><span class="line"><span class="params">&lt;configuration&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionURL<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>jdbc:mysql:<span class="comment">//master:3306/hive?createDatabaseIfNotExist=true&amp;amp;useSSL=false&lt;/value&gt; </span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionDriverName<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>com.mysql.jdbc.Driver<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionUserName<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>alessa0<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>javax.jdo.option.ConnectionPassword<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>&#123;密码&#125;<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.metastore.warehouse.dir<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/src/</span>apache-hive<span class="number">-2.3</span><span class="number">.4</span>-bin<span class="meta-keyword">/data/</span>hive/warehouse<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.exec.scratchdir<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/src/</span>apache-hive<span class="number">-2.3</span><span class="number">.4</span>-bin<span class="meta-keyword">/data/</span>hive/tmp<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.querylog.location<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="meta-keyword">/usr/</span>local<span class="meta-keyword">/src/</span>apache-hive<span class="number">-2.3</span><span class="number">.4</span>-bin<span class="meta-keyword">/data/</span>hive/log<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line"><span class="params">&lt;/configuration&gt;</span></span><br></pre></td></tr></table></figure><p><strong>把{system:java.io.tmpdir} 改成 /usr/local/src/apache-hive-2.3.4-bin/data/hive/tmp：</strong></p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">:%s/$&#123;system<span class="function">:java.io.tmpdir</span>&#125;/\<span class="string">/usr</span>\<span class="string">/local</span>\<span class="string">/src</span>\<span class="string">/apache-hive-2.3.4-bin</span>\<span class="string">/data</span>\<span class="string">/hive</span>\<span class="string">/tmp/g</span></span><br></pre></td></tr></table></figure><p><strong>把 {system:user.name} 改成 {user.name} ：</strong></p><figure class="highlight elixir"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">:%s/</span><span class="variable">$&#123;</span><span class="symbol">system:</span>user.name&#125;/alessa<span class="number">0</span>/g</span><br></pre></td></tr></table></figure><h1 id="初始化hive-MySQL版"><a href="#初始化hive-MySQL版" class="headerlink" title="初始化hive(MySQL版)"></a>初始化hive(MySQL版)</h1><ul><li>schematool -dbType mysql -initSchema</li></ul><h1 id="配置使用hiveserver2"><a href="#配置使用hiveserver2" class="headerlink" title="配置使用hiveserver2"></a>配置使用hiveserver2</h1><span class="label danger">仅在Master</span><ul><li>vim hive-site.xml</li></ul><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta"># 添加如下信息</span></span><br><span class="line"></span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.server2.thrift.port<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">10000</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.server2.thrift.bind.host<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>master<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.server2.enable.doAs<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>false<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.metastore.uris<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>thrift:<span class="comment">//master:9083&lt;/value&gt; </span></span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.support.concurrency<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>true<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.zookeeper.quorum<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>master:<span class="number">2181</span>,slave1:<span class="number">2181</span>,slave2:<span class="number">2181</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.server2.webui.host<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span>master<span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span> </span><br><span class="line">    <span class="params">&lt;property&gt;</span> </span><br><span class="line">        <span class="params">&lt;name&gt;</span>hive.server2.webui.port<span class="params">&lt;/name&gt;</span> </span><br><span class="line">        <span class="params">&lt;value&gt;</span><span class="number">10002</span><span class="params">&lt;/value&gt;</span> </span><br><span class="line">    <span class="params">&lt;/property&gt;</span></span><br></pre></td></tr></table></figure><h1 id="服务端启动"><a href="#服务端启动" class="headerlink" title="服务端启动"></a>服务端启动</h1><span class="label danger">仅在Master</span><p><strong>启动 metastore 服务</strong></p><ul><li>nohup hive —service metastore &gt;&gt; /usr/local/src/apache-hive-2.3.4-bin/logs/hivelog.log 2&gt;&amp;1 &amp;</li></ul><p><strong>启动 hiveserver2 服务</strong></p><ul><li>nohup hiveserver2 1&gt;/usr/local/src/apache-hive-2.3.4-bin/logs/hiveserver.log 2&gt;/usr/local/src/apache-hive-2.3.4-bin/logs/hiveserver.err &amp;</li></ul><p><strong>测试</strong></p><ul><li>Web UI：<a href="http://master:10002/" target="_blank" rel="noopener">http://master:10002/</a></li></ul><h1 id="客户端连接"><a href="#客户端连接" class="headerlink" title="客户端连接"></a>客户端连接</h1><span class="label danger">仅在Client</span><p><strong>启动beeline ：</strong></p><ul><li>beeline -u “jdbc:hive2://master:10000” alessa0 1008</li></ul><p><strong>退出beeline ：</strong></p><ul><li>!q</li></ul><p><br></p><meting-js id="31473269" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Hive：不要把我认成Hbase&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/035137.jpg&quot; alt=&quot;mounzer-awad-348688-unsplash&quot;&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Hive" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Hive/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Hive" scheme="https://alessa0.cn/tags/Hive/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(六)：MySQL</title>
    <link href="https://alessa0.cn/posts/3f038b9/"/>
    <id>https://alessa0.cn/posts/3f038b9/</id>
    <published>2019-04-25T02:31:11.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">MySQL：我就是个工具人…</p><br><img src="https://image.alessa0.cn/024045.jpg" alt="kevin-ku-364843-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>MySQL 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://www.mysql.com/cn/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>MySQL</a></div><p></p><h1 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h1><span class="label danger">仅在Master</span><p><strong>安装mariadb：</strong> <span class="label success">开源版MySQL</span></p><ul><li>yum -y install mariadb-server mariadb</li><li>rpm -q mariadb mariadb-server</li></ul><p><strong>设置开机启动：</strong></p><ul><li>systemctl enable mariadb</li><li>systemctl daemon-reload</li></ul><p><strong>开启mysql：</strong></p><ul><li>systemctl start mariadb</li></ul><p><strong>关闭mysql：</strong></p><ul><li>systemctl stop mariadb</li></ul><p><strong>重启mysql：</strong></p><ul><li>systemctl restart mariadb</li></ul><p><strong>查看mysql状态：</strong></p><ul><li>systemctl status mariadb</li></ul><h1 id="通过内置的安全脚本实现对数据库的安全保护"><a href="#通过内置的安全脚本实现对数据库的安全保护" class="headerlink" title="通过内置的安全脚本实现对数据库的安全保护"></a>通过内置的安全脚本实现对数据库的安全保护</h1><ul><li>mysql_secure_installation</li></ul><h1 id="创建Hive账户"><a href="#创建Hive账户" class="headerlink" title="创建Hive账户"></a>创建Hive账户</h1><p><strong>登录root账户：</strong></p><ul><li>mysql -uroot -p</li></ul><p><strong>创建账户：</strong></p><ul><li>CREATE USER ‘alessa0’@’%’ IDENTIFIED BY ‘{密码}’;</li></ul><p><strong>设置mysql远程登录：</strong></p><ul><li>GRANT ALL ON <em>.</em> TO ‘alessa0’@’%’;</li></ul><p><strong>刷新权限：</strong></p><ul><li>flush privileges;</li></ul><p><br></p><meting-js id="145223" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="www.chunlife.top/2018/09/22/MySQL查询/">MySQL查询</a></li><li><a href="chunlife.top/2018/09/22/MySQL查询/">MySQL查询</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;MySQL：我就是个工具人…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/024045.jpg&quot; alt=&quot;kevin-ku-364843-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="MySQL" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/MySQL/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="MySQL" scheme="https://alessa0.cn/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(五)：Redis</title>
    <link href="https://alessa0.cn/posts/9aff70cb/"/>
    <id>https://alessa0.cn/posts/9aff70cb/</id>
    <published>2019-04-24T09:41:34.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Redis：就是这么快！</p><br><img src="https://image.alessa0.cn/163221.jpg" alt="shiro-hatori-258976-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Redis 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://redis.io" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Redis</a></div><p></p><h1 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp redis-5.0.4.tar.gz /usr/local/src/</li><li>cd /usr/local/src/</li><li>tar zxvf redis-5.0.4.tar.gz</li><li>rm -rf redis-5.0.4.tar.gz</li></ul><h1 id="待续……"><a href="#待续……" class="headerlink" title="待续……"></a>待续……</h1><p><br></p><meting-js id="494865824" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li><li><a href="https://zsnmwy.net/300.html">针对Redis默认端口的挖矿脚本分析</a></li><li><a href="https://huzhiliang.com/posts/1682366716.html">Python 实现 Redis 异步客户端</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Redis：就是这么快！&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/163221.jpg&quot; alt=&quot;shiro-hatori-258976-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Redis" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Redis/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Redis" scheme="https://alessa0.cn/tags/Redis/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(四)：ZooKeeper</title>
    <link href="https://alessa0.cn/posts/9c5427b6/"/>
    <id>https://alessa0.cn/posts/9c5427b6/</id>
    <published>2019-04-24T09:40:10.000Z</published>
    <updated>2019-08-05T07:18:53.184Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">ZooKeeper：你们都安分点…</p><br><img src="https://image.alessa0.cn/051510.jpg" alt="daiga-ellaby-354470-unsplash"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>ZooKeeper 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://zookeeper.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Zookeeper</a></div><p></p><h1 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp zookeeper-3.4.14.tar.gz /usr/local/src/</li><li>cd /usr/local/src</li><li>tar zxvf zookeeper-3.4.14.tar.gz</li><li>rm -rf zookeeper-3.4.14.tar.gz</li></ul><p><strong>配置Zookeeper环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET ZOOKEEPER PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">ZOOKEEPER_HOME</span>=/usr/local/src/zookeeper-3.4.14 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$ZOOKEEPER_HOME/bin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="修改Zookeeper配置"><a href="#修改Zookeeper配置" class="headerlink" title="修改Zookeeper配置"></a>修改Zookeeper配置</h1><ul><li>cd zookeeper-3.4.14</li></ul><p><strong>创建临时目录/日志目录：</strong></p><ul><li>mkdir data</li><li>mkdir logs</li></ul><p><strong>配置文件：</strong></p><ul><li>cd conf</li><li>cp zoo_sample.cfg zoo.cfg</li><li>vim zoo.cfg</li></ul><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="attr">dataDir</span>=/usr/local/src/zookeeper-<span class="number">3.4</span>.<span class="number">14</span>/data </span><br><span class="line"><span class="attr">dataLogDir</span>=/usr/local/src/zookeeper-<span class="number">3.4</span>.<span class="number">14</span>/logs </span><br><span class="line"><span class="attr">server.1</span>=master:<span class="number">2888</span>:<span class="number">3888</span> </span><br><span class="line"><span class="attr">server.2</span>=slave1:<span class="number">2888</span>:<span class="number">3888</span> </span><br><span class="line"><span class="attr">server.3</span>=slave2:<span class="number">2888</span>:<span class="number">3888</span></span><br></pre></td></tr></table></figure><p><strong>分别添加唯一标识ID：</strong></p><span class="label danger">仅在Master</span><ul><li>echo “1” &gt; /usr/local/src/zookeeper-3.4.14/data/myid</li></ul><span class="label danger">仅在Slava1</span><ul><li>echo “2” &gt; /usr/local/src/zookeeper-3.4.14/data/myid</li></ul><span class="label danger">仅在Slava2</span><ul><li>echo “3” &gt; /usr/local/src/zookeeper-3.4.14/data/myid</li></ul><h1 id="启动Zookeeper"><a href="#启动Zookeeper" class="headerlink" title="启动Zookeeper"></a>启动Zookeeper</h1><p><strong>启动服务：</strong></p><ul><li>zkServer.sh start</li></ul><p><strong>查看运行状态：</strong></p><ul><li>zkServer.sh status</li><li>jps</li></ul><p><strong>关闭服务：</strong></p><ul><li>zkServer.sh stop</li></ul><p><br></p><meting-js id="1359595520" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;ZooKeeper：你们都安分点…&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/051510.jpg&quot; alt=&quot;daiga-ellaby-354470-unsplash&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Zookeeper" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Zookeeper/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Zookeeper" scheme="https://alessa0.cn/tags/Zookeeper/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop 集群搭建(三)：Hadoop</title>
    <link href="https://alessa0.cn/posts/6617c8b9/"/>
    <id>https://alessa0.cn/posts/6617c8b9/</id>
    <published>2019-04-24T09:40:02.000Z</published>
    <updated>2019-08-05T07:18:53.183Z</updated>
    
    <content type="html"><![CDATA[<!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --><p></p><p class="description">Hadoop：我好了你们再上</p><br><img src="https://image.alessa0.cn/163232.jpeg" alt="664px-Hadoop_logo.svg"><p></p><a id="more"></a><blockquote class="blockquote-center"><p>Hadoop 安装配置</p></blockquote><p></p><div class="text-center"><a class="btn" href="https://hadoop.apache.org/" target="_blank" rel="noopener"><i class="fa fa-home fa-lg fa-fw"></i>Hadoop</a></div><br>Ps：除非特别指出<span class="label danger">仅在Master</span>，则在所有节点配置<p></p><h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><ul><li>cd /mnt/hgfs/Hadoop</li><li>cp hadoop-2.8.5.tar.gz /usr/local/src/</li><li>cd /usr/local/src</li><li>tar zxvf hadoop-2.8.5.tar.gz</li><li>rm -rf hadoop-2.8.5.tar.gz</li></ul><p><strong>配置Hadoop环境变量：</strong></p><ul><li>vim ~/.bashrc</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="comment"># SET HADOOP PATH </span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">HADOOP_HOME</span>=/usr/local/src/hadoop-2.8.5 </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/bin </span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure><ul><li>source ~/.bashrc</li></ul><h1 id="Hadoop配置文件"><a href="#Hadoop配置文件" class="headerlink" title="Hadoop配置文件"></a>Hadoop配置文件</h1><ul><li>cd hadoop-2.8.5</li></ul><p><strong>创建临时目录和文件目录：</strong></p><ul><li>mkdir -p /usr/local/src/hadoop-2.8.5/dfs/name</li><li>mkdir -p /usr/local/src/hadoop-2.8.5/dfs/data</li><li>mkdir -p /usr/local/src/hadoop-2.8.5/tmp/dfs</li><li>cd etc/hadoop</li></ul><p><strong>仅在Client配置(若无可跳过此步骤)：</strong></p><ul><li>vim core-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 指定Hadoop所使用的文件系统Schema --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>mv mapred-site.xml.template mapred-site.xml</li><li>vim mapred-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>vim yarn-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定ResourceManager地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p><strong>修改Hadoop配置文件：</strong></p><ul><li>vim hadoop-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/src/jdk1.8.0_212</span><br></pre></td></tr></table></figure><ul><li>vim yarn-env.sh</li></ul><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line"><span class="builtin-name">export</span> <span class="attribute">JAVA_HOME</span>=/usr/local/src/jdk1.8.0_212</span><br></pre></td></tr></table></figure><ul><li>vim slaves</li></ul><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加如下信息</span></span><br><span class="line">slave1</span><br><span class="line">slave2</span><br></pre></td></tr></table></figure><ul><li>vim core-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定Hadoop所使用的文件系统Schema --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定HDFS本地临时存放目录 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop-2.8.5/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>vim hdfs-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定SecondaryNamenode端口地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.secondary.http-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:9001<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定HDFS本地Namenode存放目录 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/src/hadoop-2.8.5/dfs.name<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定HDFS本地Datanode存放目录 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/src/hadoop-2.8.5/dfs.data<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- HDFS副本数量(小于等于从节点的数量) --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>vim mapred-site.xml</li></ul><figure class="highlight dust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="xml"># 添加如下信息</span></span><br><span class="line"><span class="xml"></span></span><br><span class="line"><span class="xml"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="comment">&lt;!-- 指定MapReduce程序运行在Yarn上 --&gt;</span></span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="comment">&lt;!-- 配置JHS --&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:10020<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:19888<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.staging-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/usr/local/src/hadoop-2.8.5/tmp/hadoop-yarn/staging<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.intermediate-done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$</span><span class="template-variable">&#123;yarn.app.mapreduce.am.staging-dir&#125;</span><span class="xml">/history/done_intermediate<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.done-dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>$</span><span class="template-variable">&#123;yarn.app.mapreduce.am.staging-dir&#125;</span><span class="xml">/history/done<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.cleaner.enable<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.cleaner.interval-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>86400000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.max-age-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>604800000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.jobhistory.move.interval-ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span></span><br><span class="line"><span class="xml">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>180000<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span></span><br><span class="line"><span class="xml">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span></span><br><span class="line"><span class="xml"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span></span><br></pre></td></tr></table></figure><ul><li>vim yarn-site.xml</li></ul><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"># 添加如下信息</span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定reducer获取数据的方式--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定reducer获取数据所需的类--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce.shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="comment">&lt;!-- 指定ResourceManager地址 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8032<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.scheduler.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8030<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.resource-tracker.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8035<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.admin.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8033<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.webapp.address<span class="tag">&lt;/<span class="name">name</span>&gt;</span> </span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master:8088<span class="tag">&lt;/<span class="name">value</span>&gt;</span> </span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span> </span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h1 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h1><span class="label danger">仅在Master</span><p><strong>初始化NameNode：</strong></p><ul><li>hadoop namenode -format</li></ul><p><strong>启动Hadoop集群：</strong></p><ul><li>start-dfs.sh</li><li>start-yarn.sh</li></ul><p><strong>WEB监控页面：</strong></p><ul><li>HDFS：<a href="http://ip:50070" target="_blank" rel="noopener">http://ip:50070</a></li><li>YARN：<a href="http://ip:8088" target="_blank" rel="noopener">http://ip:8088</a></li></ul><p><br></p><meting-js id="1313354324" server="netease" type="song" preload="none"><hr></meting-js><!-- rebuild by neat --><div><h1>推荐文章:</h1><ul><li><a href="https://alessa0.cn/posts/55aa9f3f/">Hadoop 集群搭建(八)：Spark</a></li><li><a href="https://alessa0.cn/posts/6a54df13/">Hadoop 集群搭建(十四)：Storm on Yarn</a></li></ul></div>]]></content>
    
    <summary type="html">
    
      &lt;!-- build time:Mon Aug 05 2019 15:19:51 GMT+0800 (GMT+08:00) --&gt;&lt;p&gt;&lt;/p&gt;&lt;p class=&quot;description&quot;&gt;Hadoop：我好了你们再上&lt;/p&gt;&lt;br&gt;&lt;img src=&quot;https://image.alessa0.cn/163232.jpeg&quot; alt=&quot;664px-Hadoop_logo.svg&quot;&gt;&lt;p&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/"/>
    
      <category term="大数据" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
      <category term="环境搭建" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Hadoop" scheme="https://alessa0.cn/categories/%E6%8A%80%E6%9C%AF/%E5%A4%A7%E6%95%B0%E6%8D%AE/%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/Hadoop/"/>
    
    
      <category term="BigData" scheme="https://alessa0.cn/tags/BigData/"/>
    
      <category term="Hadoop环境搭建" scheme="https://alessa0.cn/tags/Hadoop%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/"/>
    
      <category term="Hadoop" scheme="https://alessa0.cn/tags/Hadoop/"/>
    
  </entry>
  
</feed>
